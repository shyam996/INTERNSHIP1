{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0e306aa",
   "metadata": {},
   "source": [
    "### 1. Scrape the details of most viewed videos on YouTube from Wikipedia.Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos.You need to find following details:A) Rank B) Name C) Artist D) Upload date E) Views\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8ec823e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44fd5446",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bee643e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16a54fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "\n",
    "names = driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[2]')\n",
    "for i in names:\n",
    "    name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d2c70b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"Baby Shark Dance\"[4]',\n",
       " '\"Despacito\"[7]',\n",
       " '\"Johny Johny Yes Papa\"[14]',\n",
       " '\"Bath Song\"[15]',\n",
       " '\"Shape of You\"[16]',\n",
       " '\"See You Again\"[18]',\n",
       " '\"Phonics Song with Two Words\"[23]',\n",
       " '\"Wheels on the Bus\"[24]',\n",
       " '\"Uptown Funk\"[25]',\n",
       " '\"Learning Colors – Colorful Eggs on a Farm\"[26]',\n",
       " '\"Gangnam Style\"[27]',\n",
       " '\"Masha and the Bear – Recipe for Disaster\"[32]',\n",
       " '\"Dame Tu Cosita\"[33]',\n",
       " '\"Axel F\"[34]',\n",
       " '\"Sugar\"[35]',\n",
       " '\"Roar\"[36]',\n",
       " '\"Counting Stars\"[37]',\n",
       " '\"Sorry\"[38]',\n",
       " '\"Baa Baa Black Sheep\"[39]',\n",
       " '\"Thinking Out Loud\"[40]',\n",
       " '\"Waka Waka (This Time for Africa)\"[41]',\n",
       " '\"Dark Horse\"[42]',\n",
       " '\"Faded\"[43]',\n",
       " '\"Perfect\"[44]',\n",
       " '\"Lakdi Ki Kathi\"[45]',\n",
       " '\"Let Her Go\"[46]',\n",
       " '\"Girls Like You\"[47]',\n",
       " '\"Humpty the train on a fruits ride\"[48]',\n",
       " '\"Lean On\"[49]',\n",
       " '\"Bailando\"[50]']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b954f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist =[]\n",
    "\n",
    "artists=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[3]')\n",
    "for i in artists:\n",
    "    artist.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f720a68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Pinkfong Baby Shark - Kids' Songs & Stories\",\n",
       " 'Luis Fonsi',\n",
       " 'LooLoo Kids',\n",
       " 'Cocomelon – Nursery Rhymes',\n",
       " 'Ed Sheeran',\n",
       " 'Wiz Khalifa',\n",
       " 'ChuChu TV',\n",
       " 'Cocomelon – Nursery Rhymes',\n",
       " 'Mark Ronson',\n",
       " 'Miroshka TV',\n",
       " 'Psy',\n",
       " 'Get Movies',\n",
       " 'El Chombo',\n",
       " 'Crazy Frog',\n",
       " 'Maroon 5',\n",
       " 'Katy Perry',\n",
       " 'OneRepublic',\n",
       " 'Justin Bieber',\n",
       " 'Cocomelon – Nursery Rhymes',\n",
       " 'Ed Sheeran',\n",
       " 'Shakira',\n",
       " 'Katy Perry',\n",
       " 'Alan Walker',\n",
       " 'Ed Sheeran',\n",
       " 'Jingle Toons',\n",
       " 'Passenger',\n",
       " 'Maroon 5',\n",
       " 'Kiddiestv Hindi – Nursery Rhymes & Kids Songs',\n",
       " 'Major Lazer',\n",
       " 'Enrique Iglesias']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a2fe325",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank=[]\n",
    "\n",
    "ranks= driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[1]')\n",
    "for i in ranks:\n",
    "    rank.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37404836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.',\n",
       " '2.',\n",
       " '3.',\n",
       " '4.',\n",
       " '5.',\n",
       " '6.',\n",
       " '7.',\n",
       " '8.',\n",
       " '9.',\n",
       " '10.',\n",
       " '11.',\n",
       " '12.',\n",
       " '13.',\n",
       " '14.',\n",
       " '15.',\n",
       " '16.',\n",
       " '17.',\n",
       " '18.',\n",
       " '19.',\n",
       " '20.',\n",
       " '21.',\n",
       " '22.',\n",
       " '23.',\n",
       " '24.',\n",
       " '25.',\n",
       " '26.',\n",
       " '27.',\n",
       " '28.',\n",
       " '29.',\n",
       " '30.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4be038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "view=[]\n",
    "\n",
    "views= driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[4]')\n",
    "for i in views:\n",
    "    view.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "baab50e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12.73',\n",
       " '8.14',\n",
       " '6.69',\n",
       " '6.15',\n",
       " '5.97',\n",
       " '5.86',\n",
       " '5.26',\n",
       " '5.14',\n",
       " '4.89',\n",
       " '4.87',\n",
       " '4.77',\n",
       " '4.55',\n",
       " '4.32',\n",
       " '3.87',\n",
       " '3.86',\n",
       " '3.78',\n",
       " '3.77',\n",
       " '3.65',\n",
       " '3.61',\n",
       " '3.58',\n",
       " '3.56',\n",
       " '3.50',\n",
       " '3.44',\n",
       " '3.42',\n",
       " '3.42',\n",
       " '3.42',\n",
       " '3.40',\n",
       " '3.38',\n",
       " '3.37',\n",
       " '3.37']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2802ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "publish=[]\n",
    "\n",
    "pubs= driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[5]')\n",
    "for i in pubs:\n",
    "    publish.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0217380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['June 17, 2016',\n",
       " 'January 12, 2017',\n",
       " 'October 8, 2016',\n",
       " 'May 2, 2018',\n",
       " 'January 30, 2017',\n",
       " 'April 6, 2015',\n",
       " 'March 6, 2014',\n",
       " 'May 24, 2018',\n",
       " 'November 19, 2014',\n",
       " 'February 27, 2018',\n",
       " 'July 15, 2012',\n",
       " 'January 31, 2012',\n",
       " 'April 5, 2018',\n",
       " 'June 16, 2009',\n",
       " 'January 14, 2015',\n",
       " 'September 5, 2013',\n",
       " 'May 31, 2013',\n",
       " 'October 22, 2015',\n",
       " 'June 25, 2018',\n",
       " 'October 7, 2014',\n",
       " 'June 4, 2010',\n",
       " 'February 20, 2014',\n",
       " 'December 3, 2015',\n",
       " 'November 9, 2017',\n",
       " 'June 14, 2018',\n",
       " 'July 25, 2012',\n",
       " 'May 31, 2018',\n",
       " 'January 26, 2018',\n",
       " 'March 22, 2015',\n",
       " 'April 11, 2014']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9d5e20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload_Date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[4]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>12.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[7]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[14]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[15]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[16]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[18]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[23]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Wheels on the Bus\"[24]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[25]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[26]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[27]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[32]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[33]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Axel F\"[34]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Sugar\"[35]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Roar\"[36]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Counting Stars\"[37]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Sorry\"[38]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[39]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Thinking Out Loud\"[40]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[41]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Dark Horse\"[42]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Faded\"[43]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Perfect\"[44]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[45]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Let Her Go\"[46]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Girls Like You\"[47]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[48]</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Lean On\"[49]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Bailando\"[50]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[4]   \n",
       "1    2.                                   \"Despacito\"[7]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[14]   \n",
       "3    4.                                  \"Bath Song\"[15]   \n",
       "4    5.                               \"Shape of You\"[16]   \n",
       "5    6.                              \"See You Again\"[18]   \n",
       "6    7.                \"Phonics Song with Two Words\"[23]   \n",
       "7    8.                          \"Wheels on the Bus\"[24]   \n",
       "8    9.                                \"Uptown Funk\"[25]   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"[26]   \n",
       "10  11.                              \"Gangnam Style\"[27]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[32]   \n",
       "12  13.                             \"Dame Tu Cosita\"[33]   \n",
       "13  14.                                     \"Axel F\"[34]   \n",
       "14  15.                                      \"Sugar\"[35]   \n",
       "15  16.                                       \"Roar\"[36]   \n",
       "16  17.                             \"Counting Stars\"[37]   \n",
       "17  18.                                      \"Sorry\"[38]   \n",
       "18  19.                        \"Baa Baa Black Sheep\"[39]   \n",
       "19  20.                          \"Thinking Out Loud\"[40]   \n",
       "20  21.           \"Waka Waka (This Time for Africa)\"[41]   \n",
       "21  22.                                 \"Dark Horse\"[42]   \n",
       "22  23.                                      \"Faded\"[43]   \n",
       "23  24.                                    \"Perfect\"[44]   \n",
       "24  25.                             \"Lakdi Ki Kathi\"[45]   \n",
       "25  26.                                 \"Let Her Go\"[46]   \n",
       "26  27.                             \"Girls Like You\"[47]   \n",
       "27  28.          \"Humpty the train on a fruits ride\"[48]   \n",
       "28  29.                                    \"Lean On\"[49]   \n",
       "29  30.                                   \"Bailando\"[50]   \n",
       "\n",
       "                                           Artist        Upload_Date  Views  \n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016  12.73  \n",
       "1                                      Luis Fonsi   January 12, 2017   8.14  \n",
       "2                                     LooLoo Kids    October 8, 2016   6.69  \n",
       "3                      Cocomelon – Nursery Rhymes        May 2, 2018   6.15  \n",
       "4                                      Ed Sheeran   January 30, 2017   5.97  \n",
       "5                                     Wiz Khalifa      April 6, 2015   5.86  \n",
       "6                                       ChuChu TV      March 6, 2014   5.26  \n",
       "7                      Cocomelon – Nursery Rhymes       May 24, 2018   5.14  \n",
       "8                                     Mark Ronson  November 19, 2014   4.89  \n",
       "9                                     Miroshka TV  February 27, 2018   4.87  \n",
       "10                                            Psy      July 15, 2012   4.77  \n",
       "11                                     Get Movies   January 31, 2012   4.55  \n",
       "12                                      El Chombo      April 5, 2018   4.32  \n",
       "13                                     Crazy Frog      June 16, 2009   3.87  \n",
       "14                                       Maroon 5   January 14, 2015   3.86  \n",
       "15                                     Katy Perry  September 5, 2013   3.78  \n",
       "16                                    OneRepublic       May 31, 2013   3.77  \n",
       "17                                  Justin Bieber   October 22, 2015   3.65  \n",
       "18                     Cocomelon – Nursery Rhymes      June 25, 2018   3.61  \n",
       "19                                     Ed Sheeran    October 7, 2014   3.58  \n",
       "20                                        Shakira       June 4, 2010   3.56  \n",
       "21                                     Katy Perry  February 20, 2014   3.50  \n",
       "22                                    Alan Walker   December 3, 2015   3.44  \n",
       "23                                     Ed Sheeran   November 9, 2017   3.42  \n",
       "24                                   Jingle Toons      June 14, 2018   3.42  \n",
       "25                                      Passenger      July 25, 2012   3.42  \n",
       "26                                       Maroon 5       May 31, 2018   3.40  \n",
       "27  Kiddiestv Hindi – Nursery Rhymes & Kids Songs   January 26, 2018   3.38  \n",
       "28                                    Major Lazer     March 22, 2015   3.37  \n",
       "29                               Enrique Iglesias     April 11, 2014   3.37  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Rank':rank,'Name':name,'Artist':artist,'Upload_Date':publish,'Views':view})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc72a2d",
   "metadata": {},
   "source": [
    "# 2. Scrape the details teamIndia’sinternationalfixtures from bcci.tv.Url = https://www.bcci.tv/.You need to find following details: A) Match title (I.e. 1stODI) B) Series C) Place D) Date E) Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbfe45ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40e7dba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f51381fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.bcci.tv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e37b8c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter=driver.find_element(By.XPATH,'/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a')\n",
    "inter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b79c3c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div/ul/li[2]/a')\n",
    "result.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ee75b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "match = []\n",
    "\n",
    "matches=driver.find_elements(By.XPATH,'//span[@class=\"matchOrderText ng-binding ng-scope\"]')\n",
    "for i in matches:\n",
    "    match.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c93214bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3rd ODI -',\n",
       " '2nd ODI -',\n",
       " '1st ODI -',\n",
       " '3rd ODI -',\n",
       " '2nd ODI -',\n",
       " '1st ODI -',\n",
       " '3rd ODI -',\n",
       " '2nd ODI -',\n",
       " '1st ODI -',\n",
       " '3rd ODI -',\n",
       " '2nd ODI -',\n",
       " '1st ODI -',\n",
       " '3rd ODI -',\n",
       " '2nd ODI -',\n",
       " '1st ODI -',\n",
       " '3rd ODI -',\n",
       " '2nd ODI -',\n",
       " '1st ODI -']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3dc8165",
   "metadata": {},
   "outputs": [],
   "source": [
    "series=[]\n",
    "\n",
    "ser=driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "for i in ser:\n",
    "    series.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "304938cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AUSTRALIA TOUR OF INDIA 2023',\n",
       " 'AUSTRALIA TOUR OF INDIA 2023',\n",
       " 'AUSTRALIA TOUR OF INDIA 2023',\n",
       " 'NEW ZEALAND TOUR OF INDIA 2022-23',\n",
       " 'NEW ZEALAND TOUR OF INDIA 2022-23',\n",
       " 'NEW ZEALAND TOUR OF INDIA 2022-23',\n",
       " 'SRI LANKA TOUR OF INDIA 2022-23',\n",
       " 'SRI LANKA TOUR OF INDIA 2022-23',\n",
       " 'SRI LANKA TOUR OF INDIA 2022-23',\n",
       " 'INDIA TOUR OF BANGLADESH 2022-23',\n",
       " 'INDIA TOUR OF BANGLADESH 2022-23',\n",
       " 'INDIA TOUR OF BANGLADESH 2022-23',\n",
       " 'INDIA TOUR OF NEW ZEALAND 2022-23',\n",
       " 'INDIA TOUR OF NEW ZEALAND 2022-23',\n",
       " 'INDIA TOUR OF NEW ZEALAND 2022-23',\n",
       " 'SOUTH AFRICA TOUR OF INDIA 2022',\n",
       " 'SOUTH AFRICA TOUR OF INDIA 2022',\n",
       " 'SOUTH AFRICA TOUR OF INDIA 2022']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83a9bbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "place=[]\n",
    "\n",
    "places=driver.find_elements(By.XPATH,'//span[2][@class=\"ng-binding ng-scope\"]')\n",
    "for i in places:\n",
    "    place.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0eab0c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MA Chidambaram Stadium,',\n",
       " 'Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stadium,',\n",
       " 'Wankhede Stadium,',\n",
       " 'Holkar Cricket Stadium,',\n",
       " 'Shaheed Veer Narayan Singh International Cricket Stadium,',\n",
       " 'Rajiv Gandhi International Stadium,',\n",
       " 'Greenfield International Stadium,',\n",
       " 'Eden Gardens,',\n",
       " 'Barsapara Cricket Stadium,',\n",
       " 'Zahur Ahmed Chowdhury Stadium,',\n",
       " 'Shere Bangla National Stadium, Mirpur,',\n",
       " 'Shere Bangla National Stadium, Mirpur,',\n",
       " 'Hagley Oval,',\n",
       " 'Seddon Park,',\n",
       " 'Eden Park,',\n",
       " 'Arun Jaitley Stadium,',\n",
       " 'JSCA International Stadium Complex,',\n",
       " 'Bharat Ratna Shri Atal Bihari Vajpayee Ekana Cricket Stadium,']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "742b3c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "date=[]\n",
    "\n",
    "dates = driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]')\n",
    "for i in dates:\n",
    "    date.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07435a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['22 MAR 2023',\n",
       " '19 MAR 2023',\n",
       " '17 MAR 2023',\n",
       " '24 JAN 2023',\n",
       " '21 JAN 2023',\n",
       " '18 JAN 2023',\n",
       " '15 JAN 2023',\n",
       " '12 JAN 2023',\n",
       " '10 JAN 2023',\n",
       " '10 DEC 2022',\n",
       " '7 DEC 2022',\n",
       " '4 DEC 2022',\n",
       " '30 NOV 2022',\n",
       " '27 NOV 2022',\n",
       " '25 NOV 2022',\n",
       " '11 OCT 2022',\n",
       " '9 OCT 2022',\n",
       " '6 OCT 2022']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a71ee0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "time=[]\n",
    "\n",
    "times=driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "for i in times:\n",
    "    time.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08dd24a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1:30 PM IST',\n",
       " '1:30 PM IST',\n",
       " '1:30 PM IST',\n",
       " '1:30 PM IST',\n",
       " '1:30 PM IST',\n",
       " '1:30 PM IST',\n",
       " '1:30 PM IST',\n",
       " '1:30 PM IST',\n",
       " '1:30 PM IST',\n",
       " '11:30 AM IST',\n",
       " '11:30 AM IST',\n",
       " '11:30 AM IST',\n",
       " '7:00 AM IST',\n",
       " '7:00 AM IST',\n",
       " '7:00 AM IST',\n",
       " '1:30 PM IST',\n",
       " '1:30 PM IST',\n",
       " '2:00 PM IST']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0151080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3rd ODI -</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023</td>\n",
       "      <td>MA Chidambaram Stadium,</td>\n",
       "      <td>22 MAR 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023</td>\n",
       "      <td>Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stadium,</td>\n",
       "      <td>19 MAR 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023</td>\n",
       "      <td>Wankhede Stadium,</td>\n",
       "      <td>17 MAR 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3rd ODI -</td>\n",
       "      <td>NEW ZEALAND TOUR OF INDIA 2022-23</td>\n",
       "      <td>Holkar Cricket Stadium,</td>\n",
       "      <td>24 JAN 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>NEW ZEALAND TOUR OF INDIA 2022-23</td>\n",
       "      <td>Shaheed Veer Narayan Singh International Crick...</td>\n",
       "      <td>21 JAN 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>NEW ZEALAND TOUR OF INDIA 2022-23</td>\n",
       "      <td>Rajiv Gandhi International Stadium,</td>\n",
       "      <td>18 JAN 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3rd ODI -</td>\n",
       "      <td>SRI LANKA TOUR OF INDIA 2022-23</td>\n",
       "      <td>Greenfield International Stadium,</td>\n",
       "      <td>15 JAN 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>SRI LANKA TOUR OF INDIA 2022-23</td>\n",
       "      <td>Eden Gardens,</td>\n",
       "      <td>12 JAN 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>SRI LANKA TOUR OF INDIA 2022-23</td>\n",
       "      <td>Barsapara Cricket Stadium,</td>\n",
       "      <td>10 JAN 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3rd ODI -</td>\n",
       "      <td>INDIA TOUR OF BANGLADESH 2022-23</td>\n",
       "      <td>Zahur Ahmed Chowdhury Stadium,</td>\n",
       "      <td>10 DEC 2022</td>\n",
       "      <td>11:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>INDIA TOUR OF BANGLADESH 2022-23</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur,</td>\n",
       "      <td>7 DEC 2022</td>\n",
       "      <td>11:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>INDIA TOUR OF BANGLADESH 2022-23</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur,</td>\n",
       "      <td>4 DEC 2022</td>\n",
       "      <td>11:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3rd ODI -</td>\n",
       "      <td>INDIA TOUR OF NEW ZEALAND 2022-23</td>\n",
       "      <td>Hagley Oval,</td>\n",
       "      <td>30 NOV 2022</td>\n",
       "      <td>7:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>INDIA TOUR OF NEW ZEALAND 2022-23</td>\n",
       "      <td>Seddon Park,</td>\n",
       "      <td>27 NOV 2022</td>\n",
       "      <td>7:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>INDIA TOUR OF NEW ZEALAND 2022-23</td>\n",
       "      <td>Eden Park,</td>\n",
       "      <td>25 NOV 2022</td>\n",
       "      <td>7:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3rd ODI -</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA 2022</td>\n",
       "      <td>Arun Jaitley Stadium,</td>\n",
       "      <td>11 OCT 2022</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA 2022</td>\n",
       "      <td>JSCA International Stadium Complex,</td>\n",
       "      <td>9 OCT 2022</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA 2022</td>\n",
       "      <td>Bharat Ratna Shri Atal Bihari Vajpayee Ekana C...</td>\n",
       "      <td>6 OCT 2022</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Match_Title                             Series  \\\n",
       "0    3rd ODI -       AUSTRALIA TOUR OF INDIA 2023   \n",
       "1    2nd ODI -       AUSTRALIA TOUR OF INDIA 2023   \n",
       "2    1st ODI -       AUSTRALIA TOUR OF INDIA 2023   \n",
       "3    3rd ODI -  NEW ZEALAND TOUR OF INDIA 2022-23   \n",
       "4    2nd ODI -  NEW ZEALAND TOUR OF INDIA 2022-23   \n",
       "5    1st ODI -  NEW ZEALAND TOUR OF INDIA 2022-23   \n",
       "6    3rd ODI -    SRI LANKA TOUR OF INDIA 2022-23   \n",
       "7    2nd ODI -    SRI LANKA TOUR OF INDIA 2022-23   \n",
       "8    1st ODI -    SRI LANKA TOUR OF INDIA 2022-23   \n",
       "9    3rd ODI -   INDIA TOUR OF BANGLADESH 2022-23   \n",
       "10   2nd ODI -   INDIA TOUR OF BANGLADESH 2022-23   \n",
       "11   1st ODI -   INDIA TOUR OF BANGLADESH 2022-23   \n",
       "12   3rd ODI -  INDIA TOUR OF NEW ZEALAND 2022-23   \n",
       "13   2nd ODI -  INDIA TOUR OF NEW ZEALAND 2022-23   \n",
       "14   1st ODI -  INDIA TOUR OF NEW ZEALAND 2022-23   \n",
       "15   3rd ODI -    SOUTH AFRICA TOUR OF INDIA 2022   \n",
       "16   2nd ODI -    SOUTH AFRICA TOUR OF INDIA 2022   \n",
       "17   1st ODI -    SOUTH AFRICA TOUR OF INDIA 2022   \n",
       "\n",
       "                                                Place         Date  \\\n",
       "0                             MA Chidambaram Stadium,  22 MAR 2023   \n",
       "1   Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stadium,  19 MAR 2023   \n",
       "2                                   Wankhede Stadium,  17 MAR 2023   \n",
       "3                             Holkar Cricket Stadium,  24 JAN 2023   \n",
       "4   Shaheed Veer Narayan Singh International Crick...  21 JAN 2023   \n",
       "5                 Rajiv Gandhi International Stadium,  18 JAN 2023   \n",
       "6                   Greenfield International Stadium,  15 JAN 2023   \n",
       "7                                       Eden Gardens,  12 JAN 2023   \n",
       "8                          Barsapara Cricket Stadium,  10 JAN 2023   \n",
       "9                      Zahur Ahmed Chowdhury Stadium,  10 DEC 2022   \n",
       "10             Shere Bangla National Stadium, Mirpur,   7 DEC 2022   \n",
       "11             Shere Bangla National Stadium, Mirpur,   4 DEC 2022   \n",
       "12                                       Hagley Oval,  30 NOV 2022   \n",
       "13                                       Seddon Park,  27 NOV 2022   \n",
       "14                                         Eden Park,  25 NOV 2022   \n",
       "15                              Arun Jaitley Stadium,  11 OCT 2022   \n",
       "16                JSCA International Stadium Complex,   9 OCT 2022   \n",
       "17  Bharat Ratna Shri Atal Bihari Vajpayee Ekana C...   6 OCT 2022   \n",
       "\n",
       "            Time  \n",
       "0    1:30 PM IST  \n",
       "1    1:30 PM IST  \n",
       "2    1:30 PM IST  \n",
       "3    1:30 PM IST  \n",
       "4    1:30 PM IST  \n",
       "5    1:30 PM IST  \n",
       "6    1:30 PM IST  \n",
       "7    1:30 PM IST  \n",
       "8    1:30 PM IST  \n",
       "9   11:30 AM IST  \n",
       "10  11:30 AM IST  \n",
       "11  11:30 AM IST  \n",
       "12   7:00 AM IST  \n",
       "13   7:00 AM IST  \n",
       "14   7:00 AM IST  \n",
       "15   1:30 PM IST  \n",
       "16   1:30 PM IST  \n",
       "17   2:00 PM IST  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Match_Title':match,'Series':series,'Place':place,'Date':date,'Time':time})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6dad4b",
   "metadata": {},
   "source": [
    "# 3. Scrape the details of State-wise GDP ofIndia from statisticstime.com.Url = http://statisticstimes.com/You have to find following details:A) Rank B) State C) GSDP(18-19)- at current prices D) GSDP(19-20)- at current prices E) Share(18-19) F) GDP($ billion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "481861e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8f40f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b33e45ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('http://statisticstimes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bef8a922",
   "metadata": {},
   "outputs": [],
   "source": [
    "eco = driver.find_element(By.CLASS_NAME,\"dropbtn\")\n",
    "eco.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41b776c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3c9cda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank =[]\n",
    "\n",
    "ranks = driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"][1]/tbody/tr/td[1]')\n",
    "for i in ranks[0:33]:\n",
    "    rank.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2246a9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "feb6271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = []\n",
    "\n",
    "states=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"][1]/tbody/tr/td[2]')\n",
    "for i in states[0:33]:\n",
    "    state.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6a424f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Maharashtra',\n",
       " 'Tamil Nadu',\n",
       " 'Uttar Pradesh',\n",
       " 'Gujarat',\n",
       " 'Karnataka',\n",
       " 'West Bengal',\n",
       " 'Rajasthan',\n",
       " 'Andhra Pradesh',\n",
       " 'Telangana',\n",
       " 'Madhya Pradesh',\n",
       " 'Kerala',\n",
       " 'Delhi',\n",
       " 'Haryana',\n",
       " 'Bihar',\n",
       " 'Punjab',\n",
       " 'Odisha',\n",
       " 'Assam',\n",
       " 'Chhattisgarh',\n",
       " 'Jharkhand',\n",
       " 'Uttarakhand',\n",
       " 'Jammu & Kashmir',\n",
       " 'Himachal Pradesh',\n",
       " 'Goa',\n",
       " 'Tripura',\n",
       " 'Chandigarh',\n",
       " 'Puducherry',\n",
       " 'Meghalaya',\n",
       " 'Sikkim',\n",
       " 'Manipur',\n",
       " 'Nagaland',\n",
       " 'Arunachal Pradesh',\n",
       " 'Mizoram',\n",
       " 'Andaman & Nicobar Islands']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34ebbe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "GSDP = []\n",
    "\n",
    "gsdp=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"][1]/tbody/tr/td[4]')\n",
    "for i in gsdp[0:33]:\n",
    "    GSDP.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3ecb683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,632,792',\n",
       " '1,630,208',\n",
       " '1,584,764',\n",
       " '1,502,899',\n",
       " '1,493,127',\n",
       " '1,089,898',\n",
       " '942,586',\n",
       " '862,957',\n",
       " '861,031',\n",
       " '809,592',\n",
       " '781,653',\n",
       " '774,870',\n",
       " '734,163',\n",
       " '530,363',\n",
       " '526,376',\n",
       " '487,805',\n",
       " '315,881',\n",
       " '304,063',\n",
       " '297,204',\n",
       " '245,895',\n",
       " '155,956',\n",
       " '153,845',\n",
       " '73,170',\n",
       " '49,845',\n",
       " '42,114',\n",
       " '34,433',\n",
       " '33,481',\n",
       " '28,723',\n",
       " '27,870',\n",
       " '27,283',\n",
       " '24,603',\n",
       " '22,287',\n",
       " '-']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GSDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30bd2b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "share=[]\n",
    "\n",
    "shares=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"][1]/tbody/tr/td[5]')\n",
    "for i in shares[0:33]:\n",
    "    share.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "513b5caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['13.94%',\n",
       " '8.63%',\n",
       " '8.39%',\n",
       " '7.96%',\n",
       " '7.91%',\n",
       " '5.77%',\n",
       " '4.99%',\n",
       " '4.57%',\n",
       " '4.56%',\n",
       " '4.29%',\n",
       " '4.14%',\n",
       " '4.10%',\n",
       " '3.89%',\n",
       " '2.81%',\n",
       " '2.79%',\n",
       " '2.58%',\n",
       " '1.67%',\n",
       " '1.61%',\n",
       " '1.57%',\n",
       " '1.30%',\n",
       " '0.83%',\n",
       " '0.81%',\n",
       " '0.39%',\n",
       " '0.26%',\n",
       " '0.22%',\n",
       " '0.18%',\n",
       " '0.18%',\n",
       " '0.15%',\n",
       " '0.15%',\n",
       " '0.14%',\n",
       " '0.13%',\n",
       " '0.12%',\n",
       " '-']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4b18e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GSD=[]\n",
    "\n",
    "gsd=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"][1]/tbody/tr/td[7]')\n",
    "for i in gsd[0:33]:\n",
    "    GSD.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85559123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-',\n",
       " '1,312,929',\n",
       " '1,166,817',\n",
       " '-',\n",
       " '1,156,039',\n",
       " '793,223',\n",
       " '711,627',\n",
       " '672,018',\n",
       " '663,258',\n",
       " '561,801',\n",
       " '-',\n",
       " '634,408',\n",
       " '572,240',\n",
       " '414,977',\n",
       " '418,868',\n",
       " '396,499',\n",
       " '-',\n",
       " '243,477',\n",
       " '240,036',\n",
       " '-',\n",
       " '-',\n",
       " '124,403',\n",
       " '63,408',\n",
       " '40,583',\n",
       " '-',\n",
       " '25,093',\n",
       " '26,695',\n",
       " '20,017',\n",
       " '20,673',\n",
       " '-',\n",
       " '-',\n",
       " '18,797',\n",
       " '-']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c898b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP=[]\n",
    "\n",
    "gdp=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"][1]/tbody/tr/td[6]')\n",
    "for i in gdp[0:33]:\n",
    "    GDP.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97b6cde0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['399.921',\n",
       " '247.629',\n",
       " '240.726',\n",
       " '228.290',\n",
       " '226.806',\n",
       " '165.556',\n",
       " '143.179',\n",
       " '131.083',\n",
       " '130.791',\n",
       " '122.977',\n",
       " '118.733',\n",
       " '117.703',\n",
       " '111.519',\n",
       " '80.562',\n",
       " '79.957',\n",
       " '74.098',\n",
       " '47.982',\n",
       " '46.187',\n",
       " '45.145',\n",
       " '37.351',\n",
       " '23.690',\n",
       " '23.369',\n",
       " '11.115',\n",
       " '7.571',\n",
       " '6.397',\n",
       " '5.230',\n",
       " '5.086',\n",
       " '4.363',\n",
       " '4.233',\n",
       " '4.144',\n",
       " '3.737',\n",
       " '3.385',\n",
       " '-']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f7335d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(18-19)- at current prices</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,312,929</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,166,817</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,156,039</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>793,223</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>711,627</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>672,018</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>663,258</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>561,801</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>634,408</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>572,240</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>414,977</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>418,868</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>396,499</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>243,477</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>240,036</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>124,403</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>63,408</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>40,583</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>25,093</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>26,695</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>20,017</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>20,673</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>18,797</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(18-19)- at current prices  \\\n",
       "0     1                Maharashtra                              -   \n",
       "1     2                 Tamil Nadu                      1,312,929   \n",
       "2     3              Uttar Pradesh                      1,166,817   \n",
       "3     4                    Gujarat                              -   \n",
       "4     5                  Karnataka                      1,156,039   \n",
       "5     6                West Bengal                        793,223   \n",
       "6     7                  Rajasthan                        711,627   \n",
       "7     8             Andhra Pradesh                        672,018   \n",
       "8     9                  Telangana                        663,258   \n",
       "9    10             Madhya Pradesh                        561,801   \n",
       "10   11                     Kerala                              -   \n",
       "11   12                      Delhi                        634,408   \n",
       "12   13                    Haryana                        572,240   \n",
       "13   14                      Bihar                        414,977   \n",
       "14   15                     Punjab                        418,868   \n",
       "15   16                     Odisha                        396,499   \n",
       "16   17                      Assam                              -   \n",
       "17   18               Chhattisgarh                        243,477   \n",
       "18   19                  Jharkhand                        240,036   \n",
       "19   20                Uttarakhand                              -   \n",
       "20   21            Jammu & Kashmir                              -   \n",
       "21   22           Himachal Pradesh                        124,403   \n",
       "22   23                        Goa                         63,408   \n",
       "23   24                    Tripura                         40,583   \n",
       "24   25                 Chandigarh                              -   \n",
       "25   26                 Puducherry                         25,093   \n",
       "26   27                  Meghalaya                         26,695   \n",
       "27   28                     Sikkim                         20,017   \n",
       "28   29                    Manipur                         20,673   \n",
       "29   30                   Nagaland                              -   \n",
       "30   31          Arunachal Pradesh                              -   \n",
       "31   32                    Mizoram                         18,797   \n",
       "32   33  Andaman & Nicobar Islands                              -   \n",
       "\n",
       "   Share(18-19) GDP($ billion)  \n",
       "0        13.94%        399.921  \n",
       "1         8.63%        247.629  \n",
       "2         8.39%        240.726  \n",
       "3         7.96%        228.290  \n",
       "4         7.91%        226.806  \n",
       "5         5.77%        165.556  \n",
       "6         4.99%        143.179  \n",
       "7         4.57%        131.083  \n",
       "8         4.56%        130.791  \n",
       "9         4.29%        122.977  \n",
       "10        4.14%        118.733  \n",
       "11        4.10%        117.703  \n",
       "12        3.89%        111.519  \n",
       "13        2.81%         80.562  \n",
       "14        2.79%         79.957  \n",
       "15        2.58%         74.098  \n",
       "16        1.67%         47.982  \n",
       "17        1.61%         46.187  \n",
       "18        1.57%         45.145  \n",
       "19        1.30%         37.351  \n",
       "20        0.83%         23.690  \n",
       "21        0.81%         23.369  \n",
       "22        0.39%         11.115  \n",
       "23        0.26%          7.571  \n",
       "24        0.22%          6.397  \n",
       "25        0.18%          5.230  \n",
       "26        0.18%          5.086  \n",
       "27        0.15%          4.363  \n",
       "28        0.15%          4.233  \n",
       "29        0.14%          4.144  \n",
       "30        0.13%          3.737  \n",
       "31        0.12%          3.385  \n",
       "32            -              -  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Rank':rank,'State':state,'GSDP(18-19)- at current prices':GSDP,'GSDP(18-19)- at current prices':GSD,'Share(18-19)':share,'GDP($ billion)':GDP})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fcfae2",
   "metadata": {},
   "source": [
    "# 4. Scrape the details of trending repositories on Github.com. Url = https://github.com/ You have to find the following details:A) Repository title B) Repository description C) Contributors count D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b4344d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "934dc803",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1ff1437",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://github.com/ ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87664183",
   "metadata": {},
   "outputs": [],
   "source": [
    "expl = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div[3]/nav/a[5]')\n",
    "expl.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5872ac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "trend = driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/main/div[1]/nav/div/a[3]')\n",
    "trend.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01081e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = []\n",
    "\n",
    "repo = driver.find_elements(By.XPATH,'//h2[@class=\"h3 lh-condensed\"]')\n",
    "for i in repo:\n",
    "    repos.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cae097b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xtekky / gpt4free',\n",
       " 'mitsuhiko / rye',\n",
       " 'sindresorhus / awesome',\n",
       " 'Josh-XT / Agent-LLM',\n",
       " 'whoiskatrin / chart-gpt',\n",
       " 'Snaacky / dndserver',\n",
       " 'lvwzhen / law-cn-ai',\n",
       " 'GreyDGL / PentestGPT',\n",
       " 'BigBrotherTrade / trader',\n",
       " 'Dogtiti / AutoGPT-Next-Web',\n",
       " 'Developer-Y / cs-video-courses',\n",
       " 'roboflow / notebooks',\n",
       " 'gmpetrov / databerry',\n",
       " 'GitSquared / edex-ui',\n",
       " 'suno-ai / bark',\n",
       " 'xtekky / chatgpt-clone',\n",
       " 'l15y / wenda',\n",
       " 'Eugeny / tabby',\n",
       " 'isaiahbjork / Auto-GPT-MetaTrader-Plugin',\n",
       " 'bullet-train-co / bullet_train',\n",
       " 'modal-labs / quillman',\n",
       " 'bethylamine / twitter-archives',\n",
       " 'BloopAI / bloop',\n",
       " 'zhayujie / chatgpt-on-wechat',\n",
       " 'farizrahman4u / loopgpt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "000434d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=[]\n",
    "\n",
    "urls=driver.find_elements(By.XPATH,'//h2[@class=\"h3 lh-condensed\"]/a')\n",
    "for i in urls:\n",
    "    url.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7305879f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/xtekky/gpt4free',\n",
       " 'https://github.com/mitsuhiko/rye',\n",
       " 'https://github.com/sindresorhus/awesome',\n",
       " 'https://github.com/Josh-XT/Agent-LLM',\n",
       " 'https://github.com/whoiskatrin/chart-gpt',\n",
       " 'https://github.com/Snaacky/dndserver',\n",
       " 'https://github.com/lvwzhen/law-cn-ai',\n",
       " 'https://github.com/GreyDGL/PentestGPT',\n",
       " 'https://github.com/BigBrotherTrade/trader',\n",
       " 'https://github.com/Dogtiti/AutoGPT-Next-Web',\n",
       " 'https://github.com/Developer-Y/cs-video-courses',\n",
       " 'https://github.com/roboflow/notebooks',\n",
       " 'https://github.com/gmpetrov/databerry',\n",
       " 'https://github.com/GitSquared/edex-ui',\n",
       " 'https://github.com/suno-ai/bark',\n",
       " 'https://github.com/xtekky/chatgpt-clone',\n",
       " 'https://github.com/l15y/wenda',\n",
       " 'https://github.com/Eugeny/tabby',\n",
       " 'https://github.com/isaiahbjork/Auto-GPT-MetaTrader-Plugin',\n",
       " 'https://github.com/bullet-train-co/bullet_train',\n",
       " 'https://github.com/modal-labs/quillman',\n",
       " 'https://github.com/bethylamine/twitter-archives',\n",
       " 'https://github.com/BloopAI/bloop',\n",
       " 'https://github.com/zhayujie/chatgpt-on-wechat',\n",
       " 'https://github.com/farizrahman4u/loopgpt']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c860516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONT = []\n",
    "\n",
    "for i in url:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        contrb=driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/main/turbo-frame/div/div/div/div[2]/div[2]/div/div[6]/div/h2/a/span')\n",
    "        CONT.append(contrb.text)\n",
    "    except NoSuchElementException :\n",
    "        CONT.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10ff02bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-',\n",
       " '-',\n",
       " '-',\n",
       " '10',\n",
       " '2',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '3',\n",
       " '-',\n",
       " '-',\n",
       " '4',\n",
       " '60',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '38',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f7a078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG = []\n",
    "\n",
    "for i in url:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        lang=driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/main/turbo-frame/div/div/div/div[2]/div[2]/div/div[7]/div/ul/li[1]/a/span[1]')\n",
    "        LANG.append(lang.text)\n",
    "    except NoSuchElementException :\n",
    "        LANG.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "287e47b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-',\n",
       " '-',\n",
       " '-',\n",
       " 'Python',\n",
       " 'TypeScript',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " 'TypeScript',\n",
       " '-',\n",
       " '-',\n",
       " 'TypeScript',\n",
       " 'JavaScript',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LANG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7699e176",
   "metadata": {},
   "outputs": [],
   "source": [
    "DESC = []\n",
    "\n",
    "for i in url:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        des=driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/main/turbo-frame/div/div/div/div[2]/div[2]/div/div[1]/div/p')\n",
    "        DESC.append(des.text)\n",
    "    except NoSuchElementException :\n",
    "        DESC.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3c3645b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"decentralising the Ai Industry, free gpt-4/3.5 scripts through several reverse engineered api's ( poe.com, phind.com, chat.openai.com, phind.com, writesonic.com, sqlchat.ai, t3nsor.com, you.com etc...)\",\n",
       " 'an experimental alternative to poetry/pip/pipenv/pyenv/venv/virtualenv/pdm/hatch/…',\n",
       " '😎 Awesome lists about all kinds of interesting topics',\n",
       " 'An Artificial Intelligence Automation Platform. AI Instruction management from various providers, has an adaptive memory, and a versatile plugin system with many commands including web browsing. Supports many AI providers and models and growing support every day.',\n",
       " 'AI tool to build charts based on text input',\n",
       " 'Dark and Darker private server implementation written in Python',\n",
       " '⚖️ AI 法律助手',\n",
       " 'A GPT-empowered penetration testing tool',\n",
       " '交易模块',\n",
       " '🤖 Assemble, configure, and deploy autonomous AI Agents in your browser.一键免费部署你的私人AutoGPT 网页应用',\n",
       " 'List of Computer Science courses with video lectures.',\n",
       " 'Examples and tutorials on using SOTA computer vision models and techniques. Learn everything from old-school ResNet, through YOLO and object-detection transformers like DETR, to the latest models like Grounding DINO and SAM.',\n",
       " 'The no-code platform for connecting custom data to large language models',\n",
       " 'A cross-platform, customizable science fiction terminal emulator with advanced monitoring & touchscreen support.',\n",
       " '🔊 Text-Prompted Generative Audio Model',\n",
       " 'ChatGPT interface with better UI',\n",
       " '闻达：一个LLM调用平台。为小模型外挂知识库查找和设计自动执行动作，实现不亚于于大模型的生成能力',\n",
       " 'A terminal for a more modern age',\n",
       " '-',\n",
       " 'The Open Source Ruby on Rails SaaS Template',\n",
       " 'A chat app that transcribes audio in real-time, streams back a response from a language model, and synthesizes this response as natural-sounding speech.',\n",
       " 'A collection of archived stuff from Twitter',\n",
       " 'bloop is a fast code search engine written in Rust.',\n",
       " 'Wechat robot based on ChatGPT, which using OpenAI api and itchat library. 使用ChatGPT搭建微信聊天机器人，基于GPT3.5/4.0 API和itchat实现，能处理文本、语音和图片，访问操作系统和互联网。',\n",
       " 'Modular Auto-GPT Framework']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5486336a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xtekky / gpt4free</td>\n",
       "      <td>decentralising the Ai Industry, free gpt-4/3.5...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mitsuhiko / rye</td>\n",
       "      <td>an experimental alternative to poetry/pip/pipe...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sindresorhus / awesome</td>\n",
       "      <td>😎 Awesome lists about all kinds of interesting...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Josh-XT / Agent-LLM</td>\n",
       "      <td>An Artificial Intelligence Automation Platform...</td>\n",
       "      <td>10</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>whoiskatrin / chart-gpt</td>\n",
       "      <td>AI tool to build charts based on text input</td>\n",
       "      <td>2</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Snaacky / dndserver</td>\n",
       "      <td>Dark and Darker private server implementation ...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lvwzhen / law-cn-ai</td>\n",
       "      <td>⚖️ AI 法律助手</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GreyDGL / PentestGPT</td>\n",
       "      <td>A GPT-empowered penetration testing tool</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BigBrotherTrade / trader</td>\n",
       "      <td>交易模块</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dogtiti / AutoGPT-Next-Web</td>\n",
       "      <td>🤖 Assemble, configure, and deploy autonomous A...</td>\n",
       "      <td>3</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Developer-Y / cs-video-courses</td>\n",
       "      <td>List of Computer Science courses with video le...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>roboflow / notebooks</td>\n",
       "      <td>Examples and tutorials on using SOTA computer ...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gmpetrov / databerry</td>\n",
       "      <td>The no-code platform for connecting custom dat...</td>\n",
       "      <td>4</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GitSquared / edex-ui</td>\n",
       "      <td>A cross-platform, customizable science fiction...</td>\n",
       "      <td>60</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>suno-ai / bark</td>\n",
       "      <td>🔊 Text-Prompted Generative Audio Model</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>xtekky / chatgpt-clone</td>\n",
       "      <td>ChatGPT interface with better UI</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>l15y / wenda</td>\n",
       "      <td>闻达：一个LLM调用平台。为小模型外挂知识库查找和设计自动执行动作，实现不亚于于大模型的生成能力</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Eugeny / tabby</td>\n",
       "      <td>A terminal for a more modern age</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>isaiahbjork / Auto-GPT-MetaTrader-Plugin</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bullet-train-co / bullet_train</td>\n",
       "      <td>The Open Source Ruby on Rails SaaS Template</td>\n",
       "      <td>38</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>modal-labs / quillman</td>\n",
       "      <td>A chat app that transcribes audio in real-time...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bethylamine / twitter-archives</td>\n",
       "      <td>A collection of archived stuff from Twitter</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BloopAI / bloop</td>\n",
       "      <td>bloop is a fast code search engine written in ...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>zhayujie / chatgpt-on-wechat</td>\n",
       "      <td>Wechat robot based on ChatGPT, which using Ope...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>farizrahman4u / loopgpt</td>\n",
       "      <td>Modular Auto-GPT Framework</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Repository title  \\\n",
       "0                          xtekky / gpt4free   \n",
       "1                            mitsuhiko / rye   \n",
       "2                     sindresorhus / awesome   \n",
       "3                        Josh-XT / Agent-LLM   \n",
       "4                    whoiskatrin / chart-gpt   \n",
       "5                        Snaacky / dndserver   \n",
       "6                        lvwzhen / law-cn-ai   \n",
       "7                       GreyDGL / PentestGPT   \n",
       "8                   BigBrotherTrade / trader   \n",
       "9                 Dogtiti / AutoGPT-Next-Web   \n",
       "10            Developer-Y / cs-video-courses   \n",
       "11                      roboflow / notebooks   \n",
       "12                      gmpetrov / databerry   \n",
       "13                      GitSquared / edex-ui   \n",
       "14                            suno-ai / bark   \n",
       "15                    xtekky / chatgpt-clone   \n",
       "16                              l15y / wenda   \n",
       "17                            Eugeny / tabby   \n",
       "18  isaiahbjork / Auto-GPT-MetaTrader-Plugin   \n",
       "19            bullet-train-co / bullet_train   \n",
       "20                     modal-labs / quillman   \n",
       "21            bethylamine / twitter-archives   \n",
       "22                           BloopAI / bloop   \n",
       "23              zhayujie / chatgpt-on-wechat   \n",
       "24                   farizrahman4u / loopgpt   \n",
       "\n",
       "                               Repository description Contributors count  \\\n",
       "0   decentralising the Ai Industry, free gpt-4/3.5...                  -   \n",
       "1   an experimental alternative to poetry/pip/pipe...                  -   \n",
       "2   😎 Awesome lists about all kinds of interesting...                  -   \n",
       "3   An Artificial Intelligence Automation Platform...                 10   \n",
       "4         AI tool to build charts based on text input                  2   \n",
       "5   Dark and Darker private server implementation ...                  -   \n",
       "6                                          ⚖️ AI 法律助手                  -   \n",
       "7            A GPT-empowered penetration testing tool                  -   \n",
       "8                                                交易模块                  -   \n",
       "9   🤖 Assemble, configure, and deploy autonomous A...                  3   \n",
       "10  List of Computer Science courses with video le...                  -   \n",
       "11  Examples and tutorials on using SOTA computer ...                  -   \n",
       "12  The no-code platform for connecting custom dat...                  4   \n",
       "13  A cross-platform, customizable science fiction...                 60   \n",
       "14             🔊 Text-Prompted Generative Audio Model                  -   \n",
       "15                   ChatGPT interface with better UI                  -   \n",
       "16   闻达：一个LLM调用平台。为小模型外挂知识库查找和设计自动执行动作，实现不亚于于大模型的生成能力                  -   \n",
       "17                   A terminal for a more modern age                  -   \n",
       "18                                                  -                  -   \n",
       "19        The Open Source Ruby on Rails SaaS Template                 38   \n",
       "20  A chat app that transcribes audio in real-time...                  -   \n",
       "21        A collection of archived stuff from Twitter                  -   \n",
       "22  bloop is a fast code search engine written in ...                  -   \n",
       "23  Wechat robot based on ChatGPT, which using Ope...                  -   \n",
       "24                         Modular Auto-GPT Framework                  -   \n",
       "\n",
       "   Language used  \n",
       "0              -  \n",
       "1              -  \n",
       "2              -  \n",
       "3         Python  \n",
       "4     TypeScript  \n",
       "5              -  \n",
       "6              -  \n",
       "7              -  \n",
       "8              -  \n",
       "9     TypeScript  \n",
       "10             -  \n",
       "11             -  \n",
       "12    TypeScript  \n",
       "13    JavaScript  \n",
       "14             -  \n",
       "15             -  \n",
       "16             -  \n",
       "17             -  \n",
       "18             -  \n",
       "19             -  \n",
       "20             -  \n",
       "21             -  \n",
       "22             -  \n",
       "23             -  \n",
       "24             -  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Repository title':repos,'Repository description':DESC,'Contributors count':CONT,'Language used':LANG})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7aa689d",
   "metadata": {},
   "source": [
    "# 5. Scrape the details of top 100 songs on billiboard.com.Url = https:/www.billboard.com/ You have to find the following details:A) Song name B) Artist name C) Last week rank D) Peak rank E) Weeks on board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f87a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aded8338",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2882f39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https:/www.billboard.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ec4a5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart=driver.find_element(By.XPATH,'/html/body/div[3]/div[9]/div/div/div/ul/li[1]/h3/a')\n",
    "chart.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34467040",
   "metadata": {},
   "outputs": [],
   "source": [
    "billi = driver.find_element(By.XPATH,'/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[1]/div[1]/div[2]/span/a')\n",
    "billi.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6092da45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kill Bill',\n",
       " 'Last Night',\n",
       " 'Flowers',\n",
       " 'Princess Diana',\n",
       " 'Ella Baila Sola',\n",
       " \"Creepin'\",\n",
       " 'Calm Down',\n",
       " 'Die For You',\n",
       " 'Search & Rescue',\n",
       " \"Boy's A Liar, Pt. 2\",\n",
       " 'Anti-Hero',\n",
       " 'La Bebe',\n",
       " 'Chemical',\n",
       " 'Favorite Song',\n",
       " 'Un x100to',\n",
       " 'Players',\n",
       " 'Rock And A Hard Place',\n",
       " 'You Proof',\n",
       " 'Fast Car',\n",
       " 'Sure Thing',\n",
       " 'As It Was',\n",
       " \"Thinkin' Bout Me\",\n",
       " 'Lavender Haze',\n",
       " 'One Thing At A Time',\n",
       " 'Thought You Should Know',\n",
       " \"I'm Good (Blue)\",\n",
       " 'Under The Influence',\n",
       " 'Thank God',\n",
       " 'Something In The Orange',\n",
       " 'Escapism',\n",
       " 'Slut Me Out',\n",
       " 'Por Las Noches',\n",
       " 'Unholy',\n",
       " 'Wait In The Truck',\n",
       " 'PRC',\n",
       " 'Just Wanna Rock',\n",
       " 'Handle On You',\n",
       " \"Dancin' In The Country\",\n",
       " 'Snooze',\n",
       " 'AMG',\n",
       " 'Superhero (Heroes & Villains)',\n",
       " 'TQG',\n",
       " 'Rich Flex',\n",
       " 'Love You Anyway',\n",
       " 'Spin Bout U',\n",
       " 'Next Thing You Know',\n",
       " 'Eyes Closed',\n",
       " 'Daylight',\n",
       " 'Heart Like A Truck',\n",
       " 'Cupid',\n",
       " 'Wild As Her',\n",
       " 'Bebe Dame',\n",
       " 'Bloody Mary',\n",
       " 'Tennessee Orange',\n",
       " 'Fight The Feeling',\n",
       " 'Peaches',\n",
       " 'Low Down',\n",
       " 'Beso',\n",
       " 'El Azul',\n",
       " 'Red Ruby Da Sleeze',\n",
       " \"Ain't That Some\",\n",
       " 'Never Felt So Alone',\n",
       " 'Nonsense',\n",
       " 'Everything I Love',\n",
       " 'See You Again',\n",
       " 'I Wrote The Book',\n",
       " 'Cowgirls',\n",
       " 'Man Made A Bar',\n",
       " 'Ch y La Pizza',\n",
       " 'Need A Favor',\n",
       " 'Yandel 150',\n",
       " 'In Ha Mood',\n",
       " 'Trance',\n",
       " 'ICU',\n",
       " 'El Gordo Trae El Mando',\n",
       " 'All Of The Girls You Loved Before',\n",
       " 'Gold',\n",
       " 'Dogtooth',\n",
       " 'Painting Pictures',\n",
       " 'Ceilings',\n",
       " 'Human',\n",
       " 'Que Vuelvas',\n",
       " 'Strike (Holster)',\n",
       " 'Sunrise',\n",
       " 'Like Crazy',\n",
       " 'Dawns',\n",
       " 'Happy',\n",
       " 'Chanel',\n",
       " 'Forever',\n",
       " 'Igualito A Mi Apa',\n",
       " 'Special',\n",
       " '5 Leaf Clover',\n",
       " 'Bzrp Music Sessions, Vol. 53',\n",
       " 'Heaven',\n",
       " \"Don't Play With It\",\n",
       " 'Memory Lane',\n",
       " 'Love Again',\n",
       " \"'98 Braves\",\n",
       " 'Di Que Si',\n",
       " 'It Matters To Her']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song=[]\n",
    "\n",
    "songs = driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\"]/li[1]')\n",
    "for i in songs:\n",
    "    song.append(i.text.split('\\n')[0])\n",
    "    \n",
    "song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99825dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SZA',\n",
       " 'Morgan Wallen',\n",
       " 'Miley Cyrus',\n",
       " 'Ice Spice & Nicki Minaj',\n",
       " 'Eslabon Armado X Peso Pluma',\n",
       " 'Metro Boomin, The Weeknd & 21 Savage',\n",
       " 'Rema & Selena Gomez',\n",
       " 'The Weeknd & Ariana Grande',\n",
       " 'Drake',\n",
       " 'PinkPantheress & Ice Spice',\n",
       " 'Taylor Swift',\n",
       " 'Yng Lvcas x Peso Pluma',\n",
       " 'Post Malone',\n",
       " 'Toosii',\n",
       " 'Grupo Frontera X Bad Bunny',\n",
       " 'Coi Leray',\n",
       " 'Bailey Zimmerman',\n",
       " 'Morgan Wallen',\n",
       " 'Luke Combs',\n",
       " 'Miguel',\n",
       " 'Harry Styles',\n",
       " 'Morgan Wallen',\n",
       " 'Taylor Swift',\n",
       " 'Morgan Wallen',\n",
       " 'Morgan Wallen',\n",
       " 'David Guetta & Bebe Rexha',\n",
       " 'Chris Brown',\n",
       " 'Kane Brown With Katelyn Brown',\n",
       " 'Zach Bryan',\n",
       " 'RAYE Featuring 070 Shake',\n",
       " 'NLE Choppa',\n",
       " 'Peso Pluma',\n",
       " 'Sam Smith & Kim Petras',\n",
       " 'HARDY Featuring Lainey Wilson',\n",
       " 'Peso Pluma X Natanael Cano',\n",
       " 'Lil Uzi Vert',\n",
       " 'Parker McCollum',\n",
       " 'Tyler Hubbard',\n",
       " 'SZA',\n",
       " 'Gabito Ballesteros, Peso Pluma & Natanael Cano',\n",
       " 'Metro Boomin, Future & Chris Brown',\n",
       " 'Karol G x Shakira',\n",
       " 'Drake & 21 Savage',\n",
       " 'Luke Combs',\n",
       " 'Drake & 21 Savage',\n",
       " 'Jordan Davis',\n",
       " 'Ed Sheeran',\n",
       " 'David Kushner',\n",
       " 'Lainey Wilson',\n",
       " 'Fifty Fifty',\n",
       " 'Corey Kent',\n",
       " 'Fuerza Regida X Grupo Frontera',\n",
       " 'Lady Gaga',\n",
       " 'Megan Moroney',\n",
       " 'Rod Wave',\n",
       " 'Jack Black',\n",
       " 'Lil Baby',\n",
       " 'Rosalia & Rauw Alejandro',\n",
       " 'Junior H x Peso Pluma',\n",
       " 'Nicki Minaj',\n",
       " 'Morgan Wallen',\n",
       " 'Labrinth',\n",
       " 'Sabrina Carpenter',\n",
       " 'Morgan Wallen',\n",
       " 'Tyler, The Creator Featuring Kali Uchis',\n",
       " 'Morgan Wallen',\n",
       " 'Morgan Wallen Featuring ERNEST',\n",
       " 'Morgan Wallen Featuring Eric Church',\n",
       " 'Fuerza Regida X Natanael Cano',\n",
       " 'Jelly Roll',\n",
       " 'Yandel & Feid',\n",
       " 'Ice Spice',\n",
       " 'Metro Boomin, Travis Scott & Young Thug',\n",
       " 'Coco Jones',\n",
       " 'Chino Pacas',\n",
       " 'Taylor Swift',\n",
       " 'Dierks Bentley',\n",
       " 'Tyler, The Creator',\n",
       " 'Superstar Pride',\n",
       " 'Lizzy McAlpine',\n",
       " 'Cody Johnson',\n",
       " 'Carin Leon X Grupo Frontera',\n",
       " 'Lil Yachty',\n",
       " 'Morgan Wallen',\n",
       " 'Jimin',\n",
       " 'Zach Bryan Featuring Maggie Rogers',\n",
       " 'NF',\n",
       " 'Becky G & Peso Pluma',\n",
       " 'Lil Baby Featuring Fridayy',\n",
       " 'Fuerza Regida & Peso Pluma',\n",
       " 'Lizzo Featuring SZA',\n",
       " 'Luke Combs',\n",
       " 'Bizarrap & Shakira',\n",
       " 'Niall Horan',\n",
       " 'Lola Brooke X Latto X Yung Miami Or Featuring Billy B',\n",
       " 'Old Dominion',\n",
       " 'The Kid LAROI',\n",
       " 'Morgan Wallen',\n",
       " 'Grupo Marca Registrada X Grupo Frontera',\n",
       " 'Scotty McCreery']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist=[]\n",
    "\n",
    "artists = driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\"]/li[1]')\n",
    "for i in artists:\n",
    "    artist.append(i.text.split('\\n')[1])\n",
    "    \n",
    "artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22e02e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(song),len(artist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4a5db9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4',\n",
       " '1',\n",
       " '3',\n",
       " '-',\n",
       " '10',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '2',\n",
       " '8',\n",
       " '9',\n",
       " '17',\n",
       " '-',\n",
       " '14',\n",
       " '-',\n",
       " '12',\n",
       " '11',\n",
       " '13',\n",
       " '23',\n",
       " '15',\n",
       " '18',\n",
       " '20',\n",
       " '16',\n",
       " '22',\n",
       " '19',\n",
       " '21',\n",
       " '24',\n",
       " '27',\n",
       " '25',\n",
       " '26',\n",
       " '28',\n",
       " '51',\n",
       " '29',\n",
       " '32',\n",
       " '49',\n",
       " '30',\n",
       " '31',\n",
       " '37',\n",
       " '34',\n",
       " '53',\n",
       " '38',\n",
       " '33',\n",
       " '35',\n",
       " '40',\n",
       " '39',\n",
       " '48',\n",
       " '42',\n",
       " '-',\n",
       " '36',\n",
       " '60',\n",
       " '50',\n",
       " '62',\n",
       " '46',\n",
       " '55',\n",
       " '41',\n",
       " '83',\n",
       " '58',\n",
       " '66',\n",
       " '87',\n",
       " '61',\n",
       " '56',\n",
       " '94',\n",
       " '68',\n",
       " '57',\n",
       " '-',\n",
       " '63',\n",
       " '65',\n",
       " '67',\n",
       " '70',\n",
       " '73',\n",
       " '72',\n",
       " '76',\n",
       " '80',\n",
       " '75',\n",
       " '92',\n",
       " '64',\n",
       " '86',\n",
       " '69',\n",
       " '77',\n",
       " '78',\n",
       " '89',\n",
       " '98',\n",
       " '71',\n",
       " '93',\n",
       " '52',\n",
       " '91',\n",
       " '54',\n",
       " '-',\n",
       " '84',\n",
       " '-',\n",
       " '74',\n",
       " '59',\n",
       " '79',\n",
       " '-',\n",
       " '95',\n",
       " '96',\n",
       " '88',\n",
       " '100',\n",
       " '-',\n",
       " '-']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last =[]\n",
    "\n",
    "lasts = driver.find_elements(By.XPATH,'//li[@class=\"o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max\"][1]')\n",
    "for i in lasts:\n",
    "    last.append(i.text)\n",
    "\n",
    "last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "759770c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['19',\n",
       " '12',\n",
       " '14',\n",
       " '1',\n",
       " '5',\n",
       " '20',\n",
       " '33',\n",
       " '38',\n",
       " '2',\n",
       " '11',\n",
       " '26',\n",
       " '5',\n",
       " '1',\n",
       " '9',\n",
       " '1',\n",
       " '16',\n",
       " '45',\n",
       " '49',\n",
       " '4',\n",
       " '38',\n",
       " '55',\n",
       " '7',\n",
       " '26',\n",
       " '20',\n",
       " '36',\n",
       " '34',\n",
       " '32',\n",
       " '32',\n",
       " '52',\n",
       " '20',\n",
       " '5',\n",
       " '6',\n",
       " '30',\n",
       " '33',\n",
       " '10',\n",
       " '27',\n",
       " '16',\n",
       " '9',\n",
       " '19',\n",
       " '13',\n",
       " '20',\n",
       " '8',\n",
       " '24',\n",
       " '10',\n",
       " '24',\n",
       " '13',\n",
       " '4',\n",
       " '1',\n",
       " '23',\n",
       " '5',\n",
       " '28',\n",
       " '17',\n",
       " '16',\n",
       " '19',\n",
       " '3',\n",
       " '2',\n",
       " '5',\n",
       " '4',\n",
       " '2',\n",
       " '7',\n",
       " '7',\n",
       " '2',\n",
       " '14',\n",
       " '12',\n",
       " '1',\n",
       " '12',\n",
       " '7',\n",
       " '7',\n",
       " '4',\n",
       " '3',\n",
       " '10',\n",
       " '11',\n",
       " '11',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '7',\n",
       " '4',\n",
       " '10',\n",
       " '9',\n",
       " '12',\n",
       " '17',\n",
       " '2',\n",
       " '7',\n",
       " '4',\n",
       " '12',\n",
       " '2',\n",
       " '1',\n",
       " '15',\n",
       " '1',\n",
       " '10',\n",
       " '5',\n",
       " '14',\n",
       " '7',\n",
       " '4',\n",
       " '3',\n",
       " '12',\n",
       " '7',\n",
       " '1',\n",
       " '1']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "week=[]\n",
    "\n",
    "weeks=driver.find_elements(By.XPATH,'//li[@class=\"o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max\"][2]')\n",
    "for i in weeks:\n",
    "    week.append(i.text)\n",
    "    \n",
    "week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61b4fc83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '1',\n",
       " '1',\n",
       " '4',\n",
       " '5',\n",
       " '3',\n",
       " '6',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '1',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '9',\n",
       " '10',\n",
       " '5',\n",
       " '19',\n",
       " '15',\n",
       " '1',\n",
       " '9',\n",
       " '2',\n",
       " '10',\n",
       " '7',\n",
       " '4',\n",
       " '12',\n",
       " '13',\n",
       " '10',\n",
       " '22',\n",
       " '28',\n",
       " '32',\n",
       " '1',\n",
       " '23',\n",
       " '35',\n",
       " '10',\n",
       " '31',\n",
       " '37',\n",
       " '29',\n",
       " '40',\n",
       " '8',\n",
       " '7',\n",
       " '2',\n",
       " '15',\n",
       " '5',\n",
       " '46',\n",
       " '26',\n",
       " '48',\n",
       " '29',\n",
       " '50',\n",
       " '50',\n",
       " '25',\n",
       " '41',\n",
       " '53',\n",
       " '16',\n",
       " '56',\n",
       " '50',\n",
       " '52',\n",
       " '59',\n",
       " '13',\n",
       " '11',\n",
       " '62',\n",
       " '56',\n",
       " '14',\n",
       " '65',\n",
       " '18',\n",
       " '40',\n",
       " '15',\n",
       " '69',\n",
       " '70',\n",
       " '71',\n",
       " '58',\n",
       " '42',\n",
       " '74',\n",
       " '75',\n",
       " '12',\n",
       " '77',\n",
       " '33',\n",
       " '25',\n",
       " '54',\n",
       " '81',\n",
       " '50',\n",
       " '71',\n",
       " '30',\n",
       " '1',\n",
       " '42',\n",
       " '54',\n",
       " '88',\n",
       " '8',\n",
       " '90',\n",
       " '52',\n",
       " '33',\n",
       " '9',\n",
       " '62',\n",
       " '69',\n",
       " '96',\n",
       " '40',\n",
       " '27',\n",
       " '99',\n",
       " '100']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak =[]\n",
    "\n",
    "peaks=driver.find_elements(By.XPATH,'//li[@class=\"o-chart-results-list__item // a-chart-bg-color a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-background-color-grey-lightest lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-hidden@mobile-max\"][2]')\n",
    "for i in peaks:\n",
    "    peak.append(i.text)\n",
    "    \n",
    "peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca8aefdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song name</th>\n",
       "      <th>Artist name</th>\n",
       "      <th>Last week rank</th>\n",
       "      <th>Peak rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kill Bill</td>\n",
       "      <td>SZA</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Last Night</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Princess Diana</td>\n",
       "      <td>Ice Spice &amp; Nicki Minaj</td>\n",
       "      <td>-</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ella Baila Sola</td>\n",
       "      <td>Eslabon Armado X Peso Pluma</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Memory Lane</td>\n",
       "      <td>Old Dominion</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Love Again</td>\n",
       "      <td>The Kid LAROI</td>\n",
       "      <td>88</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>'98 Braves</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Di Que Si</td>\n",
       "      <td>Grupo Marca Registrada X Grupo Frontera</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>It Matters To Her</td>\n",
       "      <td>Scotty McCreery</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Song name                              Artist name Last week rank  \\\n",
       "0           Kill Bill                                      SZA              4   \n",
       "1          Last Night                            Morgan Wallen              1   \n",
       "2             Flowers                              Miley Cyrus              3   \n",
       "3      Princess Diana                  Ice Spice & Nicki Minaj              -   \n",
       "4     Ella Baila Sola              Eslabon Armado X Peso Pluma             10   \n",
       "..                ...                                      ...            ...   \n",
       "95        Memory Lane                             Old Dominion             96   \n",
       "96         Love Again                            The Kid LAROI             88   \n",
       "97         '98 Braves                            Morgan Wallen            100   \n",
       "98          Di Que Si  Grupo Marca Registrada X Grupo Frontera              -   \n",
       "99  It Matters To Her                          Scotty McCreery              -   \n",
       "\n",
       "   Peak rank Weeks on board  \n",
       "0          1             19  \n",
       "1          1             12  \n",
       "2          1             14  \n",
       "3          4              1  \n",
       "4          5              5  \n",
       "..       ...            ...  \n",
       "95        96              3  \n",
       "96        40             12  \n",
       "97        27              7  \n",
       "98        99              1  \n",
       "99       100              1  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Song name':song,'Artist name':artist,'Last week rank':last,'Peak rank':peak,'Weeks on board':week})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28cda08",
   "metadata": {},
   "source": [
    "# 6. Scrape the details of Highest sellingnovels. Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-greycompare .You have to find the following details:A) Book name B) Author name C) Volumes sold D) Publisher E) Genre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaa35dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5685a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a13d13bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-greycompare/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e964134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '34',\n",
       " '35',\n",
       " '36',\n",
       " '37',\n",
       " '38',\n",
       " '39',\n",
       " '40',\n",
       " '41',\n",
       " '42',\n",
       " '43',\n",
       " '44',\n",
       " '45',\n",
       " '46',\n",
       " '47',\n",
       " '48',\n",
       " '49',\n",
       " '50',\n",
       " '51',\n",
       " '52',\n",
       " '53',\n",
       " '54',\n",
       " '55',\n",
       " '56',\n",
       " '57',\n",
       " '58',\n",
       " '59',\n",
       " '60',\n",
       " '61',\n",
       " '62',\n",
       " '63',\n",
       " '64',\n",
       " '65',\n",
       " '66',\n",
       " '67',\n",
       " '68',\n",
       " '69',\n",
       " '70',\n",
       " '71',\n",
       " '72',\n",
       " '73',\n",
       " '74',\n",
       " '75',\n",
       " '76',\n",
       " '77',\n",
       " '78',\n",
       " '79',\n",
       " '80',\n",
       " '81',\n",
       " '82',\n",
       " '83',\n",
       " '84',\n",
       " '85',\n",
       " '86',\n",
       " '87',\n",
       " '88',\n",
       " '89',\n",
       " '90',\n",
       " '91',\n",
       " '92',\n",
       " '93',\n",
       " '94',\n",
       " '95',\n",
       " '96',\n",
       " '97',\n",
       " '98',\n",
       " '99',\n",
       " '100']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = []\n",
    "\n",
    "ranks=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[1]')\n",
    "for i in ranks:\n",
    "    rank.append(i.text)\n",
    "    \n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9aad3c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Da Vinci Code,The',\n",
       " 'Harry Potter and the Deathly Hallows',\n",
       " \"Harry Potter and the Philosopher's Stone\",\n",
       " 'Harry Potter and the Order of the Phoenix',\n",
       " 'Fifty Shades of Grey',\n",
       " 'Harry Potter and the Goblet of Fire',\n",
       " 'Harry Potter and the Chamber of Secrets',\n",
       " 'Harry Potter and the Prisoner of Azkaban',\n",
       " 'Angels and Demons',\n",
       " \"Harry Potter and the Half-blood Prince:Children's Edition\",\n",
       " 'Fifty Shades Darker',\n",
       " 'Twilight',\n",
       " 'Girl with the Dragon Tattoo,The:Millennium Trilogy',\n",
       " 'Fifty Shades Freed',\n",
       " 'Lost Symbol,The',\n",
       " 'New Moon',\n",
       " 'Deception Point',\n",
       " 'Eclipse',\n",
       " 'Lovely Bones,The',\n",
       " 'Curious Incident of the Dog in the Night-time,The',\n",
       " 'Digital Fortress',\n",
       " 'Short History of Nearly Everything,A',\n",
       " 'Girl Who Played with Fire,The:Millennium Trilogy',\n",
       " 'Breaking Dawn',\n",
       " 'Very Hungry Caterpillar,The:The Very Hungry Caterpillar',\n",
       " 'Gruffalo,The',\n",
       " \"Jamie's 30-Minute Meals\",\n",
       " 'Kite Runner,The',\n",
       " 'One Day',\n",
       " 'Thousand Splendid Suns,A',\n",
       " \"Girl Who Kicked the Hornets' Nest,The:Millennium Trilogy\",\n",
       " \"Time Traveler's Wife,The\",\n",
       " 'Atonement',\n",
       " \"Bridget Jones's Diary:A Novel\",\n",
       " 'World According to Clarkson,The',\n",
       " \"Captain Corelli's Mandolin\",\n",
       " 'Sound of Laughter,The',\n",
       " 'Life of Pi',\n",
       " 'Billy Connolly',\n",
       " 'Child Called It,A',\n",
       " \"Gruffalo's Child,The\",\n",
       " \"Angela's Ashes:A Memoir of a Childhood\",\n",
       " 'Birdsong',\n",
       " 'Northern Lights:His Dark Materials S.',\n",
       " 'Labyrinth',\n",
       " 'Harry Potter and the Half-blood Prince',\n",
       " 'Help,The',\n",
       " 'Man and Boy',\n",
       " 'Memoirs of a Geisha',\n",
       " \"No.1 Ladies' Detective Agency,The:No.1 Ladies' Detective Agency S.\",\n",
       " 'Island,The',\n",
       " 'PS, I Love You',\n",
       " 'You are What You Eat:The Plan That Will Change Your Life',\n",
       " 'Shadow of the Wind,The',\n",
       " 'Tales of Beedle the Bard,The',\n",
       " 'Broker,The',\n",
       " \"Dr. Atkins' New Diet Revolution:The No-hunger, Luxurious Weight Loss P\",\n",
       " 'Subtle Knife,The:His Dark Materials S.',\n",
       " 'Eats, Shoots and Leaves:The Zero Tolerance Approach to Punctuation',\n",
       " \"Delia's How to Cook:(Bk.1)\",\n",
       " 'Chocolat',\n",
       " 'Boy in the Striped Pyjamas,The',\n",
       " \"My Sister's Keeper\",\n",
       " 'Amber Spyglass,The:His Dark Materials S.',\n",
       " 'To Kill a Mockingbird',\n",
       " 'Men are from Mars, Women are from Venus:A Practical Guide for Improvin',\n",
       " 'Dear Fatty',\n",
       " 'Short History of Tractors in Ukrainian,A',\n",
       " 'Hannibal',\n",
       " 'Lord of the Rings,The',\n",
       " 'Stupid White Men:...and Other Sorry Excuses for the State of the Natio',\n",
       " 'Interpretation of Murder,The',\n",
       " 'Sharon Osbourne Extreme:My Autobiography',\n",
       " 'Alchemist,The:A Fable About Following Your Dream',\n",
       " \"At My Mother's Knee ...:and Other Low Joints\",\n",
       " 'Notes from a Small Island',\n",
       " 'Return of the Naked Chef,The',\n",
       " 'Bridget Jones: The Edge of Reason',\n",
       " \"Jamie's Italy\",\n",
       " 'I Can Make You Thin',\n",
       " 'Down Under',\n",
       " 'Summons,The',\n",
       " 'Small Island',\n",
       " 'Nigella Express',\n",
       " 'Brick Lane',\n",
       " \"Memory Keeper's Daughter,The\",\n",
       " 'Room on the Broom',\n",
       " 'About a Boy',\n",
       " 'My Booky Wook',\n",
       " 'God Delusion,The',\n",
       " '\"Beano\" Annual,The',\n",
       " 'White Teeth',\n",
       " 'House at Riverton,The',\n",
       " 'Book Thief,The',\n",
       " 'Nights of Rain and Stars',\n",
       " 'Ghost,The',\n",
       " 'Happy Days with the Naked Chef',\n",
       " 'Hunger Games,The:Hunger Games Trilogy',\n",
       " \"Lost Boy,The:A Foster Child's Search for the Love of a Family\",\n",
       " \"Jamie's Ministry of Food:Anyone Can Learn to Cook in 24 Hours\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book = []\n",
    "\n",
    "books=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[2]')\n",
    "for i in books:\n",
    "    book.append(i.text)\n",
    "    \n",
    "book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5711d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brown, Dan',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'James, E. L.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Brown, Dan',\n",
       " 'Rowling, J.K.',\n",
       " 'James, E. L.',\n",
       " 'Meyer, Stephenie',\n",
       " 'Larsson, Stieg',\n",
       " 'James, E. L.',\n",
       " 'Brown, Dan',\n",
       " 'Meyer, Stephenie',\n",
       " 'Brown, Dan',\n",
       " 'Meyer, Stephenie',\n",
       " 'Sebold, Alice',\n",
       " 'Haddon, Mark',\n",
       " 'Brown, Dan',\n",
       " 'Bryson, Bill',\n",
       " 'Larsson, Stieg',\n",
       " 'Meyer, Stephenie',\n",
       " 'Carle, Eric',\n",
       " 'Donaldson, Julia',\n",
       " 'Oliver, Jamie',\n",
       " 'Hosseini, Khaled',\n",
       " 'Nicholls, David',\n",
       " 'Hosseini, Khaled',\n",
       " 'Larsson, Stieg',\n",
       " 'Niffenegger, Audrey',\n",
       " 'McEwan, Ian',\n",
       " 'Fielding, Helen',\n",
       " 'Clarkson, Jeremy',\n",
       " 'Bernieres, Louis de',\n",
       " 'Kay, Peter',\n",
       " 'Martel, Yann',\n",
       " 'Stephenson, Pamela',\n",
       " 'Pelzer, Dave',\n",
       " 'Donaldson, Julia',\n",
       " 'McCourt, Frank',\n",
       " 'Faulks, Sebastian',\n",
       " 'Pullman, Philip',\n",
       " 'Mosse, Kate',\n",
       " 'Rowling, J.K.',\n",
       " 'Stockett, Kathryn',\n",
       " 'Parsons, Tony',\n",
       " 'Golden, Arthur',\n",
       " 'McCall Smith, Alexander',\n",
       " 'Hislop, Victoria',\n",
       " 'Ahern, Cecelia',\n",
       " 'McKeith, Gillian',\n",
       " 'Zafon, Carlos Ruiz',\n",
       " 'Rowling, J.K.',\n",
       " 'Grisham, John',\n",
       " 'Atkins, Robert C.',\n",
       " 'Pullman, Philip',\n",
       " 'Truss, Lynne',\n",
       " 'Smith, Delia',\n",
       " 'Harris, Joanne',\n",
       " 'Boyne, John',\n",
       " 'Picoult, Jodi',\n",
       " 'Pullman, Philip',\n",
       " 'Lee, Harper',\n",
       " 'Gray, John',\n",
       " 'French, Dawn',\n",
       " 'Lewycka, Marina',\n",
       " 'Harris, Thomas',\n",
       " 'Tolkien, J. R. R.',\n",
       " 'Moore, Michael',\n",
       " 'Rubenfeld, Jed',\n",
       " 'Osbourne, Sharon',\n",
       " 'Coelho, Paulo',\n",
       " \"O'Grady, Paul\",\n",
       " 'Bryson, Bill',\n",
       " 'Oliver, Jamie',\n",
       " 'Fielding, Helen',\n",
       " 'Oliver, Jamie',\n",
       " 'McKenna, Paul',\n",
       " 'Bryson, Bill',\n",
       " 'Grisham, John',\n",
       " 'Levy, Andrea',\n",
       " 'Lawson, Nigella',\n",
       " 'Ali, Monica',\n",
       " 'Edwards, Kim',\n",
       " 'Donaldson, Julia',\n",
       " 'Hornby, Nick',\n",
       " 'Brand, Russell',\n",
       " 'Dawkins, Richard',\n",
       " '0',\n",
       " 'Smith, Zadie',\n",
       " 'Morton, Kate',\n",
       " 'Zusak, Markus',\n",
       " 'Binchy, Maeve',\n",
       " 'Harris, Robert',\n",
       " 'Oliver, Jamie',\n",
       " 'Collins, Suzanne',\n",
       " 'Pelzer, Dave',\n",
       " 'Oliver, Jamie']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author = []\n",
    "\n",
    "authors=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[3]')\n",
    "for i in authors:\n",
    "    author.append(i.text)\n",
    "    \n",
    "author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db077f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5,094,805',\n",
       " '4,475,152',\n",
       " '4,200,654',\n",
       " '4,179,479',\n",
       " '3,758,936',\n",
       " '3,583,215',\n",
       " '3,484,047',\n",
       " '3,377,906',\n",
       " '3,193,946',\n",
       " '2,950,264',\n",
       " '2,479,784',\n",
       " '2,315,405',\n",
       " '2,233,570',\n",
       " '2,193,928',\n",
       " '2,183,031',\n",
       " '2,152,737',\n",
       " '2,062,145',\n",
       " '2,052,876',\n",
       " '2,005,598',\n",
       " '1,979,552',\n",
       " '1,928,900',\n",
       " '1,852,919',\n",
       " '1,814,784',\n",
       " '1,787,118',\n",
       " '1,783,535',\n",
       " '1,781,269',\n",
       " '1,743,266',\n",
       " '1,629,119',\n",
       " '1,616,068',\n",
       " '1,583,992',\n",
       " '1,555,135',\n",
       " '1,546,886',\n",
       " '1,539,428',\n",
       " '1,508,205',\n",
       " '1,489,403',\n",
       " '1,352,318',\n",
       " '1,310,207',\n",
       " '1,310,176',\n",
       " '1,231,957',\n",
       " '1,217,712',\n",
       " '1,208,711',\n",
       " '1,204,058',\n",
       " '1,184,967',\n",
       " '1,181,503',\n",
       " '1,181,093',\n",
       " '1,153,181',\n",
       " '1,132,336',\n",
       " '1,130,802',\n",
       " '1,126,337',\n",
       " '1,115,549',\n",
       " '1,108,328',\n",
       " '1,107,379',\n",
       " '1,104,403',\n",
       " '1,092,349',\n",
       " '1,090,847',\n",
       " '1,087,262',\n",
       " '1,054,196',\n",
       " '1,037,160',\n",
       " '1,023,688',\n",
       " '1,015,956',\n",
       " '1,009,873',\n",
       " '1,004,414',\n",
       " '1,003,780',\n",
       " '1,002,314',\n",
       " '998,213',\n",
       " '992,846',\n",
       " '986,753',\n",
       " '986,115',\n",
       " '970,509',\n",
       " '967,466',\n",
       " '963,353',\n",
       " '962,515',\n",
       " '959,496',\n",
       " '956,114',\n",
       " '945,640',\n",
       " '931,312',\n",
       " '925,425',\n",
       " '924,695',\n",
       " '906,968',\n",
       " '905,086',\n",
       " '890,847',\n",
       " '869,671',\n",
       " '869,659',\n",
       " '862,602',\n",
       " '856,540',\n",
       " '845,858',\n",
       " '842,535',\n",
       " '828,215',\n",
       " '820,563',\n",
       " '816,907',\n",
       " '816,585',\n",
       " '815,586',\n",
       " '814,370',\n",
       " '809,641',\n",
       " '808,900',\n",
       " '807,311',\n",
       " '794,201',\n",
       " '792,187',\n",
       " '791,507',\n",
       " '791,095']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume = []\n",
    "\n",
    "volumes=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[4]')\n",
    "for i in volumes:\n",
    "    volume.append(i.text)\n",
    "    \n",
    "volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbd6dab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Transworld',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Transworld',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Little, Brown Book',\n",
       " 'Quercus',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Little, Brown Book',\n",
       " 'Transworld',\n",
       " 'Little, Brown Book',\n",
       " 'Pan Macmillan',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Transworld',\n",
       " 'Quercus',\n",
       " 'Little, Brown Book',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Bloomsbury',\n",
       " 'Hodder & Stoughton',\n",
       " 'Bloomsbury',\n",
       " 'Quercus',\n",
       " 'Random House',\n",
       " 'Random House',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Random House',\n",
       " 'Random House',\n",
       " 'Canongate',\n",
       " 'HarperCollins',\n",
       " 'Orion',\n",
       " 'Pan Macmillan',\n",
       " 'HarperCollins',\n",
       " 'Random House',\n",
       " 'Scholastic Ltd.',\n",
       " 'Orion',\n",
       " 'Bloomsbury',\n",
       " 'Penguin',\n",
       " 'HarperCollins',\n",
       " 'Random House',\n",
       " 'Little, Brown Book',\n",
       " 'Headline',\n",
       " 'HarperCollins',\n",
       " 'Penguin',\n",
       " 'Orion',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Random House',\n",
       " 'Scholastic Ltd.',\n",
       " 'Profile Books Group',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Random House Childrens Books G',\n",
       " 'Hodder & Stoughton',\n",
       " 'Scholastic Ltd.',\n",
       " 'Random House',\n",
       " 'HarperCollins',\n",
       " 'Random House',\n",
       " 'Penguin',\n",
       " 'Random House',\n",
       " 'HarperCollins',\n",
       " 'Penguin',\n",
       " 'Headline',\n",
       " 'Little, Brown Book',\n",
       " 'HarperCollins',\n",
       " 'Transworld',\n",
       " 'Transworld',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Transworld',\n",
       " 'Transworld',\n",
       " 'Random House',\n",
       " 'Headline',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Hodder & Stoughton',\n",
       " 'Transworld',\n",
       " 'D.C. Thomson',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Transworld',\n",
       " 'Orion',\n",
       " 'Random House',\n",
       " 'Penguin',\n",
       " 'Scholastic Ltd.',\n",
       " 'Orion',\n",
       " 'Penguin']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub = []\n",
    "\n",
    "pubs=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[5]')\n",
    "for i in pubs:\n",
    "    pub.append(i.text)\n",
    "    \n",
    "pub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "772631a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Crime, Thriller & Adventure',\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " 'Romance & Sagas',\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " 'Crime, Thriller & Adventure',\n",
       " \"Children's Fiction\",\n",
       " 'Romance & Sagas',\n",
       " 'Young Adult Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Romance & Sagas',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Popular Science',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'Picture Books',\n",
       " 'Picture Books',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Humour: Collections & General',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Biography: The Arts',\n",
       " 'Autobiography: General',\n",
       " 'Picture Books',\n",
       " 'Autobiography: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Science Fiction & Fantasy',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Fitness & Diet',\n",
       " 'General & Literary Fiction',\n",
       " \"Children's Fiction\",\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Fitness & Diet',\n",
       " 'Young Adult Fiction',\n",
       " 'Usage & Writing Guides',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Popular Culture & Media: General Interest',\n",
       " 'Autobiography: The Arts',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Science Fiction & Fantasy',\n",
       " 'Current Affairs & Issues',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Autobiography: The Arts',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: The Arts',\n",
       " 'Travel Writing',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'National & Regional Cuisine',\n",
       " 'Fitness & Diet',\n",
       " 'Travel Writing',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Picture Books',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: The Arts',\n",
       " 'Popular Science',\n",
       " \"Children's Annuals\",\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Food & Drink: General',\n",
       " 'Young Adult Fiction',\n",
       " 'Biography: General',\n",
       " 'Food & Drink: General']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = []\n",
    "\n",
    "gens=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[6]')\n",
    "for i in gens:\n",
    "    gen.append(i.text)\n",
    "    \n",
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a814aaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(book),len(author),len(volume),len(pub),len(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b21f44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book name</th>\n",
       "      <th>Author name</th>\n",
       "      <th>Volumes sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book name       Author name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Book name':book,'Author name':author,'Volumes sold':volume,'Publisher':pub,'Genre':gen})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f744ff2",
   "metadata": {},
   "source": [
    "# 7. Scrape the details most watched tv series of all time from imdb.com.Url = https://www.imdb.com/list/ls095964455/ You have to find the following details:A) Name B) Year span C) Genre D) Run time E) Ratings F) Votes\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a793a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a70a938c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "998e9810",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.imdb.com/list/ls095964455/ ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4948cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Game of Thrones',\n",
       " 'Stranger Things',\n",
       " 'The Walking Dead',\n",
       " '13 Reasons Why',\n",
       " 'The 100',\n",
       " 'Orange Is the New Black',\n",
       " 'Riverdale',\n",
       " \"Grey's Anatomy\",\n",
       " 'The Flash',\n",
       " 'Arrow',\n",
       " 'Money Heist',\n",
       " 'The Big Bang Theory',\n",
       " 'Black Mirror',\n",
       " 'Sherlock',\n",
       " 'Vikings',\n",
       " 'Pretty Little Liars',\n",
       " 'The Vampire Diaries',\n",
       " 'American Horror Story',\n",
       " 'Breaking Bad',\n",
       " 'Lucifer',\n",
       " 'Supernatural',\n",
       " 'Prison Break',\n",
       " 'How to Get Away with Murder',\n",
       " 'Teen Wolf',\n",
       " 'The Simpsons',\n",
       " 'Once Upon a Time',\n",
       " 'Narcos',\n",
       " 'Daredevil',\n",
       " 'Friends',\n",
       " 'How I Met Your Mother',\n",
       " 'Suits',\n",
       " 'Mr. Robot',\n",
       " 'The Originals',\n",
       " 'Supergirl',\n",
       " 'Gossip Girl',\n",
       " 'Sense8',\n",
       " 'Gotham',\n",
       " 'Westworld',\n",
       " 'Jessica Jones',\n",
       " 'Modern Family',\n",
       " 'Rick and Morty',\n",
       " 'Shadowhunters',\n",
       " 'The End of the F***ing World',\n",
       " 'House of Cards',\n",
       " 'Dark',\n",
       " 'Elite',\n",
       " 'Sex Education',\n",
       " 'Shameless',\n",
       " 'New Girl',\n",
       " 'Agents of S.H.I.E.L.D.',\n",
       " 'You',\n",
       " 'Dexter',\n",
       " 'Fear the Walking Dead',\n",
       " 'Family Guy',\n",
       " 'The Blacklist',\n",
       " 'Lost',\n",
       " 'Peaky Blinders',\n",
       " 'House',\n",
       " 'Quantico',\n",
       " 'Orphan Black',\n",
       " 'Homeland',\n",
       " 'Blindspot',\n",
       " \"DC's Legends of Tomorrow\",\n",
       " \"The Handmaid's Tale\",\n",
       " 'Chilling Adventures of Sabrina',\n",
       " 'The Good Doctor',\n",
       " 'Jane the Virgin',\n",
       " 'Glee',\n",
       " 'South Park',\n",
       " 'Brooklyn Nine-Nine',\n",
       " 'Under the Dome',\n",
       " 'The Umbrella Academy',\n",
       " 'True Detective',\n",
       " 'The OA',\n",
       " 'Desperate Housewives',\n",
       " 'Better Call Saul',\n",
       " 'Bates Motel',\n",
       " 'The Punisher',\n",
       " 'Atypical',\n",
       " 'Dynasty',\n",
       " 'This Is Us',\n",
       " 'The Good Place',\n",
       " 'Iron Fist',\n",
       " 'The Rain',\n",
       " 'Mindhunter',\n",
       " 'Revenge',\n",
       " 'Luke Cage',\n",
       " 'Scandal',\n",
       " 'The Defenders',\n",
       " 'Big Little Lies',\n",
       " 'Insatiable',\n",
       " 'The Mentalist',\n",
       " 'The Crown',\n",
       " 'Chernobyl',\n",
       " 'iZombie',\n",
       " 'Reign',\n",
       " 'A Series of Unfortunate Events',\n",
       " 'Criminal Minds',\n",
       " 'Scream: The TV Series',\n",
       " 'The Haunting of Hill House']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=[]\n",
    "\n",
    "names = driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/a')\n",
    "for i in names:\n",
    "    name.append(i.text)\n",
    "    \n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9785667d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(2011–2019)',\n",
       " '(2016–2024)',\n",
       " '(2010–2022)',\n",
       " '(2017–2020)',\n",
       " '(2014–2020)',\n",
       " '(2013–2019)',\n",
       " '(2017–2023)',\n",
       " '(2005– )',\n",
       " '(2014–2023)',\n",
       " '(2012–2020)',\n",
       " '(2017–2021)',\n",
       " '(2007–2019)',\n",
       " '(2011– )',\n",
       " '(2010–2017)',\n",
       " '(2013–2020)',\n",
       " '(2010–2017)',\n",
       " '(2009–2017)',\n",
       " '(2011– )',\n",
       " '(2008–2013)',\n",
       " '(2016–2021)',\n",
       " '(2005–2020)',\n",
       " '(2005–2017)',\n",
       " '(2014–2020)',\n",
       " '(2011–2017)',\n",
       " '(1989– )',\n",
       " '(2011–2018)',\n",
       " '(2015–2017)',\n",
       " '(2015–2018)',\n",
       " '(1994–2004)',\n",
       " '(2005–2014)',\n",
       " '(2011–2019)',\n",
       " '(2015–2019)',\n",
       " '(2013–2018)',\n",
       " '(2015–2021)',\n",
       " '(2007–2012)',\n",
       " '(2015–2018)',\n",
       " '(2014–2019)',\n",
       " '(2016–2022)',\n",
       " '(2015–2019)',\n",
       " '(2009–2020)',\n",
       " '(2013– )',\n",
       " '(2016–2019)',\n",
       " '(2017–2019)',\n",
       " '(2013–2018)',\n",
       " '(2017–2020)',\n",
       " '(2018– )',\n",
       " '(2019– )',\n",
       " '(2011–2021)',\n",
       " '(2011–2018)',\n",
       " '(2013–2020)',\n",
       " '(2018–2024)',\n",
       " '(2006–2013)',\n",
       " '(2015–2023)',\n",
       " '(1999– )',\n",
       " '(2013–2023)',\n",
       " '(2004–2010)',\n",
       " '(2013–2022)',\n",
       " '(2004–2012)',\n",
       " '(2015–2018)',\n",
       " '(2013–2017)',\n",
       " '(2011–2020)',\n",
       " '(2015–2020)',\n",
       " '(2016–2022)',\n",
       " '(2017– )',\n",
       " '(2018–2020)',\n",
       " '(2017– )',\n",
       " '(2014–2019)',\n",
       " '(2009–2015)',\n",
       " '(1997– )',\n",
       " '(2013–2021)',\n",
       " '(2013–2015)',\n",
       " '(2019–2023)',\n",
       " '(2014– )',\n",
       " '(2016–2019)',\n",
       " '(2004–2012)',\n",
       " '(2015–2022)',\n",
       " '(2013–2017)',\n",
       " '(2017–2019)',\n",
       " '(2017–2021)',\n",
       " '(2017–2022)',\n",
       " '(2016–2022)',\n",
       " '(2016–2020)',\n",
       " '(2017–2018)',\n",
       " '(2018–2020)',\n",
       " '(2017–2019)',\n",
       " '(2011–2015)',\n",
       " '(2016–2018)',\n",
       " '(2012–2018)',\n",
       " '(2017)',\n",
       " '(2017–2019)',\n",
       " '(2018–2019)',\n",
       " '(2008– )',\n",
       " '(2016–2023)',\n",
       " '(2019)',\n",
       " '(2015–2019)',\n",
       " '(2013–2017)',\n",
       " '(2017–2019)',\n",
       " '(2005– )',\n",
       " '(2015–2019)',\n",
       " '(2018)']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year=[]\n",
    "\n",
    "years = driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/span[2]')\n",
    "for i in years:\n",
    "    year.append(i.text)\n",
    "    \n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2c943bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(name),len(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fed6e7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Action, Adventure, Drama',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Thriller',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Romance',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Mystery, Romance',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Sci-Fi',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Crime, Drama, Fantasy',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Animation, Comedy',\n",
       " 'Adventure, Fantasy, Romance',\n",
       " 'Biography, Crime, Drama',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Comedy, Drama',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Romance',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Animation, Adventure, Comedy',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Adventure, Comedy, Crime',\n",
       " 'Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Crime, Drama, Romance',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Horror, Sci-Fi',\n",
       " 'Animation, Comedy',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Adventure, Drama, Fantasy',\n",
       " 'Crime, Drama',\n",
       " 'Drama, Mystery',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Crime, Drama',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama',\n",
       " 'Comedy',\n",
       " 'Comedy, Drama, Music',\n",
       " 'Animation, Comedy',\n",
       " 'Comedy, Crime',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Adventure, Comedy',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Fantasy, Mystery',\n",
       " 'Comedy, Drama, Mystery',\n",
       " 'Crime, Drama',\n",
       " 'Drama, Horror, Mystery',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Comedy, Drama, Fantasy',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Thriller',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Comedy, Drama, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Biography, Drama, History',\n",
       " 'Drama, History, Thriller',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Drama',\n",
       " 'Adventure, Comedy, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Drama, Horror, Mystery']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen=[]\n",
    "\n",
    "gens = driver.find_elements(By.XPATH,'//span[@class=\"genre\"]')\n",
    "for i in gens:\n",
    "    gen.append(i.text)\n",
    "    \n",
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31a3b9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['57 min',\n",
       " '51 min',\n",
       " '44 min',\n",
       " '60 min',\n",
       " '43 min',\n",
       " '59 min',\n",
       " '45 min',\n",
       " '41 min',\n",
       " '43 min',\n",
       " '42 min',\n",
       " '70 min',\n",
       " '22 min',\n",
       " '60 min',\n",
       " '88 min',\n",
       " '44 min',\n",
       " '44 min',\n",
       " '43 min',\n",
       " '60 min',\n",
       " '49 min',\n",
       " '42 min',\n",
       " '44 min',\n",
       " '44 min',\n",
       " '43 min',\n",
       " '41 min',\n",
       " '22 min',\n",
       " '60 min',\n",
       " '49 min',\n",
       " '54 min',\n",
       " '22 min',\n",
       " '22 min',\n",
       " '44 min',\n",
       " '49 min',\n",
       " '45 min',\n",
       " '43 min',\n",
       " '42 min',\n",
       " '60 min',\n",
       " '42 min',\n",
       " '62 min',\n",
       " '56 min',\n",
       " '22 min',\n",
       " '23 min',\n",
       " '42 min',\n",
       " '25 min',\n",
       " '51 min',\n",
       " '60 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '46 min',\n",
       " '22 min',\n",
       " '45 min',\n",
       " '45 min',\n",
       " '53 min',\n",
       " '44 min',\n",
       " '22 min',\n",
       " '43 min',\n",
       " '44 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '42 min',\n",
       " '44 min',\n",
       " '55 min',\n",
       " '42 min',\n",
       " '42 min',\n",
       " '60 min',\n",
       " '60 min',\n",
       " '41 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '22 min',\n",
       " '22 min',\n",
       " '43 min',\n",
       " '60 min',\n",
       " '55 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '46 min',\n",
       " '45 min',\n",
       " '53 min',\n",
       " '30 min',\n",
       " '42 min',\n",
       " '45 min',\n",
       " '22 min',\n",
       " '55 min',\n",
       " '45 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '55 min',\n",
       " '43 min',\n",
       " '50 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '43 min',\n",
       " '58 min',\n",
       " '330 min',\n",
       " '42 min',\n",
       " '42 min',\n",
       " '50 min',\n",
       " '42 min',\n",
       " '45 min',\n",
       " '572 min']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run=[]\n",
    "\n",
    "runs = driver.find_elements(By.XPATH,'//span[@class=\"runtime\"]')\n",
    "for i in runs:\n",
    "    run.append(i.text)\n",
    "    \n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37be466b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.2',\n",
       " '8.7',\n",
       " '8.1',\n",
       " '7.5',\n",
       " '7.6',\n",
       " '8.1',\n",
       " '6.6',\n",
       " '7.6',\n",
       " '7.5',\n",
       " '7.5',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.8',\n",
       " '9.1',\n",
       " '8.5',\n",
       " '7.4',\n",
       " '7.7',\n",
       " '8',\n",
       " '9.5',\n",
       " '8.1',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.1',\n",
       " '7.7',\n",
       " '8.7',\n",
       " '7.7',\n",
       " '8.8',\n",
       " '8.6',\n",
       " '8.9',\n",
       " '8.3',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.3',\n",
       " '6.2',\n",
       " '7.5',\n",
       " '8.2',\n",
       " '7.8',\n",
       " '8.5',\n",
       " '7.9',\n",
       " '8.5',\n",
       " '9.1',\n",
       " '6.5',\n",
       " '8',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '7.3',\n",
       " '8.3',\n",
       " '8.6',\n",
       " '7.8',\n",
       " '7.5',\n",
       " '7.7',\n",
       " '8.7',\n",
       " '6.8',\n",
       " '8.2',\n",
       " '8',\n",
       " '8.3',\n",
       " '8.8',\n",
       " '8.7',\n",
       " '6.7',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '7.3',\n",
       " '6.8',\n",
       " '8.4',\n",
       " '7.4',\n",
       " '8',\n",
       " '7.9',\n",
       " '6.8',\n",
       " '8.7',\n",
       " '8.4',\n",
       " '6.5',\n",
       " '7.9',\n",
       " '8.9',\n",
       " '7.8',\n",
       " '7.6',\n",
       " '8.9',\n",
       " '8.1',\n",
       " '8.5',\n",
       " '8.2',\n",
       " '7.3',\n",
       " '8.7',\n",
       " '8.2',\n",
       " '6.4',\n",
       " '6.3',\n",
       " '8.6',\n",
       " '7.8',\n",
       " '7.3',\n",
       " '7.7',\n",
       " '7.2',\n",
       " '8.5',\n",
       " '6.5',\n",
       " '8.1',\n",
       " '8.6',\n",
       " '9.4',\n",
       " '7.8',\n",
       " '7.4',\n",
       " '7.8',\n",
       " '8.1',\n",
       " '7',\n",
       " '8.6']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate=[]\n",
    "\n",
    "rates = driver.find_elements(By.XPATH,'//div[@class=\"ipl-rating-star small\"]/span[2]')\n",
    "for i in rates:\n",
    "    rate.append(i.text)\n",
    "    \n",
    "rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "159a524c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,154,105',\n",
       " '1,236,005',\n",
       " '1,023,302',\n",
       " '301,130',\n",
       " '260,061',\n",
       " '308,778',\n",
       " '148,287',\n",
       " '320,034',\n",
       " '354,715',\n",
       " '436,800',\n",
       " '493,421',\n",
       " '826,226',\n",
       " '568,097',\n",
       " '947,082',\n",
       " '549,083',\n",
       " '171,527',\n",
       " '330,141',\n",
       " '326,238',\n",
       " '1,964,465',\n",
       " '334,561',\n",
       " '457,102',\n",
       " '549,634',\n",
       " '156,876',\n",
       " '155,189',\n",
       " '416,379',\n",
       " '228,826',\n",
       " '439,284',\n",
       " '451,405',\n",
       " '1,022,057',\n",
       " '698,691',\n",
       " '422,917',\n",
       " '397,064',\n",
       " '140,156',\n",
       " '126,253',\n",
       " '180,269',\n",
       " '157,534',\n",
       " '234,305',\n",
       " '514,327',\n",
       " '218,800',\n",
       " '447,443',\n",
       " '548,055',\n",
       " '66,300',\n",
       " '201,261',\n",
       " '513,119',\n",
       " '406,235',\n",
       " '83,571',\n",
       " '297,324',\n",
       " '252,361',\n",
       " '232,389',\n",
       " '220,156',\n",
       " '276,319',\n",
       " '736,778',\n",
       " '133,984',\n",
       " '349,275',\n",
       " '259,942',\n",
       " '565,624',\n",
       " '576,769',\n",
       " '476,850',\n",
       " '62,033',\n",
       " '113,114',\n",
       " '348,419',\n",
       " '75,998',\n",
       " '106,997',\n",
       " '245,935',\n",
       " '100,111',\n",
       " '100,599',\n",
       " '53,791',\n",
       " '151,214',\n",
       " '385,936',\n",
       " '330,391',\n",
       " '108,676',\n",
       " '256,875',\n",
       " '590,949',\n",
       " '108,047',\n",
       " '132,471',\n",
       " '567,808',\n",
       " '111,253',\n",
       " '245,977',\n",
       " '94,729',\n",
       " '23,614',\n",
       " '148,909',\n",
       " '170,157',\n",
       " '134,433',\n",
       " '38,970',\n",
       " '303,353',\n",
       " '121,889',\n",
       " '134,449',\n",
       " '76,182',\n",
       " '111,202',\n",
       " '208,486',\n",
       " '30,319',\n",
       " '190,220',\n",
       " '228,830',\n",
       " '791,863',\n",
       " '70,655',\n",
       " '51,406',\n",
       " '63,449',\n",
       " '206,891',\n",
       " '42,955',\n",
       " '256,570']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote=[]\n",
    "\n",
    "votes = driver.find_elements(By.XPATH,'//p[4][@class=\"text-muted text-small\"]/span[2]')\n",
    "for i in votes:\n",
    "    vote.append(i.text)\n",
    "    \n",
    "vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfc10256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(name),len(year),len(gen),len(run),len(rate),len(vote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8351ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,154,105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,236,005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,023,302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>301,130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>260,061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>51,406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>63,449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>206,891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>42,955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>256,570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2024)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run time Ratings      Votes  \n",
       "0    57 min     9.2  2,154,105  \n",
       "1    51 min     8.7  1,236,005  \n",
       "2    44 min     8.1  1,023,302  \n",
       "3    60 min     7.5    301,130  \n",
       "4    43 min     7.6    260,061  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     51,406  \n",
       "96   50 min     7.8     63,449  \n",
       "97   42 min     8.1    206,891  \n",
       "98   45 min       7     42,955  \n",
       "99  572 min     8.6    256,570  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Name':name,'Year span':year,'Genre':gen,'Run time':run,'Ratings':rate,'Votes':vote})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7339ccc3",
   "metadata": {},
   "source": [
    "# 8. Details of Datasetsfrom UCI machine learning repositories. Url = https://archive.ics.uci.edu/ You have to find the following details:A) Dataset name B) Data type C) Task D) Attribute type E) No of instances F) No of attribute G) Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e3a4ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77d9ac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5924d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://archive.ics.uci.edu/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52f34faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "show = driver.find_element(By.XPATH,'/html/body/table[1]/tbody/tr/td[2]/span[2]/a/font/b')\n",
    "show.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bde8df5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abalone',\n",
       " 'Adult',\n",
       " 'Annealing',\n",
       " 'Anonymous Microsoft Web Data',\n",
       " 'Arrhythmia',\n",
       " 'Artificial Characters',\n",
       " 'Audiology (Original)',\n",
       " 'Audiology (Standardized)',\n",
       " 'Auto MPG',\n",
       " 'Automobile',\n",
       " 'Badges',\n",
       " 'Balance Scale',\n",
       " 'Balloons',\n",
       " 'Breast Cancer',\n",
       " 'Breast Cancer Wisconsin (Original)',\n",
       " 'Breast Cancer Wisconsin (Prognostic)',\n",
       " 'Breast Cancer Wisconsin (Diagnostic)',\n",
       " 'Pittsburgh Bridges',\n",
       " 'Car Evaluation',\n",
       " 'Census Income',\n",
       " 'Chess (King-Rook vs. King-Knight)',\n",
       " 'Chess (King-Rook vs. King-Pawn)',\n",
       " 'Chess (King-Rook vs. King)',\n",
       " 'Chess (Domain Theories)',\n",
       " 'Bach Chorales',\n",
       " 'Connect-4',\n",
       " 'Credit Approval',\n",
       " 'Japanese Credit Screening',\n",
       " 'Computer Hardware',\n",
       " 'Contraceptive Method Choice',\n",
       " 'Covertype',\n",
       " 'Cylinder Bands',\n",
       " 'Dermatology',\n",
       " 'Diabetes',\n",
       " 'DGP2 - The Second Data Generation Program',\n",
       " 'Document Understanding',\n",
       " 'EBL Domain Theories',\n",
       " 'Echocardiogram',\n",
       " 'Ecoli',\n",
       " 'Flags',\n",
       " 'Function Finding',\n",
       " 'Glass Identification',\n",
       " \"Haberman's Survival\",\n",
       " 'Hayes-Roth',\n",
       " 'Heart Disease',\n",
       " 'Hepatitis',\n",
       " 'Horse Colic',\n",
       " 'ICU',\n",
       " 'Image Segmentation',\n",
       " 'Internet Advertisements',\n",
       " 'Ionosphere',\n",
       " 'Iris',\n",
       " 'ISOLET',\n",
       " 'Kinship',\n",
       " 'Labor Relations',\n",
       " 'LED Display Domain',\n",
       " 'Lenses',\n",
       " 'Letter Recognition',\n",
       " 'Liver Disorders',\n",
       " 'Logic Theorist',\n",
       " 'Lung Cancer',\n",
       " 'Lymphography',\n",
       " 'Mechanical Analysis',\n",
       " 'Meta-data',\n",
       " 'Mobile Robots',\n",
       " 'Molecular Biology (Promoter Gene Sequences)',\n",
       " 'Molecular Biology (Protein Secondary Structure)',\n",
       " 'Molecular Biology (Splice-junction Gene Sequences)',\n",
       " \"MONK's Problems\",\n",
       " 'Moral Reasoner',\n",
       " 'Multiple Features',\n",
       " 'Mushroom',\n",
       " 'Musk (Version 1)',\n",
       " 'Musk (Version 2)',\n",
       " 'Nursery',\n",
       " 'Othello Domain Theory',\n",
       " 'Page Blocks Classification',\n",
       " 'Optical Recognition of Handwritten Digits',\n",
       " 'Pen-Based Recognition of Handwritten Digits',\n",
       " 'Post-Operative Patient',\n",
       " 'Primary Tumor',\n",
       " 'Prodigy',\n",
       " 'Qualitative Structure Activity Relationships',\n",
       " 'Quadruped Mammals',\n",
       " 'Servo',\n",
       " 'Shuttle Landing Control',\n",
       " 'Solar Flare',\n",
       " 'Soybean (Large)',\n",
       " 'Soybean (Small)',\n",
       " 'Challenger USA Space Shuttle O-Ring',\n",
       " 'Low Resolution Spectrometer',\n",
       " 'Spambase',\n",
       " 'SPECT Heart',\n",
       " 'SPECTF Heart',\n",
       " 'Sponge',\n",
       " 'Statlog Project',\n",
       " 'Student Loan Relational',\n",
       " 'Teaching Assistant Evaluation',\n",
       " 'Tic-Tac-Toe Endgame',\n",
       " 'Thyroid Disease',\n",
       " 'Trains',\n",
       " 'University',\n",
       " 'Congressional Voting Records',\n",
       " 'Water Treatment Plant',\n",
       " 'Waveform Database Generator (Version 1)',\n",
       " 'Waveform Database Generator (Version 2)',\n",
       " 'Wine',\n",
       " 'Yeast',\n",
       " 'Zoo',\n",
       " 'Undocumented',\n",
       " 'Twenty Newsgroups',\n",
       " 'Australian Sign Language signs',\n",
       " 'Australian Sign Language signs (High Quality)',\n",
       " 'US Census Data (1990)',\n",
       " 'Census-Income (KDD)',\n",
       " 'Coil 1999 Competition Data',\n",
       " 'Corel Image Features',\n",
       " 'E. Coli Genes',\n",
       " 'EEG Database',\n",
       " 'El Nino',\n",
       " 'Entree Chicago Recommendation Data',\n",
       " 'CMU Face Images',\n",
       " 'Insurance Company Benchmark (COIL 2000)',\n",
       " 'Internet Usage Data',\n",
       " 'IPUMS Census Database',\n",
       " 'Japanese Vowels',\n",
       " 'KDD Cup 1998 Data',\n",
       " 'KDD Cup 1999 Data',\n",
       " 'M. Tuberculosis Genes',\n",
       " 'Movie',\n",
       " 'MSNBC.com Anonymous Web Data',\n",
       " 'NSF Research Award Abstracts 1990-2003',\n",
       " 'Pioneer-1 Mobile Robot Data',\n",
       " 'Pseudo Periodic Synthetic Time Series',\n",
       " 'Reuters-21578 Text Categorization Collection',\n",
       " 'Robot Execution Failures',\n",
       " 'Synthetic Control Chart Time Series',\n",
       " 'Syskill and Webert Web Page Ratings',\n",
       " 'UNIX User Data',\n",
       " 'Volcanoes on Venus - JARtool experiment',\n",
       " 'Statlog (Australian Credit Approval)',\n",
       " 'Statlog (German Credit Data)',\n",
       " 'Statlog (Heart)',\n",
       " 'Statlog (Landsat Satellite)',\n",
       " 'Statlog (Image Segmentation)',\n",
       " 'Statlog (Shuttle)',\n",
       " 'Statlog (Vehicle Silhouettes)',\n",
       " 'Connectionist Bench (Nettalk Corpus)',\n",
       " 'Connectionist Bench (Sonar, Mines vs. Rocks)',\n",
       " 'Connectionist Bench (Vowel Recognition - Deterding Data)',\n",
       " 'Economic Sanctions',\n",
       " 'Protein Data',\n",
       " 'Cloud',\n",
       " 'CalIt2 Building People Counts',\n",
       " 'Dodgers Loop Sensor',\n",
       " 'Poker Hand',\n",
       " 'MAGIC Gamma Telescope',\n",
       " 'UJI Pen Characters',\n",
       " 'Mammographic Mass',\n",
       " 'Forest Fires',\n",
       " 'Reuters Transcribed Subset',\n",
       " 'Bag of Words',\n",
       " 'Concrete Compressive Strength',\n",
       " 'Hill-Valley',\n",
       " 'Arcene',\n",
       " 'Dexter',\n",
       " 'Dorothea',\n",
       " 'Gisette',\n",
       " 'Madelon',\n",
       " 'Ozone Level Detection',\n",
       " 'Abscisic Acid Signaling Network',\n",
       " 'Parkinsons',\n",
       " 'Character Trajectories',\n",
       " 'Blood Transfusion Service Center',\n",
       " 'UJI Pen Characters (Version 2)',\n",
       " 'Semeion Handwritten Digit',\n",
       " 'SECOM',\n",
       " 'Plants',\n",
       " 'Libras Movement',\n",
       " 'Concrete Slump Test',\n",
       " 'Communities and Crime',\n",
       " 'Acute Inflammations',\n",
       " 'Wine Quality',\n",
       " 'URL Reputation',\n",
       " 'p53 Mutants',\n",
       " 'Parkinsons Telemonitoring',\n",
       " 'Demospongiae',\n",
       " 'Opinosis Opinion ⁄ Review',\n",
       " 'Breast Tissue',\n",
       " 'Cardiotocography',\n",
       " 'Wall-Following Robot Navigation Data',\n",
       " 'Spoken Arabic Digit',\n",
       " 'Localization Data for Person Activity',\n",
       " 'AutoUniv',\n",
       " 'Steel Plates Faults',\n",
       " 'MiniBooNE particle identification',\n",
       " 'YearPredictionMSD',\n",
       " 'PEMS-SF',\n",
       " 'OpinRank Review Dataset',\n",
       " 'Relative location of CT slices on axial axis',\n",
       " 'Online Handwritten Assamese Characters Dataset',\n",
       " 'PubChem Bioassay Data',\n",
       " 'Record Linkage Comparison Patterns',\n",
       " 'Communities and Crime Unnormalized',\n",
       " 'Vertebral Column',\n",
       " 'EMG Physical Action Data Set',\n",
       " 'Vicon Physical Action Data Set',\n",
       " 'Amazon Commerce reviews set',\n",
       " 'Amazon Access Samples',\n",
       " 'Reuter_50_50',\n",
       " 'Farm Ads',\n",
       " 'DBWorld e-mails',\n",
       " 'KEGG Metabolic Relation Network (Directed)',\n",
       " 'KEGG Metabolic Reaction Network (Undirected)',\n",
       " 'Bank Marketing',\n",
       " 'YouTube Comedy Slam Preference Data',\n",
       " 'Gas Sensor Array Drift Dataset',\n",
       " 'ILPD (Indian Liver Patient Dataset)',\n",
       " 'OPPORTUNITY Activity Recognition',\n",
       " 'Nomao',\n",
       " 'SMS Spam Collection',\n",
       " 'Skin Segmentation',\n",
       " 'Planning Relax',\n",
       " 'PAMAP2 Physical Activity Monitoring',\n",
       " 'Restaurant & consumer data',\n",
       " 'CNAE-9',\n",
       " 'Individual household electric power consumption',\n",
       " 'seeds',\n",
       " 'Northix',\n",
       " 'QtyT40I10D100K',\n",
       " 'Legal Case Reports',\n",
       " 'Human Activity Recognition Using Smartphones',\n",
       " 'One-hundred plant species leaves data set',\n",
       " 'Energy efficiency',\n",
       " 'Yacht Hydrodynamics',\n",
       " 'Fertility',\n",
       " 'Daphnet Freezing of Gait',\n",
       " '3D Road Network (North Jutland, Denmark)',\n",
       " 'ISTANBUL STOCK EXCHANGE',\n",
       " 'Buzz in social media',\n",
       " 'First-order theorem proving',\n",
       " 'Wearable Computing: Classification of Body Postures and Movements (PUC-Rio)',\n",
       " 'Gas sensor arrays in open sampling settings',\n",
       " 'Climate Model Simulation Crashes',\n",
       " 'MicroMass',\n",
       " 'QSAR biodegradation',\n",
       " 'BLOGGER',\n",
       " 'Daily and Sports Activities',\n",
       " 'User Knowledge Modeling',\n",
       " 'Reuters RCV1 RCV2 Multilingual, Multiview Text Categorization Test collection',\n",
       " 'NYSK',\n",
       " 'Turkiye Student Evaluation',\n",
       " \"ser Knowledge Modeling Data (Students' Knowledge Levels on DC Electrical Machines)\",\n",
       " 'EEG Eye State',\n",
       " 'Physicochemical Properties of Protein Tertiary Structure',\n",
       " 'seismic-bumps',\n",
       " 'banknote authentication',\n",
       " 'USPTO Algorithm Challenge, run by NASA-Harvard Tournament Lab and TopCoder Problem: Pat',\n",
       " 'YouTube Multiview Video Games Dataset',\n",
       " 'Gas Sensor Array Drift Dataset at Different Concentrations',\n",
       " 'Activities of Daily Living (ADLs) Recognition Using Binary Sensors',\n",
       " 'SkillCraft1 Master Table Dataset',\n",
       " 'Weight Lifting Exercises monitored with Inertial Measurement Units',\n",
       " 'SML2010',\n",
       " 'Bike Sharing Dataset',\n",
       " 'Predict keywords activities in a online social media',\n",
       " 'Thoracic Surgery Data',\n",
       " 'EMG dataset in Lower Limb',\n",
       " 'SUSY',\n",
       " 'HIGGS',\n",
       " 'Qualitative_Bankruptcy',\n",
       " 'LSVT Voice Rehabilitation',\n",
       " 'Dataset for ADL Recognition with Wrist-worn Accelerometer',\n",
       " 'Wilt',\n",
       " 'User Identification From Walking Activity',\n",
       " 'Activity Recognition from Single Chest-Mounted Accelerometer',\n",
       " 'Leaf',\n",
       " 'Dresses_Attribute_Sales',\n",
       " 'Tamilnadu Electricity Board Hourly Readings',\n",
       " 'Airfoil Self-Noise',\n",
       " 'Wholesale customers',\n",
       " 'Twitter Data set for Arabic Sentiment Analysis',\n",
       " 'Combined Cycle Power Plant',\n",
       " 'Urban Land Cover',\n",
       " 'Diabetes 130-US hospitals for years 1999-2008',\n",
       " 'Bach Choral Harmony',\n",
       " 'StoneFlakes',\n",
       " 'Tennis Major Tournament Match Statistics',\n",
       " 'Parkinson Speech Dataset with Multiple Types of Sound Recordings',\n",
       " 'Gesture Phase Segmentation',\n",
       " 'Perfume Data',\n",
       " 'BlogFeedback',\n",
       " 'REALDISP Activity Recognition Dataset',\n",
       " 'Newspaper and magazine images segmentation dataset',\n",
       " 'AAAI 2014 Accepted Papers',\n",
       " 'Gas sensor array under flow modulation',\n",
       " 'Gas sensor array exposed to turbulent gas mixtures',\n",
       " 'UJIIndoorLoc',\n",
       " 'Sentence Classification',\n",
       " 'Dow Jones Index',\n",
       " 'sEMG for Basic Hand movements',\n",
       " 'AAAI 2013 Accepted Papers',\n",
       " 'Geographical Original of Music',\n",
       " 'Condition Based Maintenance of Naval Propulsion Plants',\n",
       " 'Grammatical Facial Expressions',\n",
       " 'NoisyOffice',\n",
       " 'MHEALTH Dataset',\n",
       " 'Student Performance',\n",
       " 'ElectricityLoadDiagrams20112014',\n",
       " 'Gas sensor array under dynamic gas mixtures',\n",
       " 'microblogPCU',\n",
       " 'Firm-Teacher_Clave-Direction_Classification',\n",
       " 'Dataset for Sensorless Drive Diagnosis',\n",
       " 'TV News Channel Commercial Detection Dataset',\n",
       " 'Phishing Websites',\n",
       " 'Greenhouse Gas Observing Network',\n",
       " 'Diabetic Retinopathy Debrecen Data Set',\n",
       " 'HIV-1 protease cleavage',\n",
       " 'Sentiment Labelled Sentences',\n",
       " 'Online News Popularity',\n",
       " 'Forest type mapping',\n",
       " 'wiki4HE',\n",
       " 'Online Video Characteristics and Transcoding Time Dataset',\n",
       " 'Chronic_Kidney_Disease',\n",
       " 'Machine Learning based ZZAlpha Ltd. Stock Recommendations 2012-2014',\n",
       " 'Folio',\n",
       " 'Taxi Service Trajectory - Prediction Challenge, ECML PKDD 2015',\n",
       " 'Cuff-Less Blood Pressure Estimation',\n",
       " 'Smartphone-Based Recognition of Human Activities and Postural Transitions',\n",
       " 'Mice Protein Expression',\n",
       " 'UJIIndoorLoc-Mag',\n",
       " 'Heterogeneity Activity Recognition',\n",
       " 'Educational Process Mining (EPM): A Learning Analytics Data Set',\n",
       " 'HEPMASS',\n",
       " 'Indoor User Movement Prediction from RSS data',\n",
       " 'Open University Learning Analytics dataset',\n",
       " 'default of credit card clients',\n",
       " 'Mesothelioma’s disease data set',\n",
       " 'Online Retail',\n",
       " 'SIFT10M',\n",
       " 'GPS Trajectories',\n",
       " 'Detect Malacious Executable(AntiVirus)',\n",
       " 'Occupancy Detection',\n",
       " 'Improved Spiral Test Using Digitized Graphics Tablet for Monitoring Parkinson’s Disease',\n",
       " 'News Aggregator',\n",
       " 'Air Quality',\n",
       " 'Twin gas sensor arrays',\n",
       " 'Gas sensors for home activity monitoring',\n",
       " 'Facebook Comment Volume Dataset',\n",
       " 'Smartphone Dataset for Human Activity Recognition (HAR) in Ambient Assisted Living (AAL)',\n",
       " 'Polish companies bankruptcy data',\n",
       " 'Activity Recognition system based on Multisensor data fusion (AReM)',\n",
       " 'Dota2 Games Results',\n",
       " 'Facebook metrics',\n",
       " 'UbiqLog (smartphone lifelogging)',\n",
       " 'NIPS Conference Papers 1987-2015',\n",
       " 'HTRU2',\n",
       " 'Drug consumption (quantified)',\n",
       " 'Appliances energy prediction',\n",
       " 'Miskolc IIS Hybrid IPS',\n",
       " 'KDC-4007 dataset Collection',\n",
       " 'Geo-Magnetic field and WLAN dataset for indoor localisation from wristband and smartphone',\n",
       " 'DrivFace',\n",
       " 'Website Phishing',\n",
       " 'YouTube Spam Collection',\n",
       " 'Beijing PM2.5 Data',\n",
       " 'Cargo 2000 Freight Tracking and Tracing',\n",
       " 'Cervical cancer (Risk Factors)',\n",
       " 'Quality Assessment of Digital Colposcopies',\n",
       " 'KASANDR',\n",
       " 'FMA: A Dataset For Music Analysis',\n",
       " 'Air quality',\n",
       " 'Epileptic Seizure Recognition',\n",
       " 'Devanagari Handwritten Character Dataset',\n",
       " 'Stock portfolio performance',\n",
       " 'MoCap Hand Postures',\n",
       " 'Early biomarkers of Parkinson�s disease based on natural connected speech',\n",
       " 'Data for Software Engineering Teamwork Assessment in Education Setting',\n",
       " 'PM2.5 Data of Five Chinese Cities',\n",
       " 'Parkinson Disease Spiral Drawings Using Digitized Graphics Tablet',\n",
       " 'Sales_Transactions_Dataset_Weekly',\n",
       " 'Las Vegas Strip',\n",
       " 'Eco-hotel',\n",
       " 'MEU-Mobile KSD',\n",
       " 'Crowdsourced Mapping',\n",
       " 'gene expression cancer RNA-Seq',\n",
       " 'Hybrid Indoor Positioning Dataset from WiFi RSSI, Bluetooth and magnetometer',\n",
       " 'chestnut – LARVIC',\n",
       " 'Burst Header Packet (BHP) flooding attack on Optical Burst Switching (OBS) Network',\n",
       " 'Motion Capture Hand Postures',\n",
       " 'Anuran Calls (MFCCs)',\n",
       " 'TTC-3600: Benchmark dataset for Turkish text categorization',\n",
       " 'Gastrointestinal Lesions in Regular Colonoscopy',\n",
       " 'Daily Demand Forecasting Orders',\n",
       " 'Paper Reviews',\n",
       " 'extention of Z-Alizadeh sani dataset',\n",
       " 'Z-Alizadeh Sani',\n",
       " 'Dynamic Features of VirusShare Executables',\n",
       " 'IDA2016Challenge',\n",
       " 'DSRC Vehicle Communications',\n",
       " 'Mturk User-Perceived Clusters over Images',\n",
       " 'Character Font Images',\n",
       " 'DeliciousMIL: A Data Set for Multi-Label Multi-Instance Learning with Instance Labels',\n",
       " 'Autistic Spectrum Disorder Screening Data for Children',\n",
       " 'Autistic Spectrum Disorder Screening Data for Adolescent',\n",
       " 'APS Failure at Scania Trucks',\n",
       " 'Wireless Indoor Localization',\n",
       " 'HCC Survival',\n",
       " 'CSM (Conventional and Social Media Movies) Dataset 2014 and 2015',\n",
       " 'University of Tehran Question Dataset 2016 (UTQD.2016)',\n",
       " 'Autism Screening Adult',\n",
       " 'Activity recognition with healthy older people using a batteryless wearable sensor',\n",
       " 'Immunotherapy Dataset',\n",
       " 'Cryotherapy Dataset',\n",
       " 'OCT data & Color Fundus Images of Left & Right Eyes',\n",
       " 'Discrete Tone Image Dataset',\n",
       " 'News Popularity in Multiple Social Media Platforms',\n",
       " 'Ultrasonic flowmeter diagnostics',\n",
       " 'ICMLA 2014 Accepted Papers Data Set',\n",
       " 'BLE RSSI Dataset for Indoor localization and Navigation',\n",
       " 'Container Crane Controller Data Set',\n",
       " 'Residential Building Data Set',\n",
       " 'Health News in Twitter',\n",
       " 'chipseq',\n",
       " 'SGEMM GPU kernel performance',\n",
       " 'Repeat Consumption Matrices',\n",
       " 'detection_of_IoT_botnet_attacks_N_BaIoT',\n",
       " 'Absenteeism at work',\n",
       " 'SCADI',\n",
       " 'Condition monitoring of hydraulic systems',\n",
       " 'Carbon Nanotubes',\n",
       " 'Optical Interconnection Network',\n",
       " 'Sports articles for objectivity analysis',\n",
       " 'Breast Cancer Coimbra',\n",
       " 'GNFUV Unmanned Surface Vehicles Sensor Data',\n",
       " 'Dishonest Internet users Dataset',\n",
       " 'Victorian Era Authorship Attribution',\n",
       " 'Simulated Falls and Daily Living Activities Data Set',\n",
       " 'Multimodal Damage Identification for Humanitarian Computing',\n",
       " 'EEG Steady-State Visual Evoked Potential Signals',\n",
       " 'Roman Urdu Data Set',\n",
       " 'Avila',\n",
       " 'PANDOR',\n",
       " 'Drug Review Dataset (Druglib.com)',\n",
       " 'Drug Review Dataset (Drugs.com)',\n",
       " 'Physical Unclonable Functions',\n",
       " 'Superconductivty Data',\n",
       " 'WESAD (Wearable Stress and Affect Detection)',\n",
       " 'GNFUV Unmanned Surface Vehicles Sensor Data Set 2',\n",
       " 'Student Academics Performance',\n",
       " 'Online Shoppers Purchasing Intention Dataset',\n",
       " 'PMU-UD',\n",
       " \"Parkinson's Disease Classification\",\n",
       " 'Electrical Grid Stability Simulated Data',\n",
       " 'Caesarian Section Classification Dataset',\n",
       " 'BAUM-1',\n",
       " 'BAUM-2',\n",
       " 'Audit Data',\n",
       " 'BuddyMove Data Set',\n",
       " 'Real estate valuation data set',\n",
       " 'Early biomarkers of Parkinson’s disease based on natural connected speech Data Set',\n",
       " 'Somerville Happiness Survey',\n",
       " '2.4 GHZ Indoor Channel Measurements',\n",
       " 'EMG data for gestures',\n",
       " 'Parking Birmingham',\n",
       " 'Behavior of the urban traffic of the city of Sao Paulo in Brazil',\n",
       " 'Travel Reviews',\n",
       " 'Tarvel Review Ratings',\n",
       " 'Rice Leaf Diseases',\n",
       " 'Gas sensor array temperature modulation',\n",
       " 'Facebook Live Sellers in Thailand',\n",
       " 'Parkinson Dataset with replicated acoustic features',\n",
       " 'Metro Interstate Traffic Volume',\n",
       " 'Query Analytics Workloads Dataset',\n",
       " 'Wave Energy Converters',\n",
       " 'PPG-DaLiA',\n",
       " 'Alcohol QCM Sensor Dataset',\n",
       " 'Divorce Predictors data set',\n",
       " 'Incident management process enriched event log',\n",
       " 'Opinion Corpus for Lebanese Arabic Reviews (OCLAR)',\n",
       " 'MEx',\n",
       " 'Beijing Multi-Site Air-Quality Data',\n",
       " 'Online Retail II',\n",
       " 'Hepatitis C Virus (HCV) for Egyptian patients',\n",
       " 'QSAR fish toxicity',\n",
       " 'QSAR aquatic toxicity',\n",
       " 'Human Activity Recognition from Continuous Ambient Sensor Data',\n",
       " 'WISDM Smartphone and Smartwatch Activity and Biometrics Dataset',\n",
       " 'QSAR oral toxicity',\n",
       " 'QSAR androgen receptor',\n",
       " 'QSAR Bioconcentration classes dataset',\n",
       " 'QSAR fish bioconcentration factor (BCF)',\n",
       " 'A study of Asian Religious and Biblical Texts',\n",
       " 'Real-time Election Results: Portugal 2019',\n",
       " 'Bias correction of numerical prediction model temperature forecast',\n",
       " 'Bar Crawl: Detecting Heavy Drinking',\n",
       " 'Kitsune Network Attack Dataset',\n",
       " 'Shoulder Implant X-Ray Manufacturer Classification',\n",
       " 'Speaker Accent Recognition',\n",
       " 'Heart failure clinical records',\n",
       " 'Deepfakes: Medical Image Tamper Detection',\n",
       " 'selfBACK',\n",
       " 'South German Credit',\n",
       " 'Exasens',\n",
       " 'Swarm Behaviour',\n",
       " 'Crop mapping using fused optical-radar data set',\n",
       " 'BitcoinHeistRansomwareAddressDataset',\n",
       " 'Facebook Large Page-Page Network',\n",
       " 'Amphibians',\n",
       " 'Early stage diabetes risk prediction dataset.',\n",
       " 'Turkish Spam V01',\n",
       " 'Stock keeping units',\n",
       " 'Demand Forecasting for a store',\n",
       " 'Detect Malware Types',\n",
       " 'Wave Energy Converters',\n",
       " 'Youtube cookery channels viewers comments in Hinglish',\n",
       " 'Pedestrian in Traffic Dataset',\n",
       " 'Cervical Cancer Behavior Risk',\n",
       " 'Sattriya_Dance_Single_Hand_Gestures Dataset',\n",
       " 'Divorce Predictors data set',\n",
       " '3W dataset',\n",
       " 'Malware static and dynamic features VxHeaven and Virus Total',\n",
       " 'Internet Firewall Data',\n",
       " 'User Profiling and Abusive Language Detection Dataset',\n",
       " 'Estimation of obesity levels based on eating habits and physical condition',\n",
       " 'Rice (Cammeo and Osmancik)',\n",
       " 'Vehicle routing and scheduling problems',\n",
       " 'Algerian Forest Fires Dataset',\n",
       " 'Breath Metabolomics',\n",
       " 'Horton General Hospital',\n",
       " 'UrbanGB, urban road accidents coordinates labelled by the urban center',\n",
       " 'Gas Turbine CO and NOx Emission Data Set',\n",
       " 'Activity recognition using wearable physiological measurements',\n",
       " 'clickstream data for online shopping',\n",
       " 'CNNpred: CNN-based stock market prediction using a diverse set of variables',\n",
       " 'Apartment for rent classified',\n",
       " ': Simulated Data set of Iraqi tourism places',\n",
       " 'Nasarian CAD Dataset',\n",
       " 'Monolithic Columns in Troad and Mysia Region',\n",
       " 'Bar Crawl: Detecting Heavy Drinking',\n",
       " 'Seoul Bike Sharing Demand',\n",
       " 'Person Classification Gait Data',\n",
       " 'Shill Bidding Dataset',\n",
       " 'Iranian Churn Dataset',\n",
       " 'Unmanned Aerial Vehicle (UAV) Intrusion Detection',\n",
       " 'Bone marrow transplant: children',\n",
       " 'Exasens',\n",
       " 'COVID-19 Surveillance',\n",
       " 'Refractive errors',\n",
       " 'Shoulder Implant X-Ray Manufacturer Classification',\n",
       " 'CLINC150',\n",
       " 'HCV data',\n",
       " 'Taiwanese Bankruptcy Prediction',\n",
       " 'South German Credit (UPDATE)',\n",
       " 'IIWA14-R820-Gazebo-Dataset-10Trajectories',\n",
       " 'Guitar Chords finger positions',\n",
       " 'Russian Corpus of Biographical Texts',\n",
       " 'Codon usage',\n",
       " 'Intelligent Media Accelerometer and Gyroscope (IM-AccGyro) Dataset',\n",
       " 'Myocardial infarction complications',\n",
       " 'Hungarian Chickenpox Cases',\n",
       " 'Simulated data for survival modelling',\n",
       " 'Student Performance on an entrance examination',\n",
       " 'Chemical Composition of Ceramic Samples',\n",
       " 'Labeled Text Forum Threads Dataset',\n",
       " 'Stock keeping units',\n",
       " 'BLE RSSI dataset for Indoor localization',\n",
       " 'Basketball dataset',\n",
       " 'GitHub MUSAE',\n",
       " 'Anticancer peptides',\n",
       " 'Monolithic Columns in Troad and Mysia Region',\n",
       " 'Gender by Name',\n",
       " 'Iranian Churn Dataset',\n",
       " 'Unmanned Aerial Vehicle (UAV) Intrusion Detection',\n",
       " 'Shoulder Implant Manufacture Classification',\n",
       " 'LastFM Asia Social Network',\n",
       " 'Wheat kernels',\n",
       " 'Productivity Prediction of Garment Employees',\n",
       " 'Multi-view Brain Networks',\n",
       " 'LastFM Asia Social Network',\n",
       " 'Wisesight Sentiment Corpus',\n",
       " 'AI4I 2020 Predictive Maintenance Dataset',\n",
       " 'Dry Bean Dataset',\n",
       " 'in-vehicle coupon recommendation',\n",
       " 'Gait Classification',\n",
       " 'Wikipedia Math Essentials',\n",
       " 'Wikipedia Math Essentials',\n",
       " 'Synchronous Machine Data Set',\n",
       " 'Average Localization Error (ALE) in sensor node localization process in WSNs',\n",
       " '9mers from cullpdb',\n",
       " 'TamilSentiMix',\n",
       " 'Accelerometer',\n",
       " 'Synchronous Machine Data Set',\n",
       " 'Pedal Me Bicycle Deliveries',\n",
       " 'Turkish Headlines Dataset',\n",
       " 'Secondary Mushroom Dataset',\n",
       " 'Power consumption of Tetouan city',\n",
       " 'Raisin Dataset',\n",
       " 'Steel Industry Energy Consumption Dataset',\n",
       " 'Gender Gap in Spanish WP',\n",
       " 'Non verbal tourists data',\n",
       " 'Roman Urdu Sentiment Analysis Dataset (RUSAD)',\n",
       " 'TUANDROMD ( Tezpur University Android Malware Dataset)',\n",
       " 'Higher Education Students Performance Evaluation Dataset',\n",
       " 'Risk Factor prediction of Chronic Kidney Disease',\n",
       " 'Lab Test',\n",
       " 'Shoulder Implant Manufacture Classification',\n",
       " 'Rocket League Skillshots Data Set',\n",
       " 'Sepsis survival minimal clinical records',\n",
       " 'Water Quality Prediction',\n",
       " 'Traffic Flow Forecasting',\n",
       " 'sentiment analysis in Saudi Arabia about distance education during Covid-19',\n",
       " 'Kain Tradisional Sambas',\n",
       " 'Image Recognition Task Execution Times in Mobile Edge Computing',\n",
       " 'REWEMA',\n",
       " 'REJAFADA',\n",
       " 'Steel Industry Energy Consumption Dataset',\n",
       " 'Influenza outbreak event prediction via Twitter data',\n",
       " 'Turkish Music Emotion Dataset',\n",
       " 'Maternal Health Risk Data Set',\n",
       " 'Room Occupancy Estimation',\n",
       " 'Image Recognition Task Execution Times in Mobile Edge Computing']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=[]\n",
    "\n",
    "names=driver.find_elements(By.XPATH,'//p[@class=\"normal\"]/b/a')\n",
    "for i in names:\n",
    "    name.append(i.text)\n",
    "    \n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac7c8116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38e1d37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Univariate, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Data-Generator ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Domain-Theory ',\n",
       " 'Univariate, Time-Series ',\n",
       " 'Multivariate, Spatial ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Domain-Theory ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Data-Generator ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Relational ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Data-Generator ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Domain-Theory ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Domain-Theory ',\n",
       " 'Sequential, Domain-Theory ',\n",
       " 'Sequential ',\n",
       " 'Sequential, Domain-Theory ',\n",
       " 'Multivariate ',\n",
       " 'Domain-Theory ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Domain-Theory ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Domain-Theory ',\n",
       " 'Domain-Theory ',\n",
       " 'Multivariate, Data-Generator ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Domain-Theory ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Domain-Theory ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Data-Generator ',\n",
       " 'Multivariate, Data-Generator ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Text ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Relational ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Spatio-temporal ',\n",
       " 'Transactional, Sequential ',\n",
       " 'Image ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Relational ',\n",
       " 'Multivariate, Relational ',\n",
       " 'Sequential ',\n",
       " 'Text ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Univariate, Time-Series ',\n",
       " 'Text ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate, Text ',\n",
       " 'Text, Sequential ',\n",
       " 'Image ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Domain-Theory ',\n",
       " ' ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Sequential ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Univariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Text ',\n",
       " 'Domain-Theory ',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Time-Series ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate, Text, Domain-Theory ',\n",
       " 'Time-Series, Domain-Theory ',\n",
       " 'Multivariate, Text, Domain-Theory ',\n",
       " 'Text ',\n",
       " 'Text ',\n",
       " 'Multivariate, Univariate, Text ',\n",
       " 'Multivariate, Univariate, Text ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Univariate ',\n",
       " 'Multivariate, Text, Domain-Theory ',\n",
       " 'Univariate ',\n",
       " 'Univariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Univariate, Text ',\n",
       " 'Sequential ',\n",
       " 'Text ',\n",
       " 'Multivariate, Time-Series ',\n",
       " ' ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Sequential, Text ',\n",
       " 'Multivariate, Univariate, Time-Series ',\n",
       " 'Time-Series, Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Sequential ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Domain-Theory ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series, Text ',\n",
       " 'Univariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Univariate, Sequential, Time-Series ',\n",
       " 'Univariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Sequential ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Univariate, Domain-Theory ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " ' ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Time-Series ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Univariate, Sequential, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series, Domain-Theory ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Time-Series, Domain-Theory ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Text ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " ' ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Sequential, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " ' ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " ' ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Time-Series ',\n",
       " 'Text ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Sequential, Text ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " ' ',\n",
       " 'Sequential ',\n",
       " 'Univariate ',\n",
       " 'Univariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Univariate, Domain-Theory ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Sequential ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Univariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Univariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Univariate ',\n",
       " 'Time-Series ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Multivariate ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate, Univariate, Sequential, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Univariate ',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Text ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Sequential, Time-Series, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate, Time-Series, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate, Univariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Univariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Univariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Text ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Sequential, Time-Series ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Sequential ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Time-Series ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Sequential ',\n",
       " ' ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Time-Series ',\n",
       " 'Text ',\n",
       " 'Univariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Univariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Univariate ']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=[]\n",
    "\n",
    "datas=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[2]')\n",
    "for i in datas[1:623]:\n",
    "    data.append(i.text)\n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cba8901e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8f7eeac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Recommender-Systems ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Function-Learning ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Relational-Learning ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Recommender-Systems ',\n",
       " 'Classification ',\n",
       " 'Regression, Description ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Causal-Discovery ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Causal-Discovery ',\n",
       " 'Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression, Clustering, Causal-Discovery ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Regression, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Regression, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression, Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression, Clustering, Causa ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering, Causal-Discovery ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Causal-Discovery ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Regression, Clustering, Causal-Discovery ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Clustering, Causal-Discovery ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Causal-Discovery ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Causal-Discovery ',\n",
       " 'Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification, Clustering, Causal-Discovery ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Causal-Discovery ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Clustering ',\n",
       " 'Classification, Regression ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression ',\n",
       " 'Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Recommendation ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Regression, Clustering ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Clustering, Causal-Discovery ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Causal-Discovery ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Causal-Discovery ',\n",
       " 'Clustering ',\n",
       " 'Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Causal-Discovery ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task=[]\n",
    "\n",
    "tasks=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[3]')\n",
    "for i in tasks[1:623]:\n",
    "    task.append(i.text)\n",
    "    \n",
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b8e2810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Categorical, Integer, Real ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Real ',\n",
       " 'Categorical, Integer, Real ',\n",
       " ' ',\n",
       " 'Categorical ',\n",
       " 'Categorical ',\n",
       " 'Categorical ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Integer ',\n",
       " ' ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical, Real, Integer ',\n",
       " 'Integer ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Integer ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Real ',\n",
       " 'Categorical, Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical ',\n",
       " 'Categorical ',\n",
       " 'Integer ',\n",
       " 'Categorical, Integer, Real ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical ',\n",
       " 'Categorical ',\n",
       " 'Categorical ',\n",
       " 'Categorical ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Categorical ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Categorical ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical ',\n",
       " 'Categorical ',\n",
       " 'Categorical ',\n",
       " 'Categorical ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Categorical ',\n",
       " 'Integer ',\n",
       " 'Categorical, Integer ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Real ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Categorical, Integer ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Categorical, Real ',\n",
       " 'Real ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Categorical ',\n",
       " 'Integer ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Integer ',\n",
       " 'Real ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Integer ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Categorical ',\n",
       " ' ',\n",
       " 'Categorical, Real ',\n",
       " ' ',\n",
       " 'Categorical ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Categorical ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Categorical ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Integer ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Categorical ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Categorical, Integer ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Categorical ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Categorical ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att=[]\n",
    "\n",
    "atts=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[4]')\n",
    "for i in atts[1:623]:\n",
    "    att.append(i.text)\n",
    "    \n",
    "att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20af1934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4177 ',\n",
       " '48842 ',\n",
       " '798 ',\n",
       " '37711 ',\n",
       " '452 ',\n",
       " '6000 ',\n",
       " '226 ',\n",
       " '226 ',\n",
       " '398 ',\n",
       " '205 ',\n",
       " '294 ',\n",
       " '625 ',\n",
       " '16 ',\n",
       " '286 ',\n",
       " '699 ',\n",
       " '198 ',\n",
       " '569 ',\n",
       " '108 ',\n",
       " '1728 ',\n",
       " '48842 ',\n",
       " ' ',\n",
       " '3196 ',\n",
       " '28056 ',\n",
       " ' ',\n",
       " '100 ',\n",
       " '67557 ',\n",
       " '690 ',\n",
       " '125 ',\n",
       " '209 ',\n",
       " '1473 ',\n",
       " '581012 ',\n",
       " '512 ',\n",
       " '366 ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '132 ',\n",
       " '336 ',\n",
       " '194 ',\n",
       " '352 ',\n",
       " '214 ',\n",
       " '306 ',\n",
       " '160 ',\n",
       " '303 ',\n",
       " '155 ',\n",
       " '368 ',\n",
       " ' ',\n",
       " '2310 ',\n",
       " '3279 ',\n",
       " '351 ',\n",
       " '150 ',\n",
       " '7797 ',\n",
       " '104 ',\n",
       " '57 ',\n",
       " ' ',\n",
       " '24 ',\n",
       " '20000 ',\n",
       " '345 ',\n",
       " ' ',\n",
       " '32 ',\n",
       " '148 ',\n",
       " '209 ',\n",
       " '528 ',\n",
       " ' ',\n",
       " '106 ',\n",
       " '128 ',\n",
       " '3190 ',\n",
       " '432 ',\n",
       " '202 ',\n",
       " '2000 ',\n",
       " '8124 ',\n",
       " '476 ',\n",
       " '6598 ',\n",
       " '12960 ',\n",
       " ' ',\n",
       " '5473 ',\n",
       " '5620 ',\n",
       " '10992 ',\n",
       " '90 ',\n",
       " '339 ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '167 ',\n",
       " '15 ',\n",
       " '1389 ',\n",
       " '307 ',\n",
       " '47 ',\n",
       " '23 ',\n",
       " '531 ',\n",
       " '4601 ',\n",
       " '267 ',\n",
       " '267 ',\n",
       " '76 ',\n",
       " ' ',\n",
       " '1000 ',\n",
       " '151 ',\n",
       " '958 ',\n",
       " '7200 ',\n",
       " '10 ',\n",
       " '285 ',\n",
       " '435 ',\n",
       " '527 ',\n",
       " '5000 ',\n",
       " '5000 ',\n",
       " '178 ',\n",
       " '1484 ',\n",
       " '101 ',\n",
       " ' ',\n",
       " '20000 ',\n",
       " '6650 ',\n",
       " '2565 ',\n",
       " '2458285 ',\n",
       " '299285 ',\n",
       " '340 ',\n",
       " '68040 ',\n",
       " ' ',\n",
       " '122 ',\n",
       " '178080 ',\n",
       " '50672 ',\n",
       " '640 ',\n",
       " '9000 ',\n",
       " '10104 ',\n",
       " '256932 ',\n",
       " '640 ',\n",
       " '191779 ',\n",
       " '4000000 ',\n",
       " ' ',\n",
       " '10000 ',\n",
       " '989818 ',\n",
       " '129000 ',\n",
       " ' ',\n",
       " '100000 ',\n",
       " '21578 ',\n",
       " '463 ',\n",
       " '600 ',\n",
       " '332 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '690 ',\n",
       " '1000 ',\n",
       " '270 ',\n",
       " '6435 ',\n",
       " '2310 ',\n",
       " '58000 ',\n",
       " '946 ',\n",
       " '20008 ',\n",
       " '208 ',\n",
       " '528 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1024 ',\n",
       " '10080 ',\n",
       " '50400 ',\n",
       " '1025010 ',\n",
       " '19020 ',\n",
       " '1364 ',\n",
       " '961 ',\n",
       " '517 ',\n",
       " '200 ',\n",
       " '8000000 ',\n",
       " '1030 ',\n",
       " '606 ',\n",
       " '900 ',\n",
       " '2600 ',\n",
       " '1950 ',\n",
       " '13500 ',\n",
       " '4400 ',\n",
       " '2536 ',\n",
       " '300 ',\n",
       " '197 ',\n",
       " '2858 ',\n",
       " '748 ',\n",
       " '11640 ',\n",
       " '1593 ',\n",
       " '1567 ',\n",
       " '22632 ',\n",
       " '360 ',\n",
       " '103 ',\n",
       " '1994 ',\n",
       " '120 ',\n",
       " '4898 ',\n",
       " '2396130 ',\n",
       " '16772 ',\n",
       " '5875 ',\n",
       " '503 ',\n",
       " '51 ',\n",
       " '106 ',\n",
       " '2126 ',\n",
       " '5456 ',\n",
       " '8800 ',\n",
       " '164860 ',\n",
       " ' ',\n",
       " '1941 ',\n",
       " '130065 ',\n",
       " '515345 ',\n",
       " '440 ',\n",
       " ' ',\n",
       " '53500 ',\n",
       " '8235 ',\n",
       " ' ',\n",
       " '5749132 ',\n",
       " '2215 ',\n",
       " '310 ',\n",
       " '10000 ',\n",
       " '3000 ',\n",
       " '1500 ',\n",
       " '30000 ',\n",
       " '2500 ',\n",
       " '4143 ',\n",
       " '64 ',\n",
       " '53414 ',\n",
       " '65554 ',\n",
       " '45211 ',\n",
       " '1138562 ',\n",
       " '13910 ',\n",
       " '583 ',\n",
       " '2551 ',\n",
       " '34465 ',\n",
       " '5574 ',\n",
       " '245057 ',\n",
       " '182 ',\n",
       " '3850505 ',\n",
       " '138 ',\n",
       " '1080 ',\n",
       " '2075259 ',\n",
       " '210 ',\n",
       " '115 ',\n",
       " '3960456 ',\n",
       " ' ',\n",
       " '10299 ',\n",
       " '1600 ',\n",
       " '768 ',\n",
       " '308 ',\n",
       " '100 ',\n",
       " '237 ',\n",
       " '434874 ',\n",
       " '536 ',\n",
       " '140000 ',\n",
       " '6118 ',\n",
       " '165632 ',\n",
       " '18000 ',\n",
       " '540 ',\n",
       " '931 ',\n",
       " '1055 ',\n",
       " '100 ',\n",
       " '9120 ',\n",
       " '403 ',\n",
       " '111740 ',\n",
       " '10421 ',\n",
       " '5820 ',\n",
       " '403 ',\n",
       " '14980 ',\n",
       " '45730 ',\n",
       " '2584 ',\n",
       " '1372 ',\n",
       " '306 ',\n",
       " '120000 ',\n",
       " '13910 ',\n",
       " '2747 ',\n",
       " '3395 ',\n",
       " '39242 ',\n",
       " '4137 ',\n",
       " '17389 ',\n",
       " '51 ',\n",
       " '470 ',\n",
       " '132 ',\n",
       " '5000000 ',\n",
       " '11000000 ',\n",
       " '250 ',\n",
       " '126 ',\n",
       " ' ',\n",
       " '4889 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '340 ',\n",
       " '501 ',\n",
       " '45781 ',\n",
       " '1503 ',\n",
       " '440 ',\n",
       " '2000 ',\n",
       " '9568 ',\n",
       " '168 ',\n",
       " '100000 ',\n",
       " '5665 ',\n",
       " '79 ',\n",
       " '127 ',\n",
       " '1040 ',\n",
       " '9900 ',\n",
       " '560 ',\n",
       " '60021 ',\n",
       " '1419 ',\n",
       " '101 ',\n",
       " '399 ',\n",
       " '58 ',\n",
       " '180 ',\n",
       " '21048 ',\n",
       " ' ',\n",
       " '750 ',\n",
       " '3000 ',\n",
       " '150 ',\n",
       " '1059 ',\n",
       " '11934 ',\n",
       " '27965 ',\n",
       " '216 ',\n",
       " '120 ',\n",
       " '649 ',\n",
       " '370 ',\n",
       " '4178504 ',\n",
       " '221579 ',\n",
       " '10800 ',\n",
       " '58509 ',\n",
       " '129685 ',\n",
       " '2456 ',\n",
       " '2921 ',\n",
       " '1151 ',\n",
       " '6590 ',\n",
       " '3000 ',\n",
       " '39797 ',\n",
       " '326 ',\n",
       " '913 ',\n",
       " '168286 ',\n",
       " '400 ',\n",
       " '314080 ',\n",
       " '637 ',\n",
       " '1710671 ',\n",
       " '12000 ',\n",
       " '10929 ',\n",
       " '1080 ',\n",
       " '40000 ',\n",
       " '43930257 ',\n",
       " '230318 ',\n",
       " '10500000 ',\n",
       " '13197 ',\n",
       " ' ',\n",
       " '30000 ',\n",
       " '324 ',\n",
       " '541909 ',\n",
       " '11164866 ',\n",
       " '163 ',\n",
       " '373 ',\n",
       " '20560 ',\n",
       " '40 ',\n",
       " '422937 ',\n",
       " '9358 ',\n",
       " '640 ',\n",
       " '919438 ',\n",
       " '40949 ',\n",
       " '5744 ',\n",
       " '10503 ',\n",
       " '42240 ',\n",
       " '102944 ',\n",
       " '500 ',\n",
       " '9782222 ',\n",
       " '11463 ',\n",
       " '17898 ',\n",
       " '1885 ',\n",
       " '19735 ',\n",
       " '1540 ',\n",
       " '4007 ',\n",
       " '153540 ',\n",
       " '606 ',\n",
       " '1353 ',\n",
       " '1956 ',\n",
       " '43824 ',\n",
       " '3942 ',\n",
       " '858 ',\n",
       " '287 ',\n",
       " '17764280 ',\n",
       " '106574 ',\n",
       " '9358 ',\n",
       " '11500 ',\n",
       " '92000 ',\n",
       " '315 ',\n",
       " '78095 ',\n",
       " '130 ',\n",
       " '74 ',\n",
       " '52854 ',\n",
       " '77 ',\n",
       " '811 ',\n",
       " '504 ',\n",
       " '401 ',\n",
       " '2856 ',\n",
       " '10546 ',\n",
       " '801 ',\n",
       " '1540 ',\n",
       " '1451 ',\n",
       " '1075 ',\n",
       " '78095 ',\n",
       " '7195 ',\n",
       " '3600 ',\n",
       " '76 ',\n",
       " '60 ',\n",
       " '405 ',\n",
       " '303 ',\n",
       " '303 ',\n",
       " '107888 ',\n",
       " '76000 ',\n",
       " '10000 ',\n",
       " '180 ',\n",
       " '745000 ',\n",
       " '12234 ',\n",
       " '292 ',\n",
       " '104 ',\n",
       " '60000 ',\n",
       " '2000 ',\n",
       " '165 ',\n",
       " '217 ',\n",
       " '1175 ',\n",
       " '704 ',\n",
       " '75128 ',\n",
       " '90 ',\n",
       " '90 ',\n",
       " '50 ',\n",
       " '71 ',\n",
       " '93239 ',\n",
       " '540 ',\n",
       " '105 ',\n",
       " '6611 ',\n",
       " '15 ',\n",
       " '372 ',\n",
       " '58000 ',\n",
       " '4960 ',\n",
       " '241600 ',\n",
       " '130000 ',\n",
       " '7062606 ',\n",
       " '740 ',\n",
       " '70 ',\n",
       " '2205 ',\n",
       " '10721 ',\n",
       " '640 ',\n",
       " '1000 ',\n",
       " '116 ',\n",
       " '1672 ',\n",
       " '322 ',\n",
       " '93600 ',\n",
       " '3060 ',\n",
       " '5879 ',\n",
       " '9200 ',\n",
       " '20000 ',\n",
       " '20867 ',\n",
       " ' ',\n",
       " '4143 ',\n",
       " '215063 ',\n",
       " '6000000 ',\n",
       " '21263 ',\n",
       " '63000000 ',\n",
       " '10190 ',\n",
       " '300 ',\n",
       " '12330 ',\n",
       " '5180 ',\n",
       " '756 ',\n",
       " '10000 ',\n",
       " '80 ',\n",
       " '1184 ',\n",
       " '1047 ',\n",
       " '777 ',\n",
       " '249 ',\n",
       " '414 ',\n",
       " ' ',\n",
       " '143 ',\n",
       " '7840 ',\n",
       " '30000 ',\n",
       " '35717 ',\n",
       " '135 ',\n",
       " '980 ',\n",
       " '5456 ',\n",
       " '120 ',\n",
       " '4095000 ',\n",
       " '7051 ',\n",
       " '240 ',\n",
       " '48204 ',\n",
       " '260000 ',\n",
       " '288000 ',\n",
       " '8300000 ',\n",
       " '125 ',\n",
       " '170 ',\n",
       " '141712 ',\n",
       " '3916 ',\n",
       " '6262 ',\n",
       " '420768 ',\n",
       " '1067371 ',\n",
       " '1385 ',\n",
       " '908 ',\n",
       " '546 ',\n",
       " '13956534 ',\n",
       " '15630426 ',\n",
       " '8992 ',\n",
       " '1687 ',\n",
       " '779 ',\n",
       " '1056 ',\n",
       " '590 ',\n",
       " '21643 ',\n",
       " '7750 ',\n",
       " '14057567 ',\n",
       " '27170754 ',\n",
       " '597 ',\n",
       " '329 ',\n",
       " '299 ',\n",
       " '20000 ',\n",
       " '26136 ',\n",
       " '1000 ',\n",
       " '399 ',\n",
       " '24017 ',\n",
       " '325834 ',\n",
       " '2916697 ',\n",
       " '22470 ',\n",
       " '189 ',\n",
       " '520 ',\n",
       " '826 ',\n",
       " '2279 ',\n",
       " '28764 ',\n",
       " '7107 ',\n",
       " '288000 ',\n",
       " '9800 ',\n",
       " '4760 ',\n",
       " '72 ',\n",
       " '1450 ',\n",
       " '170 ',\n",
       " '1984 ',\n",
       " '2955 ',\n",
       " '65532 ',\n",
       " '65919 ',\n",
       " '2111 ',\n",
       " '3810 ',\n",
       " '18 ',\n",
       " '244 ',\n",
       " '104 ',\n",
       " '139 ',\n",
       " '360177 ',\n",
       " '36733 ',\n",
       " '4480 ',\n",
       " '165474 ',\n",
       " '1985 ',\n",
       " '10000 ',\n",
       " '232 ',\n",
       " '150 ',\n",
       " '11 ',\n",
       " '14057567 ',\n",
       " '8760 ',\n",
       " '48 ',\n",
       " '6321 ',\n",
       " '3150 ',\n",
       " '17256 ',\n",
       " '187 ',\n",
       " '399 ',\n",
       " '14 ',\n",
       " '467 ',\n",
       " '597 ',\n",
       " '23700 ',\n",
       " '615 ',\n",
       " '6819 ',\n",
       " '1000 ',\n",
       " ' ',\n",
       " '2633 ',\n",
       " '200 ',\n",
       " '13028 ',\n",
       " '800 ',\n",
       " '1700 ',\n",
       " '521 ',\n",
       " '120000 ',\n",
       " '666 ',\n",
       " '88 ',\n",
       " '200 ',\n",
       " '2279 ',\n",
       " '23570 ',\n",
       " '10000 ',\n",
       " '37700 ',\n",
       " '1850 ',\n",
       " '11 ',\n",
       " '147270 ',\n",
       " '3150 ',\n",
       " '17256 ',\n",
       " '597 ',\n",
       " '7624 ',\n",
       " '314 ',\n",
       " '1197 ',\n",
       " '70 ',\n",
       " '7624 ',\n",
       " '26737 ',\n",
       " '10000 ',\n",
       " '13611 ',\n",
       " '12684 ',\n",
       " '48 ',\n",
       " '731 ',\n",
       " '731 ',\n",
       " '557 ',\n",
       " '107 ',\n",
       " '158716 ',\n",
       " '15744 ',\n",
       " '153000 ',\n",
       " '557 ',\n",
       " '36 ',\n",
       " '4200 ',\n",
       " '61069 ',\n",
       " '52417 ',\n",
       " '900 ',\n",
       " '35040 ',\n",
       " '4746 ',\n",
       " '73 ',\n",
       " '11000 ',\n",
       " '4465 ',\n",
       " '145 ',\n",
       " '202 ',\n",
       " '221 ',\n",
       " '597 ',\n",
       " '298 ',\n",
       " '110341 ',\n",
       " '705 ',\n",
       " '2101 ',\n",
       " '1765 ',\n",
       " '150 ',\n",
       " '4000 ',\n",
       " '6272 ',\n",
       " '1996 ',\n",
       " '35040 ',\n",
       " '75840 ',\n",
       " '400 ',\n",
       " '1014 ',\n",
       " '10129 ',\n",
       " '4000 ']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insta=[]\n",
    "\n",
    "instas=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[5]')\n",
    "for i in instas[1:623]:\n",
    "    insta.append(i.text)\n",
    "    \n",
    "insta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1ca7134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8 ',\n",
       " '14 ',\n",
       " '38 ',\n",
       " '294 ',\n",
       " '279 ',\n",
       " '7 ',\n",
       " ' ',\n",
       " '69 ',\n",
       " '8 ',\n",
       " '26 ',\n",
       " '1 ',\n",
       " '4 ',\n",
       " '4 ',\n",
       " '9 ',\n",
       " '10 ',\n",
       " '34 ',\n",
       " '32 ',\n",
       " '13 ',\n",
       " '6 ',\n",
       " '14 ',\n",
       " '22 ',\n",
       " '36 ',\n",
       " '6 ',\n",
       " ' ',\n",
       " '6 ',\n",
       " '42 ',\n",
       " '15 ',\n",
       " ' ',\n",
       " '9 ',\n",
       " '9 ',\n",
       " '54 ',\n",
       " '39 ',\n",
       " '33 ',\n",
       " '20 ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '12 ',\n",
       " '8 ',\n",
       " '30 ',\n",
       " ' ',\n",
       " '10 ',\n",
       " '3 ',\n",
       " '5 ',\n",
       " '75 ',\n",
       " '19 ',\n",
       " '27 ',\n",
       " ' ',\n",
       " '19 ',\n",
       " '1558 ',\n",
       " '34 ',\n",
       " '4 ',\n",
       " '617 ',\n",
       " '12 ',\n",
       " '16 ',\n",
       " '7 ',\n",
       " '4 ',\n",
       " '16 ',\n",
       " '7 ',\n",
       " ' ',\n",
       " '56 ',\n",
       " '18 ',\n",
       " '8 ',\n",
       " '22 ',\n",
       " ' ',\n",
       " '58 ',\n",
       " ' ',\n",
       " '61 ',\n",
       " '7 ',\n",
       " ' ',\n",
       " '649 ',\n",
       " '22 ',\n",
       " '168 ',\n",
       " '168 ',\n",
       " '8 ',\n",
       " ' ',\n",
       " '10 ',\n",
       " '64 ',\n",
       " '16 ',\n",
       " '8 ',\n",
       " '17 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '72 ',\n",
       " '4 ',\n",
       " '6 ',\n",
       " '10 ',\n",
       " '35 ',\n",
       " '35 ',\n",
       " '4 ',\n",
       " '102 ',\n",
       " '57 ',\n",
       " '22 ',\n",
       " '44 ',\n",
       " '45 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '5 ',\n",
       " '9 ',\n",
       " '21 ',\n",
       " '32 ',\n",
       " '17 ',\n",
       " '16 ',\n",
       " '38 ',\n",
       " '21 ',\n",
       " '40 ',\n",
       " '13 ',\n",
       " '8 ',\n",
       " '17 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '15 ',\n",
       " '22 ',\n",
       " '68 ',\n",
       " '40 ',\n",
       " '17 ',\n",
       " '89 ',\n",
       " ' ',\n",
       " '4 ',\n",
       " '12 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '86 ',\n",
       " '72 ',\n",
       " '61 ',\n",
       " '12 ',\n",
       " '481 ',\n",
       " '42 ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '5 ',\n",
       " '90 ',\n",
       " ' ',\n",
       " '5 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '14 ',\n",
       " '20 ',\n",
       " '13 ',\n",
       " '36 ',\n",
       " '19 ',\n",
       " '9 ',\n",
       " '18 ',\n",
       " '4 ',\n",
       " '60 ',\n",
       " '10 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '10 ',\n",
       " '4 ',\n",
       " '3 ',\n",
       " '11 ',\n",
       " '11 ',\n",
       " ' ',\n",
       " '6 ',\n",
       " '13 ',\n",
       " ' ',\n",
       " '100000 ',\n",
       " '9 ',\n",
       " '101 ',\n",
       " '10000 ',\n",
       " '20000 ',\n",
       " '100000 ',\n",
       " '5000 ',\n",
       " '500 ',\n",
       " '73 ',\n",
       " '43 ',\n",
       " '23 ',\n",
       " '3 ',\n",
       " '5 ',\n",
       " ' ',\n",
       " '256 ',\n",
       " '591 ',\n",
       " '70 ',\n",
       " '91 ',\n",
       " '10 ',\n",
       " '128 ',\n",
       " '6 ',\n",
       " '12 ',\n",
       " '3231961 ',\n",
       " '5409 ',\n",
       " '26 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '10 ',\n",
       " '23 ',\n",
       " '24 ',\n",
       " '13 ',\n",
       " '8 ',\n",
       " ' ',\n",
       " '27 ',\n",
       " '50 ',\n",
       " '90 ',\n",
       " '138672 ',\n",
       " ' ',\n",
       " '386 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '12 ',\n",
       " '147 ',\n",
       " '6 ',\n",
       " '8 ',\n",
       " '27 ',\n",
       " '10000 ',\n",
       " '20000 ',\n",
       " '10000 ',\n",
       " '54877 ',\n",
       " '4702 ',\n",
       " '24 ',\n",
       " '29 ',\n",
       " '17 ',\n",
       " '3 ',\n",
       " '128 ',\n",
       " '10 ',\n",
       " '242 ',\n",
       " '120 ',\n",
       " ' ',\n",
       " '4 ',\n",
       " '13 ',\n",
       " '52 ',\n",
       " '47 ',\n",
       " '857 ',\n",
       " '9 ',\n",
       " '7 ',\n",
       " '200 ',\n",
       " '4 ',\n",
       " ' ',\n",
       " '561 ',\n",
       " '64 ',\n",
       " '8 ',\n",
       " '7 ',\n",
       " '10 ',\n",
       " '9 ',\n",
       " '4 ',\n",
       " '8 ',\n",
       " '77 ',\n",
       " '51 ',\n",
       " '18 ',\n",
       " '1950000 ',\n",
       " '18 ',\n",
       " '1300 ',\n",
       " '41 ',\n",
       " '6 ',\n",
       " '5625 ',\n",
       " '5 ',\n",
       " ' ',\n",
       " '7 ',\n",
       " '33 ',\n",
       " '5 ',\n",
       " '15 ',\n",
       " '9 ',\n",
       " '19 ',\n",
       " '5 ',\n",
       " '5 ',\n",
       " '1000000 ',\n",
       " '129 ',\n",
       " ' ',\n",
       " '20 ',\n",
       " '152 ',\n",
       " '24 ',\n",
       " '16 ',\n",
       " '35 ',\n",
       " '17 ',\n",
       " '5 ',\n",
       " '18 ',\n",
       " '28 ',\n",
       " '7 ',\n",
       " '309 ',\n",
       " '3 ',\n",
       " '6 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '16 ',\n",
       " '13 ',\n",
       " '5 ',\n",
       " '6 ',\n",
       " '8 ',\n",
       " '2 ',\n",
       " '4 ',\n",
       " '148 ',\n",
       " '55 ',\n",
       " '17 ',\n",
       " '8 ',\n",
       " '42 ',\n",
       " '26 ',\n",
       " '50 ',\n",
       " '2 ',\n",
       " '281 ',\n",
       " '120 ',\n",
       " ' ',\n",
       " '6 ',\n",
       " '120432 ',\n",
       " '150000 ',\n",
       " '529 ',\n",
       " ' ',\n",
       " '16 ',\n",
       " '2500 ',\n",
       " '5 ',\n",
       " '68 ',\n",
       " '16 ',\n",
       " '100 ',\n",
       " '216 ',\n",
       " '23 ',\n",
       " '33 ',\n",
       " '140256 ',\n",
       " '19 ',\n",
       " '20 ',\n",
       " '20 ',\n",
       " '49 ',\n",
       " '12 ',\n",
       " '30 ',\n",
       " '5232 ',\n",
       " '20 ',\n",
       " '1 ',\n",
       " ' ',\n",
       " '61 ',\n",
       " '27 ',\n",
       " '53 ',\n",
       " '11 ',\n",
       " '25 ',\n",
       " '0 ',\n",
       " '20 ',\n",
       " '9 ',\n",
       " '3 ',\n",
       " '561 ',\n",
       " '82 ',\n",
       " '13 ',\n",
       " '16 ',\n",
       " '13 ',\n",
       " '28 ',\n",
       " '4 ',\n",
       " ' ',\n",
       " '24 ',\n",
       " '34 ',\n",
       " '8 ',\n",
       " '128 ',\n",
       " '15 ',\n",
       " '513 ',\n",
       " '7 ',\n",
       " '7 ',\n",
       " '5 ',\n",
       " '15 ',\n",
       " '480000 ',\n",
       " '11 ',\n",
       " '54 ',\n",
       " '561 ',\n",
       " '64 ',\n",
       " '6 ',\n",
       " '116 ',\n",
       " '19 ',\n",
       " ' ',\n",
       " '5812 ',\n",
       " '9 ',\n",
       " '32 ',\n",
       " '29 ',\n",
       " '67 ',\n",
       " ' ',\n",
       " '25 ',\n",
       " '6400 ',\n",
       " '10 ',\n",
       " '5 ',\n",
       " '13 ',\n",
       " '98 ',\n",
       " '36 ',\n",
       " '69 ',\n",
       " '2158859 ',\n",
       " '518 ',\n",
       " '15 ',\n",
       " '179 ',\n",
       " ' ',\n",
       " '12 ',\n",
       " '38 ',\n",
       " '65 ',\n",
       " '102 ',\n",
       " '86 ',\n",
       " '7 ',\n",
       " '53 ',\n",
       " '20 ',\n",
       " '1 ',\n",
       " '71 ',\n",
       " '29 ',\n",
       " '20531 ',\n",
       " '65 ',\n",
       " '3 ',\n",
       " '22 ',\n",
       " '38 ',\n",
       " '22 ',\n",
       " '4814 ',\n",
       " '698 ',\n",
       " '13 ',\n",
       " '10 ',\n",
       " '59 ',\n",
       " '56 ',\n",
       " '482 ',\n",
       " '171 ',\n",
       " '5 ',\n",
       " '500 ',\n",
       " '411 ',\n",
       " '8519 ',\n",
       " '21 ',\n",
       " '21 ',\n",
       " '171 ',\n",
       " '7 ',\n",
       " '49 ',\n",
       " '12 ',\n",
       " '3 ',\n",
       " '21 ',\n",
       " '9 ',\n",
       " '8 ',\n",
       " '7 ',\n",
       " '2 ',\n",
       " '11 ',\n",
       " '11 ',\n",
       " '173 ',\n",
       " '5 ',\n",
       " '15 ',\n",
       " '3 ',\n",
       " '105 ',\n",
       " '25000 ',\n",
       " ' ',\n",
       " '18 ',\n",
       " '21000 ',\n",
       " '115 ',\n",
       " '21 ',\n",
       " '206 ',\n",
       " '43680 ',\n",
       " '8 ',\n",
       " '10 ',\n",
       " '59 ',\n",
       " '10 ',\n",
       " '5 ',\n",
       " '5 ',\n",
       " '1000 ',\n",
       " '138 ',\n",
       " ' ',\n",
       " '16 ',\n",
       " '2 ',\n",
       " '10 ',\n",
       " ' ',\n",
       " '8 ',\n",
       " '6 ',\n",
       " '129 ',\n",
       " '81 ',\n",
       " '12 ',\n",
       " '6 ',\n",
       " '22 ',\n",
       " '18 ',\n",
       " '9 ',\n",
       " '754 ',\n",
       " '14 ',\n",
       " '5 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '18 ',\n",
       " '7 ',\n",
       " '7 ',\n",
       " ' ',\n",
       " '7 ',\n",
       " '5 ',\n",
       " '6 ',\n",
       " '4 ',\n",
       " '18 ',\n",
       " '11 ',\n",
       " '25 ',\n",
       " ' ',\n",
       " '20 ',\n",
       " '12 ',\n",
       " '46 ',\n",
       " '9 ',\n",
       " '8 ',\n",
       " '49 ',\n",
       " '11 ',\n",
       " '8 ',\n",
       " '54 ',\n",
       " '36 ',\n",
       " '3916 ',\n",
       " '710 ',\n",
       " '18 ',\n",
       " '8 ',\n",
       " '29 ',\n",
       " '7 ',\n",
       " '9 ',\n",
       " '37 ',\n",
       " '6 ',\n",
       " '1024 ',\n",
       " '1024 ',\n",
       " '14 ',\n",
       " '7 ',\n",
       " '8265 ',\n",
       " '29 ',\n",
       " '25 ',\n",
       " '3 ',\n",
       " '115 ',\n",
       " '1 ',\n",
       " '12 ',\n",
       " '13 ',\n",
       " '200000 ',\n",
       " '6 ',\n",
       " '21 ',\n",
       " '4 ',\n",
       " '2400 ',\n",
       " '175 ',\n",
       " '10 ',\n",
       " '4714 ',\n",
       " '23 ',\n",
       " '17 ',\n",
       " '2 ',\n",
       " '9 ',\n",
       " '8 ',\n",
       " '280 ',\n",
       " '49 ',\n",
       " '3 ',\n",
       " '14 ',\n",
       " '19 ',\n",
       " ' ',\n",
       " '54 ',\n",
       " '8 ',\n",
       " '1087 ',\n",
       " '12 ',\n",
       " '3 ',\n",
       " '17 ',\n",
       " '8 ',\n",
       " '9 ',\n",
       " '12 ',\n",
       " '1656 ',\n",
       " '6 ',\n",
       " '2 ',\n",
       " '11 ',\n",
       " '533 ',\n",
       " '14 ',\n",
       " '84 ',\n",
       " '22 ',\n",
       " '16 ',\n",
       " '52 ',\n",
       " '19 ',\n",
       " '3 ',\n",
       " '14 ',\n",
       " '321 ',\n",
       " '13 ',\n",
       " '13 ',\n",
       " '55 ',\n",
       " '39 ',\n",
       " '4 ',\n",
       " '7 ',\n",
       " '79 ',\n",
       " '1 ',\n",
       " ' ',\n",
       " '14 ',\n",
       " '96 ',\n",
       " '21 ',\n",
       " ' ',\n",
       " '5 ',\n",
       " '2 ',\n",
       " '69 ',\n",
       " '9 ',\n",
       " '124 ',\n",
       " '20 ',\n",
       " '25 ',\n",
       " '11 ',\n",
       " '19 ',\n",
       " '9 ',\n",
       " '9 ',\n",
       " '5 ',\n",
       " '7 ',\n",
       " '4006 ',\n",
       " '2 ',\n",
       " '19 ',\n",
       " '4 ',\n",
       " '13 ',\n",
       " '55 ',\n",
       " '1 ',\n",
       " '7842 ',\n",
       " '15 ',\n",
       " '15 ',\n",
       " '70 ',\n",
       " '7842 ',\n",
       " '4 ',\n",
       " '14 ',\n",
       " '17 ',\n",
       " '23 ',\n",
       " '321 ',\n",
       " '1068 ',\n",
       " '1068 ',\n",
       " '5 ',\n",
       " '6 ',\n",
       " '4 ',\n",
       " ' ',\n",
       " '5 ',\n",
       " '5 ',\n",
       " '15 ',\n",
       " '7 ',\n",
       " '21 ',\n",
       " '9 ',\n",
       " '8 ',\n",
       " '11 ',\n",
       " '21 ',\n",
       " '22 ',\n",
       " '2 ',\n",
       " '241 ',\n",
       " '33 ',\n",
       " '29 ',\n",
       " '7 ',\n",
       " '1 ',\n",
       " ' ',\n",
       " '4 ',\n",
       " '11 ',\n",
       " '47 ',\n",
       " '10 ',\n",
       " '3 ',\n",
       " '2 ',\n",
       " '632 ',\n",
       " '6826 ',\n",
       " '11 ',\n",
       " '525 ',\n",
       " '50 ',\n",
       " '7 ',\n",
       " '16 ',\n",
       " '2 ']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num=[]\n",
    "\n",
    "nums=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[6]')\n",
    "for i in nums[1:623]:\n",
    "    num.append(i.text)\n",
    "    \n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff948ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1995 ',\n",
       " '1996 ',\n",
       " ' ',\n",
       " '1998 ',\n",
       " '1998 ',\n",
       " '1992 ',\n",
       " '1987 ',\n",
       " '1992 ',\n",
       " '1993 ',\n",
       " '1987 ',\n",
       " '1994 ',\n",
       " '1994 ',\n",
       " ' ',\n",
       " '1988 ',\n",
       " '1992 ',\n",
       " '1995 ',\n",
       " '1995 ',\n",
       " '1990 ',\n",
       " '1997 ',\n",
       " '1996 ',\n",
       " '1988 ',\n",
       " '1989 ',\n",
       " '1994 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1995 ',\n",
       " ' ',\n",
       " '1992 ',\n",
       " '1987 ',\n",
       " '1997 ',\n",
       " '1998 ',\n",
       " '1995 ',\n",
       " '1998 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1994 ',\n",
       " ' ',\n",
       " '1989 ',\n",
       " '1996 ',\n",
       " '1990 ',\n",
       " '1990 ',\n",
       " '1987 ',\n",
       " '1999 ',\n",
       " '1989 ',\n",
       " '1988 ',\n",
       " '1988 ',\n",
       " '1989 ',\n",
       " ' ',\n",
       " '1990 ',\n",
       " '1998 ',\n",
       " '1989 ',\n",
       " '1988 ',\n",
       " '1994 ',\n",
       " '1990 ',\n",
       " '1988 ',\n",
       " '1988 ',\n",
       " '1990 ',\n",
       " '1991 ',\n",
       " '1990 ',\n",
       " ' ',\n",
       " '1992 ',\n",
       " '1988 ',\n",
       " '1990 ',\n",
       " '1996 ',\n",
       " '1995 ',\n",
       " '1990 ',\n",
       " ' ',\n",
       " '1992 ',\n",
       " '1992 ',\n",
       " '1994 ',\n",
       " ' ',\n",
       " '1987 ',\n",
       " '1994 ',\n",
       " '1994 ',\n",
       " '1997 ',\n",
       " '1991 ',\n",
       " '1995 ',\n",
       " '1998 ',\n",
       " '1998 ',\n",
       " '1993 ',\n",
       " '1988 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1992 ',\n",
       " '1993 ',\n",
       " '1988 ',\n",
       " '1989 ',\n",
       " '1988 ',\n",
       " '1987 ',\n",
       " '1993 ',\n",
       " '1988 ',\n",
       " '1999 ',\n",
       " '2001 ',\n",
       " '2001 ',\n",
       " ' ',\n",
       " '1992 ',\n",
       " '1993 ',\n",
       " '1997 ',\n",
       " '1991 ',\n",
       " '1987 ',\n",
       " '1994 ',\n",
       " '1988 ',\n",
       " '1987 ',\n",
       " '1993 ',\n",
       " '1988 ',\n",
       " '1988 ',\n",
       " '1991 ',\n",
       " '1996 ',\n",
       " '1990 ',\n",
       " ' ',\n",
       " '1999 ',\n",
       " '1999 ',\n",
       " '2002 ',\n",
       " ' ',\n",
       " '2000 ',\n",
       " '1999 ',\n",
       " '1999 ',\n",
       " '2001 ',\n",
       " '1999 ',\n",
       " '1999 ',\n",
       " '2000 ',\n",
       " '1999 ',\n",
       " '2000 ',\n",
       " '1999 ',\n",
       " '1999 ',\n",
       " ' ',\n",
       " '1998 ',\n",
       " '1999 ',\n",
       " '2001 ',\n",
       " '1999 ',\n",
       " ' ',\n",
       " '2003 ',\n",
       " '1999 ',\n",
       " '1999 ',\n",
       " '1997 ',\n",
       " '1999 ',\n",
       " '1999 ',\n",
       " '1998 ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1994 ',\n",
       " ' ',\n",
       " '1993 ',\n",
       " '1990 ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1989 ',\n",
       " '2006 ',\n",
       " '2006 ',\n",
       " '2007 ',\n",
       " '2007 ',\n",
       " '2007 ',\n",
       " '2007 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2007 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2009 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2009 ',\n",
       " '2009 ',\n",
       " '2009 ',\n",
       " '2009 ',\n",
       " '2009 ',\n",
       " '2009 ',\n",
       " '2010 ',\n",
       " '2009 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2014 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2013 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2015 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2014 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2015 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2015 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2016 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2019 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2019 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2021 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2021 ',\n",
       " '2021 ']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year=[]\n",
    "\n",
    "years=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[7]')\n",
    "for i in years[1:623]:\n",
    "    year.append(i.text)\n",
    "    \n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d9a8922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622 622 622 622 622 622 622\n"
     ]
    }
   ],
   "source": [
    "print(len(name),len(data),len(task),len(att),len(insta),len(num),len(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66ff3f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset name</th>\n",
       "      <th>Data type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute type</th>\n",
       "      <th>No of instances</th>\n",
       "      <th>No of attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twitte...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset name  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                                            Annealing   \n",
       "3                         Anonymous Microsoft Web Data   \n",
       "4                                           Arrhythmia   \n",
       "..                                                 ...   \n",
       "617  Influenza outbreak event prediction via Twitte...   \n",
       "618                      Turkish Music Emotion Dataset   \n",
       "619                      Maternal Health Risk Data Set   \n",
       "620                          Room Occupancy Estimation   \n",
       "621  Image Recognition Task Execution Times in Mobi...   \n",
       "\n",
       "                      Data type                  Task  \\\n",
       "0                 Multivariate        Classification    \n",
       "1                 Multivariate        Classification    \n",
       "2                 Multivariate        Classification    \n",
       "3                                Recommender-Systems    \n",
       "4                 Multivariate        Classification    \n",
       "..                          ...                   ...   \n",
       "617               Multivariate        Classification    \n",
       "618               Multivariate        Classification    \n",
       "619                                   Classification    \n",
       "620  Multivariate, Time-Series        Classification    \n",
       "621                 Univariate            Regression    \n",
       "\n",
       "                  Attribute type No of instances No of attribute   Year  \n",
       "0    Categorical, Integer, Real            4177               8   1995   \n",
       "1          Categorical, Integer           48842              14   1996   \n",
       "2    Categorical, Integer, Real             798              38          \n",
       "3                   Categorical           37711             294   1998   \n",
       "4    Categorical, Integer, Real             452             279   1998   \n",
       "..                           ...             ...             ...    ...  \n",
       "617               Integer, Real           75840             525   2020   \n",
       "618               Integer, Real             400              50   2020   \n",
       "619                                        1014               7   2020   \n",
       "620                        Real           10129              16   2021   \n",
       "621                        Real            4000               2   2021   \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Dataset name':name,'Data type':data,'Task':task,'Attribute type':att,'No of instances':insta,'No of attribute':num,'Year':year})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f019addf",
   "metadata": {},
   "source": [
    "# 9. Scrape the details of Data science recruiters Url = https://www.naukri.com/hr-recruiters-consultants  You have to find the following details:A) Name B) Designation C)Company D)Skills they hire for E) Location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e28bbef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1583dee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1746b9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com/hr-recruiters-consultants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63044fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Santhosh Kumar',\n",
       " 'Gauri Bhosle',\n",
       " 'Surendra R',\n",
       " 'Neha Pandey',\n",
       " 'Vinita Raut',\n",
       " 'BALA Sakthivelmuthu',\n",
       " 'Prarit Gupta',\n",
       " 'Raghu Hrexecutive',\n",
       " 'Take jobs',\n",
       " 'iNFIN Technologies',\n",
       " 'Punit Kumar Bhidodiya',\n",
       " 'Ishan Ahmed',\n",
       " 'Sreekanth Menon',\n",
       " 'TechCube IT Services Pvt Ltd',\n",
       " 'Fatte Chand Soni',\n",
       " 'Koustav Bose',\n",
       " 'Vaishambi Saxena',\n",
       " 'Be Tuned Solutions',\n",
       " 'Prerna Kashyap',\n",
       " 'Sunil Joshi',\n",
       " 'Stella',\n",
       " 'Pranav Varia',\n",
       " 'Emma Rodrigues',\n",
       " 'Sonal Sharma',\n",
       " 'Sita Chhetri',\n",
       " 'Nikhil Bhardwaj',\n",
       " 'Vibhuti Bhatt',\n",
       " 'Pushkar Gupta',\n",
       " 'Anjali Gupta',\n",
       " 'katrina Dikoster',\n",
       " 'shalini gupta',\n",
       " 'Pradeep Naik',\n",
       " 'K Gayaj',\n",
       " 'Ms Chitra Doshi',\n",
       " 'Deepak Tripathi',\n",
       " 'ASHISH MAURYA',\n",
       " 'Charmi Dave',\n",
       " 'Lilly Mohindru',\n",
       " 'Nivedita Rawat',\n",
       " 'Sandeep Samantaray',\n",
       " 'Vijay Bharadvaj',\n",
       " 'iota Academy',\n",
       " 'Arindam Bhattacharjee',\n",
       " 'Jyoti Chopra',\n",
       " 'Marlin',\n",
       " 'Aditya Choudhry',\n",
       " 'Nimble Organics',\n",
       " 'RAJ KUMAR PANDEY',\n",
       " 'BVL REALTY',\n",
       " 'Kavya M']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = []\n",
    "\n",
    "names = driver.find_elements(By.XPATH,'//span[@class=\"fl ellipsis\"]')\n",
    "for i in names:\n",
    "    name.append(i.text)\n",
    "    \n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69896199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe0a3e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Associate Manager Human Resources',\n",
       " 'Human Resources',\n",
       " 'Company Recruiter',\n",
       " 'Company Recruiter',\n",
       " 'Company Recruiter',\n",
       " 'Company Recruiter',\n",
       " 'Human Resource Manager',\n",
       " 'Human Resource manager',\n",
       " 'Human Resources',\n",
       " 'Human Resources',\n",
       " 'Human Resource Manager',\n",
       " 'Human Resource Manager',\n",
       " 'Human Resources',\n",
       " 'Human Resource Manager',\n",
       " 'Human Resource Generalist',\n",
       " 'human resource manager',\n",
       " 'Human Resources',\n",
       " 'Human Resource Manager',\n",
       " 'Human Resource Manager',\n",
       " 'Human Resource Manager',\n",
       " 'Human Resources',\n",
       " 'Human Resource Manager',\n",
       " 'Human Resource Manager',\n",
       " 'Human Resource Manager',\n",
       " 'Human Resource Manager',\n",
       " 'Regional HR Manager',\n",
       " 'Human Resources',\n",
       " 'Human Resource Manager',\n",
       " 'Human Resource Manager',\n",
       " 'Regional HR Manager',\n",
       " 'Regional HR Manager',\n",
       " 'Human Resources',\n",
       " 'Human Resource Manager',\n",
       " 'Human Resource Manager',\n",
       " 'Human Resource Manager',\n",
       " 'Human Resource Manager',\n",
       " 'Human Resources',\n",
       " 'Human Resources',\n",
       " 'Human Resource Manager',\n",
       " 'Human Resources',\n",
       " 'Human Resource Manager',\n",
       " 'Human Resource manager',\n",
       " 'Associate Manager Human Resources',\n",
       " 'Human Resource Manager',\n",
       " 'Human resources',\n",
       " 'Human Resource Manager',\n",
       " 'Human Resource Manager',\n",
       " 'Human Resource Manager',\n",
       " 'HUMAN RESOURCES',\n",
       " 'Human Resource Manager']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desig = []\n",
    "\n",
    "des = driver.find_elements(By.XPATH,'//span[@class=\"ellipsis clr\"]')\n",
    "for i in des:\n",
    "    desig.append(i.text)\n",
    "    \n",
    "desig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bd43398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Maveric Systems',\n",
       " 'TCRC',\n",
       " 'DSR Design &amp; Engineering Solutions',\n",
       " 'Ingenious E-Brain Solutions Private Limited',\n",
       " 'Xpansion HR Solutions Private Limited',\n",
       " 'E Vel',\n",
       " 'HMS Relations Management',\n",
       " 'IQs soft',\n",
       " 'Take Jobs',\n",
       " 'Infin Software Technologies Pvt. Ltd',\n",
       " 'Exatip Technologies',\n",
       " 'Jute Wonders Unlimited',\n",
       " 'Sterlite Technologies Ltd. Elitecore',\n",
       " 'TechCube IT Services Pvt Ltd',\n",
       " 'Tetraskelion Softwares (P) Ltd',\n",
       " 'KKR BOSE DESIGN SERVICES PVT LTD',\n",
       " '22Feet Tribal Worldwide (DDB Worldwide)',\n",
       " 'Be-Tuned Solutions',\n",
       " 'CoconutEvent',\n",
       " 'Ravi infra- Build Projects Private limited,',\n",
       " 'Treselle Software Pvt Ltd',\n",
       " 'Smart Technospace Pvt Ltd',\n",
       " 'Sahil International',\n",
       " 'Paragyte Technologies',\n",
       " 'Sarbottam Cement Pvt. Ltd. / Laxmi Steels...',\n",
       " 'Larsen And Toubro',\n",
       " 'Gujarat Ambuja Exports limited',\n",
       " 'Nityo Infotech',\n",
       " 'Reliance Communications',\n",
       " 'Cambridge Learning System',\n",
       " 'Cambridge Learning System',\n",
       " 'Akamai Technologies',\n",
       " 'HCG Cancer Care',\n",
       " 'Rasson Energy India Pvt. Ltd.',\n",
       " 'Influence Technolabs Pvt Ltd',\n",
       " 'STEP IN SOLUTIONS',\n",
       " 'Charmi D Dave',\n",
       " 'Orion eSolutions.Pvt.Ltd',\n",
       " 'Miracle Group',\n",
       " 'Jones Lang La Salle',\n",
       " 'Novel Group',\n",
       " 'iota Academy',\n",
       " 'Perfetti Van Melle India',\n",
       " 'Vikas Kochar &amp; Associates',\n",
       " 'MarlinByte Software Solutions Pvt. Ltd.',\n",
       " 'Motilal Oswal Securities Limited',\n",
       " 'Nimble Organics Jobs',\n",
       " 'United Telecoms Limited',\n",
       " 'BVL GROUP',\n",
       " 'Appscook Technologies']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp = []\n",
    "\n",
    "com = driver.find_elements(By.XPATH,'//a[2][@class=\"ellipsis\"]')\n",
    "for i in com:\n",
    "    comp.append(i.text)\n",
    "    \n",
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c56e425b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It Recruitment, Campus Recruitment, Campus Hiring, Software Testing',\n",
       " 'Operation Executive, Jr. Chemist/ Chemist, Audit, Chemist, Operation Coordination, Documentation, Typist, Data Entry, Operation, Inspection, Survey, Analysis',\n",
       " 'Design Engineering, AutoCAD, Solid Works',\n",
       " 'B.tech, Operations, Business Development, Business Analysis, Business Intelligence, Business Research, Market Research, Ipr',\n",
       " 'Bde, Accounting, Education Counseling, Sales, Inside Sales, Telecalling, International Bpo, International Call Center',\n",
       " 'Html, Css, Javascript, Ui Development, Java, Android, Ios, Liferay Developer, Sfdc, Cloud Fusion, Atg Developer',\n",
       " 'Counter Sales, Sales',\n",
       " 'Java/J2ee ( Core Java, Struts, Hibernate, Servlets, JSP, Spring), .Net ( C# asp.net, Vb.net, Sql Server ), Testing tools &amp;ndash;Manual / Automation ( QTP',\n",
       " 'tally, Bank Reconciliation, billing, electricals, Cable Laying, Fault Finding, Team Leading, Back Office, Personal Loans, operations, design',\n",
       " 'Technical, PHP, Web Development, Web Technologies, Wordpress, Javascript, HTML, OSCommerce, Codeigniter, JQuery, CSS, Facebook, Seo, Smo, Smm, Search Engine',\n",
       " 'Software Development, Business Development',\n",
       " 'Back Office',\n",
       " 'C++, Java/j2ee, C, Networking, Radius, Diameter, Aaa, Testing, Billing, Mediation, Charging, Rating, Policy Control, Provisioning, Oss/bss, Core',\n",
       " 'Skills- Technical Troubleshooting / Sales / Up-Selling / Order Processing / Customer Services / Contact Center Account Management - Roles- Representatives /',\n",
       " '.Net, Java, PHP, Android, Testing, IOS, Web and Graphic, UI, SAP, Quality Assurance / Testing, Manual Testing, Software Testing, Web Applications, Web',\n",
       " 'Ravit',\n",
       " 'Magento, PHP, Content, Design, DotNet, BD',\n",
       " 'Content Writing, Content Development, Technical Writing, Creative Writing, Bidder Required, Online Bidding, Business Development',\n",
       " 'English Literature, Copy Writing, Content Writing, Copy Editing, Proof Reading, Content Editing, Content',\n",
       " 'BDM/ BDO, Branch Manager, Senior Branch manager, Chartered Accountant, Marketing Executive, Operation Executive, accountant, Account Management, account',\n",
       " 'Java, Database, Front End, Big Data, Cloud Computing, Salesforce, Testing, Data Scientist, DevOps, Lead Generation, Mobile, Technical Architect, Technical PM',\n",
       " 'Project Management, Sharp Supervision, Leadership, ready to travel, excellent communication skill, drywall/PEB knowledge, Project Planning, Project',\n",
       " 'Marketing, Customer Service, Finance, Telecom, Graphic Designing, System Administration System Engineer, It Executive, System Technician, Hardware And',\n",
       " 'java, support, ui designer/developer, Java Script, html, spring, hibernate, React.js, .net, Node.js, Recruitment',\n",
       " 'Erection Commissioning, Stores, Installation, Material Receipt, Project Scheduling, Mechanical Engineering, B.e, Maintenance, Electrical Engineering',\n",
       " 'Thermodynamics, Heat Transfer, Product Quality, Mechanical Engineering, B.e, Diploma, Maintenance, B.tech, Autocad, Mechanical Maintenance, Mechanical Design',\n",
       " 'Good Communication Skill, Confident Personality, Store Executive, Account Executive, Public Relation Officer, Purchase Executive, Sr. Administrator',\n",
       " 'Myntra, Redbus, Digital Vidya, Accolite Software, Hiya',\n",
       " 'Software Development, Technical, It, Web Designing, Sales, Management, Relationship Management, Real Estate Marketing, Sales Management, Selling, New Business',\n",
       " 'Education Industry, Educational Sales, Educational Administration, Educational Marketing',\n",
       " 'Web Designing, Education, Educational Sales, Educational Marketing, Sales, Advertising, Public Relations, Marketing Campaigns, Promotions, Events, Social',\n",
       " 'Internet Technologies, Media Streaming, Information Security, Network Security, Presales Consultant',\n",
       " 'health care services, Oncologist, Center Management, Marketing, International Marketing, Cradit Controle, Hr Managers, Accounts Managers, Quality Control',\n",
       " 'Procurement, Supply Chain, Engineer, Marketing, Project Management, Supply Chain Management, Sales, Business Development',\n",
       " 'HTML, CSS, .Net, Dream Weaver, Photoshop, Java Script, Visual Studio, Android, XML, HTML5, C, Java, JQuery, JSON, J2ME, SDK, IDE, JAVA, JQUERY',\n",
       " 'Javascript, MVC, PHP, UX, Web Technologies, Product Management, Software Services',\n",
       " 'Store Keeping, Stores Maintenance, Inventory, Store Management',\n",
       " 'Developers, IOS DEVELOPERS, IOS, IPHONE, Android Developer, Android, Business Development, Business Analytics, Online Bidding, Bidder, Internet Marketing, Mass',\n",
       " 'Developers, Project Mangers, Quality Assurance, Accounting, Content Writing, Android, Ios',\n",
       " 'Sr. Manager, Manager, Management, Facilities, Facility Management, Hotel, Cafeteria Management, Event Management, Corporate Events, Daily Operations',\n",
       " 'Business Development, Client Relationship Management, Project Engineering, It Hardware, Material Procurement, Project Procurement, Digital Marketing',\n",
       " 'Curriculum Development, physics, Teaching, Iit, Iit-jee, Jee, Jee Main, Advanced, Neet, Entrance Exam, Competitive Exam, Nit, T, Math',\n",
       " 'Channel Sales, Fmcg Sales, Sales, Channel Distribution, Distribution, Distribution Network, Business Development',\n",
       " 'Executive, Managers, Data Entry Operation, Data Entry Operator, Communication Skills, Audit, Bangalore',\n",
       " 'Web Designing, Web Development, Content Writing, seo, Digital Marketing, Business Development, Web Technologies, Php, Wordpress',\n",
       " 'Sales/ Marketing, Sales Management, Client Acquisition, Rm, Hni Sales, Hni Acquisition, Hni Client Handling, Mutual Funds, Sip, Equity, Broking, Financial',\n",
       " 'Executive, Front Office, MS Office, English Speaker, Computers, Receptionist, Marketing Executives, Operations, Management',\n",
       " 'Channel Sales Management, Territory Sales Management, Area Sales Management, Channel Sales, Distributor Sales, Dealer Management, Business Development',\n",
       " 'accounting, auditing, finance, payments, reporting, Receptionist Activities, Front Office, Communication Skills, MS Office, Administration, Security',\n",
       " 'Core Java, JavaEE, Spring, Spring Boot, HIbernate, Maven, Mysql, Project Management, Planning, Scheduling, Monitoring, Execution, Organizing, Team']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill = []\n",
    "\n",
    "skills = driver.find_elements(By.XPATH,'//div[@class=\"hireSec highlightable\"]')\n",
    "for i in skills:\n",
    "    skill.append(i.text)\n",
    "    \n",
    "skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11d2236c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chennai',\n",
       " 'Mumbai',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Gurgaon',\n",
       " 'Pune',\n",
       " 'Madurai',\n",
       " 'Delhi',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Delhi',\n",
       " 'Chandigarh',\n",
       " 'Indore',\n",
       " 'Delhi',\n",
       " 'Ahmedabad',\n",
       " 'Mohali',\n",
       " 'Jaipur',\n",
       " 'Mumbai',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Mohali',\n",
       " 'Mumbai',\n",
       " 'Udaipur',\n",
       " 'Chennai',\n",
       " 'Surat',\n",
       " 'Mumbai',\n",
       " 'Pune',\n",
       " 'Nepal - (Kathmandu)',\n",
       " 'Kolkata',\n",
       " 'Ahmedabad',\n",
       " 'Delhi',\n",
       " 'Gurgaon',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Delhi',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Ahmedabad',\n",
       " 'Delhi',\n",
       " 'Mumbai',\n",
       " 'Ahmedabad',\n",
       " 'Mohali',\n",
       " 'Chandigarh',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Kolkata',\n",
       " 'Kolkata',\n",
       " 'Delhi',\n",
       " 'Delhi',\n",
       " 'Amritsar',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Noida',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Thrissur']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locat = []\n",
    "\n",
    "loc = driver.find_elements(By.XPATH,'//small[@class=\"ellipsis\"]')\n",
    "for i in loc:\n",
    "    locat.append(i.text)\n",
    "    \n",
    "locat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48da7552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50 50 50 50\n"
     ]
    }
   ],
   "source": [
    "print(len(name),len(desig),len(comp),len(skill),len(locat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31f1f9d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skills they hire for</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Santhosh Kumar</td>\n",
       "      <td>Associate Manager Human Resources</td>\n",
       "      <td>Maveric Systems</td>\n",
       "      <td>It Recruitment, Campus Recruitment, Campus Hir...</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gauri Bhosle</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>TCRC</td>\n",
       "      <td>Operation Executive, Jr. Chemist/ Chemist, Aud...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Surendra R</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>DSR Design &amp;amp; Engineering Solutions</td>\n",
       "      <td>Design Engineering, AutoCAD, Solid Works</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neha Pandey</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Ingenious E-Brain Solutions Private Limited</td>\n",
       "      <td>B.tech, Operations, Business Development, Busi...</td>\n",
       "      <td>Gurgaon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vinita Raut</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Xpansion HR Solutions Private Limited</td>\n",
       "      <td>Bde, Accounting, Education Counseling, Sales, ...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BALA Sakthivelmuthu</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>E Vel</td>\n",
       "      <td>Html, Css, Javascript, Ui Development, Java, A...</td>\n",
       "      <td>Madurai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Prarit Gupta</td>\n",
       "      <td>Human Resource Manager</td>\n",
       "      <td>HMS Relations Management</td>\n",
       "      <td>Counter Sales, Sales</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Raghu Hrexecutive</td>\n",
       "      <td>Human Resource manager</td>\n",
       "      <td>IQs soft</td>\n",
       "      <td>Java/J2ee ( Core Java, Struts, Hibernate, Serv...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Take jobs</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>Take Jobs</td>\n",
       "      <td>tally, Bank Reconciliation, billing, electrica...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>iNFIN Technologies</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>Infin Software Technologies Pvt. Ltd</td>\n",
       "      <td>Technical, PHP, Web Development, Web Technolog...</td>\n",
       "      <td>Chandigarh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Punit Kumar Bhidodiya</td>\n",
       "      <td>Human Resource Manager</td>\n",
       "      <td>Exatip Technologies</td>\n",
       "      <td>Software Development, Business Development</td>\n",
       "      <td>Indore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ishan Ahmed</td>\n",
       "      <td>Human Resource Manager</td>\n",
       "      <td>Jute Wonders Unlimited</td>\n",
       "      <td>Back Office</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sreekanth Menon</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>Sterlite Technologies Ltd. Elitecore</td>\n",
       "      <td>C++, Java/j2ee, C, Networking, Radius, Diamete...</td>\n",
       "      <td>Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TechCube IT Services Pvt Ltd</td>\n",
       "      <td>Human Resource Manager</td>\n",
       "      <td>TechCube IT Services Pvt Ltd</td>\n",
       "      <td>Skills- Technical Troubleshooting / Sales / Up...</td>\n",
       "      <td>Mohali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Fatte Chand Soni</td>\n",
       "      <td>Human Resource Generalist</td>\n",
       "      <td>Tetraskelion Softwares (P) Ltd</td>\n",
       "      <td>.Net, Java, PHP, Android, Testing, IOS, Web an...</td>\n",
       "      <td>Jaipur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Koustav Bose</td>\n",
       "      <td>human resource manager</td>\n",
       "      <td>KKR BOSE DESIGN SERVICES PVT LTD</td>\n",
       "      <td>Ravit</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Vaishambi Saxena</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>22Feet Tribal Worldwide (DDB Worldwide)</td>\n",
       "      <td>Magento, PHP, Content, Design, DotNet, BD</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Be Tuned Solutions</td>\n",
       "      <td>Human Resource Manager</td>\n",
       "      <td>Be-Tuned Solutions</td>\n",
       "      <td>Content Writing, Content Development, Technica...</td>\n",
       "      <td>Mohali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Prerna Kashyap</td>\n",
       "      <td>Human Resource Manager</td>\n",
       "      <td>CoconutEvent</td>\n",
       "      <td>English Literature, Copy Writing, Content Writ...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sunil Joshi</td>\n",
       "      <td>Human Resource Manager</td>\n",
       "      <td>Ravi infra- Build Projects Private limited,</td>\n",
       "      <td>BDM/ BDO, Branch Manager, Senior Branch manage...</td>\n",
       "      <td>Udaipur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Stella</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>Treselle Software Pvt Ltd</td>\n",
       "      <td>Java, Database, Front End, Big Data, Cloud Com...</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Pranav Varia</td>\n",
       "      <td>Human Resource Manager</td>\n",
       "      <td>Smart Technospace Pvt Ltd</td>\n",
       "      <td>Project Management, Sharp Supervision, Leaders...</td>\n",
       "      <td>Surat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Emma Rodrigues</td>\n",
       "      <td>Human Resource Manager</td>\n",
       "      <td>Sahil International</td>\n",
       "      <td>Marketing, Customer Service, Finance, Telecom,...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Sonal Sharma</td>\n",
       "      <td>Human Resource Manager</td>\n",
       "      <td>Paragyte Technologies</td>\n",
       "      <td>java, support, ui designer/developer, Java Scr...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sita Chhetri</td>\n",
       "      <td>Human Resource Manager</td>\n",
       "      <td>Sarbottam Cement Pvt. Ltd. / Laxmi Steels...</td>\n",
       "      <td>Erection Commissioning, Stores, Installation, ...</td>\n",
       "      <td>Nepal - (Kathmandu)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Nikhil Bhardwaj</td>\n",
       "      <td>Regional HR Manager</td>\n",
       "      <td>Larsen And Toubro</td>\n",
       "      <td>Thermodynamics, Heat Transfer, Product Quality...</td>\n",
       "      <td>Kolkata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Vibhuti Bhatt</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>Gujarat Ambuja Exports limited</td>\n",
       "      <td>Good Communication Skill, Confident Personalit...</td>\n",
       "      <td>Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Pushkar Gupta</td>\n",
       "      <td>Human Resource Manager</td>\n",
       "      <td>Nityo Infotech</td>\n",
       "      <td>Myntra, Redbus, Digital Vidya, Accolite Softwa...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Anjali Gupta</td>\n",
       "      <td>Human Resource Manager</td>\n",
       "      <td>Reliance Communications</td>\n",
       "      <td>Software Development, Technical, It, Web Desig...</td>\n",
       "      <td>Gurgaon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>katrina Dikoster</td>\n",
       "      <td>Regional HR Manager</td>\n",
       "      <td>Cambridge Learning System</td>\n",
       "      <td>Education Industry, Educational Sales, Educati...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>shalini gupta</td>\n",
       "      <td>Regional HR Manager</td>\n",
       "      <td>Cambridge Learning System</td>\n",
       "      <td>Web Designing, Education, Educational Sales, E...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Pradeep Naik</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>Akamai Technologies</td>\n",
       "      <td>Internet Technologies, Media Streaming, Inform...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>K Gayaj</td>\n",
       "      <td>Human Resource Manager</td>\n",
       "      <td>HCG Cancer Care</td>\n",
       "      <td>health care services, Oncologist, Center Manag...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Ms Chitra Doshi</td>\n",
       "      <td>Human Resource Manager</td>\n",
       "      <td>Rasson Energy India Pvt. Ltd.</td>\n",
       "      <td>Procurement, Supply Chain, Engineer, Marketing...</td>\n",
       "      <td>Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Deepak Tripathi</td>\n",
       "      <td>Human Resource Manager</td>\n",
       "      <td>Influence Technolabs Pvt Ltd</td>\n",
       "      <td>HTML, CSS, .Net, Dream Weaver, Photoshop, Java...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ASHISH MAURYA</td>\n",
       "      <td>Human Resource Manager</td>\n",
       "      <td>STEP IN SOLUTIONS</td>\n",
       "      <td>Javascript, MVC, PHP, UX, Web Technologies, Pr...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Charmi Dave</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>Charmi D Dave</td>\n",
       "      <td>Store Keeping, Stores Maintenance, Inventory, ...</td>\n",
       "      <td>Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Lilly Mohindru</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>Orion eSolutions.Pvt.Ltd</td>\n",
       "      <td>Developers, IOS DEVELOPERS, IOS, IPHONE, Andro...</td>\n",
       "      <td>Mohali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Nivedita Rawat</td>\n",
       "      <td>Human Resource Manager</td>\n",
       "      <td>Miracle Group</td>\n",
       "      <td>Developers, Project Mangers, Quality Assurance...</td>\n",
       "      <td>Chandigarh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Sandeep Samantaray</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>Jones Lang La Salle</td>\n",
       "      <td>Sr. Manager, Manager, Management, Facilities, ...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Vijay Bharadvaj</td>\n",
       "      <td>Human Resource Manager</td>\n",
       "      <td>Novel Group</td>\n",
       "      <td>Business Development, Client Relationship Mana...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>iota Academy</td>\n",
       "      <td>Human Resource manager</td>\n",
       "      <td>iota Academy</td>\n",
       "      <td>Curriculum Development, physics, Teaching, Iit...</td>\n",
       "      <td>Kolkata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Arindam Bhattacharjee</td>\n",
       "      <td>Associate Manager Human Resources</td>\n",
       "      <td>Perfetti Van Melle India</td>\n",
       "      <td>Channel Sales, Fmcg Sales, Sales, Channel Dist...</td>\n",
       "      <td>Kolkata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Jyoti Chopra</td>\n",
       "      <td>Human Resource Manager</td>\n",
       "      <td>Vikas Kochar &amp;amp; Associates</td>\n",
       "      <td>Executive, Managers, Data Entry Operation, Dat...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Marlin</td>\n",
       "      <td>Human resources</td>\n",
       "      <td>MarlinByte Software Solutions Pvt. Ltd.</td>\n",
       "      <td>Web Designing, Web Development, Content Writin...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Aditya Choudhry</td>\n",
       "      <td>Human Resource Manager</td>\n",
       "      <td>Motilal Oswal Securities Limited</td>\n",
       "      <td>Sales/ Marketing, Sales Management, Client Acq...</td>\n",
       "      <td>Amritsar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Nimble Organics</td>\n",
       "      <td>Human Resource Manager</td>\n",
       "      <td>Nimble Organics Jobs</td>\n",
       "      <td>Executive, Front Office, MS Office, English Sp...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>RAJ KUMAR PANDEY</td>\n",
       "      <td>Human Resource Manager</td>\n",
       "      <td>United Telecoms Limited</td>\n",
       "      <td>Channel Sales Management, Territory Sales Mana...</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>BVL REALTY</td>\n",
       "      <td>HUMAN RESOURCES</td>\n",
       "      <td>BVL GROUP</td>\n",
       "      <td>accounting, auditing, finance, payments, repor...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Kavya M</td>\n",
       "      <td>Human Resource Manager</td>\n",
       "      <td>Appscook Technologies</td>\n",
       "      <td>Core Java, JavaEE, Spring, Spring Boot, HIbern...</td>\n",
       "      <td>Thrissur</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Name                        Designation  \\\n",
       "0                 Santhosh Kumar  Associate Manager Human Resources   \n",
       "1                   Gauri Bhosle                    Human Resources   \n",
       "2                     Surendra R                  Company Recruiter   \n",
       "3                    Neha Pandey                  Company Recruiter   \n",
       "4                    Vinita Raut                  Company Recruiter   \n",
       "5            BALA Sakthivelmuthu                  Company Recruiter   \n",
       "6                   Prarit Gupta             Human Resource Manager   \n",
       "7              Raghu Hrexecutive             Human Resource manager   \n",
       "8                      Take jobs                    Human Resources   \n",
       "9             iNFIN Technologies                    Human Resources   \n",
       "10         Punit Kumar Bhidodiya             Human Resource Manager   \n",
       "11                   Ishan Ahmed             Human Resource Manager   \n",
       "12               Sreekanth Menon                    Human Resources   \n",
       "13  TechCube IT Services Pvt Ltd             Human Resource Manager   \n",
       "14              Fatte Chand Soni          Human Resource Generalist   \n",
       "15                  Koustav Bose             human resource manager   \n",
       "16              Vaishambi Saxena                    Human Resources   \n",
       "17            Be Tuned Solutions             Human Resource Manager   \n",
       "18                Prerna Kashyap             Human Resource Manager   \n",
       "19                   Sunil Joshi             Human Resource Manager   \n",
       "20                        Stella                    Human Resources   \n",
       "21                  Pranav Varia             Human Resource Manager   \n",
       "22                Emma Rodrigues             Human Resource Manager   \n",
       "23                  Sonal Sharma             Human Resource Manager   \n",
       "24                  Sita Chhetri             Human Resource Manager   \n",
       "25               Nikhil Bhardwaj                Regional HR Manager   \n",
       "26                 Vibhuti Bhatt                    Human Resources   \n",
       "27                 Pushkar Gupta             Human Resource Manager   \n",
       "28                  Anjali Gupta             Human Resource Manager   \n",
       "29              katrina Dikoster                Regional HR Manager   \n",
       "30                 shalini gupta                Regional HR Manager   \n",
       "31                  Pradeep Naik                    Human Resources   \n",
       "32                       K Gayaj             Human Resource Manager   \n",
       "33               Ms Chitra Doshi             Human Resource Manager   \n",
       "34               Deepak Tripathi             Human Resource Manager   \n",
       "35                 ASHISH MAURYA             Human Resource Manager   \n",
       "36                   Charmi Dave                    Human Resources   \n",
       "37                Lilly Mohindru                    Human Resources   \n",
       "38                Nivedita Rawat             Human Resource Manager   \n",
       "39            Sandeep Samantaray                    Human Resources   \n",
       "40               Vijay Bharadvaj             Human Resource Manager   \n",
       "41                  iota Academy             Human Resource manager   \n",
       "42         Arindam Bhattacharjee  Associate Manager Human Resources   \n",
       "43                  Jyoti Chopra             Human Resource Manager   \n",
       "44                        Marlin                    Human resources   \n",
       "45               Aditya Choudhry             Human Resource Manager   \n",
       "46               Nimble Organics             Human Resource Manager   \n",
       "47              RAJ KUMAR PANDEY             Human Resource Manager   \n",
       "48                    BVL REALTY                    HUMAN RESOURCES   \n",
       "49                       Kavya M             Human Resource Manager   \n",
       "\n",
       "                                         Company  \\\n",
       "0                                Maveric Systems   \n",
       "1                                           TCRC   \n",
       "2         DSR Design &amp; Engineering Solutions   \n",
       "3    Ingenious E-Brain Solutions Private Limited   \n",
       "4          Xpansion HR Solutions Private Limited   \n",
       "5                                          E Vel   \n",
       "6                       HMS Relations Management   \n",
       "7                                       IQs soft   \n",
       "8                                      Take Jobs   \n",
       "9           Infin Software Technologies Pvt. Ltd   \n",
       "10                           Exatip Technologies   \n",
       "11                        Jute Wonders Unlimited   \n",
       "12          Sterlite Technologies Ltd. Elitecore   \n",
       "13                  TechCube IT Services Pvt Ltd   \n",
       "14                Tetraskelion Softwares (P) Ltd   \n",
       "15              KKR BOSE DESIGN SERVICES PVT LTD   \n",
       "16       22Feet Tribal Worldwide (DDB Worldwide)   \n",
       "17                            Be-Tuned Solutions   \n",
       "18                                  CoconutEvent   \n",
       "19   Ravi infra- Build Projects Private limited,   \n",
       "20                     Treselle Software Pvt Ltd   \n",
       "21                     Smart Technospace Pvt Ltd   \n",
       "22                           Sahil International   \n",
       "23                         Paragyte Technologies   \n",
       "24  Sarbottam Cement Pvt. Ltd. / Laxmi Steels...   \n",
       "25                             Larsen And Toubro   \n",
       "26                Gujarat Ambuja Exports limited   \n",
       "27                                Nityo Infotech   \n",
       "28                       Reliance Communications   \n",
       "29                     Cambridge Learning System   \n",
       "30                     Cambridge Learning System   \n",
       "31                           Akamai Technologies   \n",
       "32                               HCG Cancer Care   \n",
       "33                 Rasson Energy India Pvt. Ltd.   \n",
       "34                  Influence Technolabs Pvt Ltd   \n",
       "35                             STEP IN SOLUTIONS   \n",
       "36                                 Charmi D Dave   \n",
       "37                      Orion eSolutions.Pvt.Ltd   \n",
       "38                                 Miracle Group   \n",
       "39                           Jones Lang La Salle   \n",
       "40                                   Novel Group   \n",
       "41                                  iota Academy   \n",
       "42                      Perfetti Van Melle India   \n",
       "43                 Vikas Kochar &amp; Associates   \n",
       "44       MarlinByte Software Solutions Pvt. Ltd.   \n",
       "45              Motilal Oswal Securities Limited   \n",
       "46                          Nimble Organics Jobs   \n",
       "47                       United Telecoms Limited   \n",
       "48                                     BVL GROUP   \n",
       "49                         Appscook Technologies   \n",
       "\n",
       "                                 Skills they hire for  \\\n",
       "0   It Recruitment, Campus Recruitment, Campus Hir...   \n",
       "1   Operation Executive, Jr. Chemist/ Chemist, Aud...   \n",
       "2            Design Engineering, AutoCAD, Solid Works   \n",
       "3   B.tech, Operations, Business Development, Busi...   \n",
       "4   Bde, Accounting, Education Counseling, Sales, ...   \n",
       "5   Html, Css, Javascript, Ui Development, Java, A...   \n",
       "6                                Counter Sales, Sales   \n",
       "7   Java/J2ee ( Core Java, Struts, Hibernate, Serv...   \n",
       "8   tally, Bank Reconciliation, billing, electrica...   \n",
       "9   Technical, PHP, Web Development, Web Technolog...   \n",
       "10         Software Development, Business Development   \n",
       "11                                        Back Office   \n",
       "12  C++, Java/j2ee, C, Networking, Radius, Diamete...   \n",
       "13  Skills- Technical Troubleshooting / Sales / Up...   \n",
       "14  .Net, Java, PHP, Android, Testing, IOS, Web an...   \n",
       "15                                              Ravit   \n",
       "16          Magento, PHP, Content, Design, DotNet, BD   \n",
       "17  Content Writing, Content Development, Technica...   \n",
       "18  English Literature, Copy Writing, Content Writ...   \n",
       "19  BDM/ BDO, Branch Manager, Senior Branch manage...   \n",
       "20  Java, Database, Front End, Big Data, Cloud Com...   \n",
       "21  Project Management, Sharp Supervision, Leaders...   \n",
       "22  Marketing, Customer Service, Finance, Telecom,...   \n",
       "23  java, support, ui designer/developer, Java Scr...   \n",
       "24  Erection Commissioning, Stores, Installation, ...   \n",
       "25  Thermodynamics, Heat Transfer, Product Quality...   \n",
       "26  Good Communication Skill, Confident Personalit...   \n",
       "27  Myntra, Redbus, Digital Vidya, Accolite Softwa...   \n",
       "28  Software Development, Technical, It, Web Desig...   \n",
       "29  Education Industry, Educational Sales, Educati...   \n",
       "30  Web Designing, Education, Educational Sales, E...   \n",
       "31  Internet Technologies, Media Streaming, Inform...   \n",
       "32  health care services, Oncologist, Center Manag...   \n",
       "33  Procurement, Supply Chain, Engineer, Marketing...   \n",
       "34  HTML, CSS, .Net, Dream Weaver, Photoshop, Java...   \n",
       "35  Javascript, MVC, PHP, UX, Web Technologies, Pr...   \n",
       "36  Store Keeping, Stores Maintenance, Inventory, ...   \n",
       "37  Developers, IOS DEVELOPERS, IOS, IPHONE, Andro...   \n",
       "38  Developers, Project Mangers, Quality Assurance...   \n",
       "39  Sr. Manager, Manager, Management, Facilities, ...   \n",
       "40  Business Development, Client Relationship Mana...   \n",
       "41  Curriculum Development, physics, Teaching, Iit...   \n",
       "42  Channel Sales, Fmcg Sales, Sales, Channel Dist...   \n",
       "43  Executive, Managers, Data Entry Operation, Dat...   \n",
       "44  Web Designing, Web Development, Content Writin...   \n",
       "45  Sales/ Marketing, Sales Management, Client Acq...   \n",
       "46  Executive, Front Office, MS Office, English Sp...   \n",
       "47  Channel Sales Management, Territory Sales Mana...   \n",
       "48  accounting, auditing, finance, payments, repor...   \n",
       "49  Core Java, JavaEE, Spring, Spring Boot, HIbern...   \n",
       "\n",
       "                    Location  \n",
       "0                    Chennai  \n",
       "1                     Mumbai  \n",
       "2   Hyderabad / Secunderabad  \n",
       "3                    Gurgaon  \n",
       "4                       Pune  \n",
       "5                    Madurai  \n",
       "6                      Delhi  \n",
       "7      Bengaluru / Bangalore  \n",
       "8                      Delhi  \n",
       "9                 Chandigarh  \n",
       "10                    Indore  \n",
       "11                     Delhi  \n",
       "12                 Ahmedabad  \n",
       "13                    Mohali  \n",
       "14                    Jaipur  \n",
       "15                    Mumbai  \n",
       "16     Bengaluru / Bangalore  \n",
       "17                    Mohali  \n",
       "18                    Mumbai  \n",
       "19                   Udaipur  \n",
       "20                   Chennai  \n",
       "21                     Surat  \n",
       "22                    Mumbai  \n",
       "23                      Pune  \n",
       "24       Nepal - (Kathmandu)  \n",
       "25                   Kolkata  \n",
       "26                 Ahmedabad  \n",
       "27                     Delhi  \n",
       "28                   Gurgaon  \n",
       "29  Hyderabad / Secunderabad  \n",
       "30                     Delhi  \n",
       "31     Bengaluru / Bangalore  \n",
       "32     Bengaluru / Bangalore  \n",
       "33                 Ahmedabad  \n",
       "34                     Delhi  \n",
       "35                    Mumbai  \n",
       "36                 Ahmedabad  \n",
       "37                    Mohali  \n",
       "38                Chandigarh  \n",
       "39     Bengaluru / Bangalore  \n",
       "40     Bengaluru / Bangalore  \n",
       "41                   Kolkata  \n",
       "42                   Kolkata  \n",
       "43                     Delhi  \n",
       "44                     Delhi  \n",
       "45                  Amritsar  \n",
       "46     Bengaluru / Bangalore  \n",
       "47                     Noida  \n",
       "48     Bengaluru / Bangalore  \n",
       "49                  Thrissur  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Name':name,'Designation':desig,'Company':comp,'Skills they hire for':skill,'Location':locat})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a2f95a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
